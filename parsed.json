[
    {
        "Observable": "An inventory system or database containing records of all enterprise assets with attributes such as network address, hardware address, machine name, owner, department, and approval status, along with logs or timestamps indicating bi-annual or more frequent reviews and updates.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": {
            "Checklist": "The safeguard can be assessed using a checklist to verify the existence of the inventory and the presence of required attributes for each asset.",
            "Verifiable": "The accuracy and completeness of the inventory can be verified by cross-referencing with actual asset data and system configurations.",
            "Measurable": "Quantitative metrics such as coverage, accuracy, and update frequency can be derived from the inventory data to measure enforcement quality."
        },
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": {
            "Data-driven": "Statistics and metrics can be generated from the inventory database, event logs, and network scan data to assess compliance.",
            "Model-based": "The configuration and structure of the inventory system can be evaluated against the safeguard requirements to determine if it is properly set up.",
            "Active testing": "Network probing or scanning tools can be used to actively discover assets not listed in the inventory, providing data for metrics."
        },
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory - The enterprise's list of current approved inventory to include all assets as outlined in the Safeguard. This list is a mix of manual and tool-generated endpoints that includes information such as authorized, non-authorized, IP address, device type, and any other information as defined by the enterprise.",
                "Aggregate Enterprise Asset Inventory - The enterprise's list of all devices detected, manually or through automated scans, since the last update to GV1.",
                "Date of last update to the Enterprise Asset Inventory"
            ]
        ],
        "Operations": [
            [
                "Calculate the intersection of GV1 and Input 2",
                [
                    "Enumerate items in GV1 that are not in Input 2 (M4)",
                    "Enumerate items in Input 2 not in Input 1 (GV2: M5). These assets are considered unauthorized."
                ]
            ],
            [
                "Check items in Input 1 for complete or missing detailed information",
                [
                    "Enumerate items that have complete information (M6)",
                    "Enumerate items that do not have complete information or missing information (M7)."
                ]
            ],
            "Calculate the time (in months) since the last update to Input 1 by using the current date and Input 4 (M8)."
        ],
        "Metric_as_text": [
            [
                "If M1 is not provided or available, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply.",
                "If M8 is greater than six months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "What percentage of the aggregate endpoint inventory is accounted for in the current enterprise asset inventory?",
                "measure.description": [
                    "M3 = Count of items in the intersection of GV1 and Input 2",
                    "M2 = Count of items in Input 2"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Logs of unauthorized asset detection, records of actions taken (e.g., removal, denial, quarantine), and weekly review reports.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist because the existence of a process can be assessed through documentation or scripts; Verifiable because the actions taken can be confirmed by checking system logs and configurations; Measurable because the frequency and effectiveness of the process can be quantified using data from logs and reviews.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven because it involves analyzing event logs, asset detection data, and action records to evaluate enforcement; Model-based because it requires checking the configuration and setup of the process for addressing unauthorized assets; Active testing because probing the network with unauthorized assets can test if the process responds appropriately.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV2: Unauthorized Assets",
                "The enterprise-defined time frame for removing unauthorized assets    (weekly or more often)."
            ]
        ],
        "Operations": [
            "At the time frame specified by Input 3, for each unauthorized asset\n    in GV2, check to see if the asset is present in the updated asset\n    inventory from GV1.",
            [
                "For those items in GV2 that are not in GV1, scan the network to determine if the item is still reachable on the network.",
                [
                    "Enumerate the items from GV2 that are unreachable (M4)",
                    "Enumerate the items from GV1 that are unreachable (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M3 is greater than seven days, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The ratio of unaccounted for, unauthorized assets, to the total assets in the asset inventory.",
                "measure.description": [
                    "M4 = Count of items from GV2 that are unreachable after scan",
                    "M2 = Count of GV2"
                ],
                "measure.id": [
                    "M4",
                    "M2",
                    "M4",
                    "M2"
                ],
                "equation": "If the value of M4 is 0, there are no unauthorized assets that remain unaccounted for. In this case, the value of the metric is 1. Otherwise, the value is (M2 - M4) / M2."
            }
        ]
    },
    {
        "Observable": "Scan reports from the active discovery tool, configuration settings indicating scan schedule (e.g., cron jobs or tool configurations), and logs of scan executions.",
        "Class": "Checklist, Verifiable",
        "Class.explanation": "Checklist because the presence and configuration of the tool can be assessed through scripting (e.g., checking if the tool is installed and configured correctly). Verifiable because the system configuration (e.g., scan frequency settings) can be manually or automatically verified against policies.",
        "Evaluation_Method": "Data-driven, Active testing",
        "Evaluation_Method.explanation": "Data-driven because statistics can be generated from scan logs, configuration data, and network coverage reports to evaluate enforcement. Active testing because probing the system (e.g., running the discovery tool or checking its output) may be necessary to verify functionality and scan execution.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "The list of active discovery tool(s) used by the enterprise",
                "List consisting of the union from scan results conducted using all    active asset discovery tool(s) within the enterprise (discovered    assets).",
                "Timeframe between two active asset discovery tool scans.",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Identify enterprise assets not discovered by the active discovery\n    tools by comparing Input 1 and Input 3 (M2).",
            "Identify the configurations for active asset discovery tools that\n    interface with GV1 by using GV3",
            [
                "Using the configuration information in GV3, check the approved configurations to verify that the tools are capable of interfacing with the asset inventory to make automatic updates.",
                [
                    "Enumerate those tools that are compliant (M3)",
                    "Enumerate those that are not compliant (M4)."
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M7 is greater than 24 hours, then this Safeguard is measured at a\n    0 and receives a failing score. The other metrics don't apply.",
                "If M5 is 0, then this Safeguard is measured at a 0 and receives a\n    failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "Asset Discovery Coverage",
                "measure.description": [
                    "M1 = Count of all discovered assets from Input 3",
                    "M6 = Count of GV1"
                ],
                "measure.id": [
                    "M1",
                    "M6"
                ],
                "equation": "M1 / M6"
            }
        ]
    },
    {
        "Observable": "DHCP server configuration logs, IP address management tool configurations, asset inventory update logs, and timestamps of inventory updates.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the configuration of DHCP servers and IP management tools can be inspected to check if logging is enabled or tools are configured. Measurable because quantitative data such as the count of servers with logging enabled and the frequency of inventory updates can be analyzed from logs and records.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based because the configuration settings of DHCP servers and IP tools can be compared against standards to verify compliance. Data-driven because log data and update timestamps can be statistically analyzed to measure coverage and update frequencies.",
        "Inputs": [
            [
                "List of DHCP Servers",
                "GV41: List of Change Management Database (CMDB) Servers"
            ]
        ],
        "Operations": [
            "For each DHCP server, enumerate those where DHCP logging is enabled (M2)",
            "For each CMDB server, enumerate those where DHCP logs are used to update IP addresses (M4)"
        ],
        "Metric_as_text": [
            [
                "M4 > 0 indicates a non up-to-date asset inventory"
            ]
        ],
        "Metric": [
            {
                "definition": "Ratio of appropriately configured DHCP logging enabled to known DHCP servers",
                "measure.description": [
                    "M2 = Count of DHCP servers with logging enabled",
                    "M1 = Count of Input 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Scan results from passive discovery tools, configuration settings of the tools, logs of scan activities, and records of asset inventory updates.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration and presence of the passive discovery tool can be checked against established standards or scripts; Measurable because the frequency, coverage, and timeliness of scans and updates require quantitative analysis of data from logs and inventory records.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation involves analyzing data from event logs, scan results, and inventory updates to generate statistics on tool configuration, network coverage, scan intervals, and update timing, rather than relying solely on configuration checks or active probing.",
        "Inputs": [
            [
                "GV4: Enterprise Network Architecture Documentation",
                "List of passive asset discovery tools in use by the organization.    For each, include the location of the tool's configuration    information and which networks it covers.",
                "GV3: Configuration Standard - Approved configuration(s) for each passive asset discovery    tool. Configurations should include the settings necessary for the    tool to be able to update the enterprise's asset inventory"
            ]
        ],
        "Operations": [
            "Identify approved configurations for passive asset discovery tools\n    using GV3",
            [
                "For each passive asset discovery tool provided in Input 2, check the tool's configuration against the appropriate approved configuration from GV3",
                [
                    "Enumerate those tools that are properly configured (M1)",
                    "Enumerate those tools that are improperly configured (M2) noting the deviations from proper configuration"
                ]
            ],
            [
                "Identify and enumerate the enterprise's networks (M5) using Input 1, check to see if at least one properly configured passive asset discovery tool from M1 covers that network.",
                [
                    "Create a list of the enterprise's networks that have coverage from at least one properly configured passive asset discovery tool (M3)",
                    "Create a list of the enterprise's networks that do not have coverage from any properly configured passive asset discovery tools (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The ratio of the organization's networks with coverage from at least one properly configured passive asset discovery tool to the total number of networks",
                "measure.description": [
                    "M3 = Count of organization's networks that are covered by properly    configured passive discovery tools",
                    "M5 = Count of enterprise's networks."
                ],
                "measure.id": [
                    "M3",
                    "M5"
                ],
                "equation": "M3 / M5"
            }
        ]
    },
    {
        "Observable": "A detailed software inventory database or list with entries containing title, publisher, initial install/use date, business purpose, and optionally URL, app store, version, deployment mechanism, decommission date, and number of licenses; logs or records of bi-annual reviews and updates; integration with software discovery tools.",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist because the presence and format of the inventory can be automatically checked via scripting; Verifiable because the configuration of the inventory management system can be inspected for compliance; Measurable because data on inventory coverage, metadata completeness, and update frequency can be analyzed quantitatively.",
        "Evaluation_Method": "Data-driven, Model-based, Active testing",
        "Evaluation_Method.explanation": "Data-driven for statistical analysis of inventory data and review logs to assess coverage and timeliness; Model-based for evaluating the configured policies and settings in the inventory system; Active testing for probing the system to verify inventory accuracy against actual software installations.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory - The authorized software inventory with detailed information    including: title, publisher, initial install/use date, and business purpose for each entry; where appropriate, include the Uniform Resource Locator (URL), app store(s), version(s), deployment mechanism, and decommission date",
                "GV6: Last Update to Authorized Software Inventory"
            ]
        ],
        "Operations": [
            [
                "Check GV5 for completeness of detailed information.",
                [
                    "Note items that have complete detailed information (M2).",
                    "Note items that have missing or incomplete information (M3)."
                ]
            ],
            "Compare the current date to GV6 and note timeframe in months (M4)."
        ],
        "Metric_as_text": [
            [
                "If M1 is not provided or available, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply.",
                "If M4 is greater than six months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "What percentage of the current enterprise asset inventory contains necessary detailed information?",
                "measure.description": [
                    "M2 = Count of items in GV5 with complete information",
                    "M1 = Count of GV5"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The software inventory list with authorization status (authorized/unauthorized) and support status for each software, exception documentation files for unsupported software, and timestamps or logs of review activities.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard is verifiable because it involves checking the configuration of the software inventory (e.g., support status and authorization designations) and the existence of exception documentation, which can be assessed through manual inspection or automated verification tools without requiring complex data analytics.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation is used to assess the configuration of authorized software and exception documentation by examining system settings and documents. Data-driven evaluation is used for review frequency by analyzing timestamps from review logs to generate statistics on compliance with the monthly review requirement.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory    deployment mechanism, and decommission date.",
                "Authoritative source of information indicating supported/unsupported    details by product.",
                "Exception documentation for unsupported software that is necessary    for the fulfillment of the enterprise's mission.",
                "GV6: Last Update to Authorized Software Inventory"
            ]
        ],
        "Operations": [
            [
                "For each item in GV5, perform a lookup in Input 2 to verify the supported/unsupported status.",
                [
                    "Enumerate each item labeled \"unsupported\" but \"supported\" based on Input 2 (M2)",
                    "Enumerate each item labeled \"supported\" but \"unsupported\" based on Input 2 (M3)."
                ]
            ],
            "Identify and note truly \"unsupported\" items from Input 1 after conducting Operation 1 (M4).",
            [
                "For each unsupported item identified in Operation 2, conduct a check using Input 3.",
                [
                    "Note items that do not have appropriate exception documentation (M5).",
                    "Note items that do have appropriate exception documentation (M6)."
                ]
            ],
            "Compare the date of GV6 to the current date and note the timeframe in\n    weeks (M7)."
        ],
        "Metric_as_text": [
            [
                "If M7 is greater than four, then this Safeguard is measured at a 0\n    and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "What percentage of authorized software inventory in use is unsupported?",
                "measure.description": [
                    "M4 = Count of unsupported items",
                    "M1 = Count of Input 1"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Software inventory lists, exception documentation records, review logs, and evidence of software removal actions on enterprise assets.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the presence of unauthorized software and exceptions can be checked against system configurations and documents (e.g., software inventories and exception logs). Measurable because the number of unauthorized software instances and their handling can be quantified and analyzed over time using data from logs and inventories.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because statistics on software counts, exception rates, and removal actions can be generated from event logs, inventory data, and review records. Model-based because the system's software configuration and exception policies can be modeled and verified against established standards (e.g., checking if software lists align with authorized baselines).",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV1: Enterprise Asset Inventory",
                "Enterprise defined timeframe for scanning of enterprise assets.",
                "Enterprise defined allowable timeframe for resolution of discovered    unauthorized software (recommend at least monthly)"
            ]
        ],
        "Operations": [
            "Identify the software capable enterprise\nassets in GV1 (GV7)",
            "Scan the assets identified in Operation 1 and\nnote software present on each asset (M1)",
            [
                "Compare the scan results to\nthe authorized software list in GV5\nEnumerate unauthorized software identified on assets (M2)",
                [
                    "Enumerate unauthorized software identified on assets (M2)"
                ]
            ],
            [
                "Conduct a subsequent scan of assets identified in Operation 1 as dictated by the timeframe in Input 3\nCompare to a list generated in Operation 3 (M2)",
                [
                    "Compare to a list generated in Operation 3 (M2)"
                ]
            ],
            [
                "For each software still present in Operation 4, check the authorized software list in GV5\nSoftware that remains installed and is not listed in GV5 is placed on the unaddressed software list (M3) for that asset.",
                [
                    "Software that remains installed and is not listed in GV5 is placed on the unaddressed software list (M3) for that asset."
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M4 is greater than four weeks, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "Ensure unauthorized software installations are addressed",
                "measure.description": [
                    "M2 = The count of unauthorized software installed on a given asset",
                    "M3 = The count of unaddressed software installed on a given asset,    identified by follow-up scan."
                ],
                "measure.id": [
                    "M2",
                    "M3",
                    "M3"
                ],
                "equation": "(M2-M3) / M3"
            }
        ]
    },
    {
        "Observable": "Presence of software inventory tools on enterprise assets, discovery logs generated by these tools, and documentation reports of installed software.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist because the installation of software inventory tools can be verified through automated scripts; Verifiable because the configuration settings of these tools can be inspected for compliance; Measurable because the effectiveness of discovery and documentation requires data analysis from logs and reports.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven for analyzing event logs, discovery data, and documentation rates; Model-based for checking the configuration models of the inventory tools; Active testing for probing systems to ensure the tools are functioning correctly and discovering software.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV7: Software Capable Assets",
                "List of software inventory tools"
            ]
        ],
        "Operations": [
            "Use GV1 and GV7 to identify and enumerate assets unable to\n    support sofware (M2).",
            [
                "For each software capable asset GV7:",
                [
                    "Identify and enumerate if the asset is covered by at least one software inventory tool (M3)",
                    "Identify and enumerate if the asset is not covered by at least one software inventory tool (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M5 is 0 or unavailable, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of endpoints covered by software inventory tools to the total number of applicable endpoints",
                "measure.description": [
                    "M3 = Count of assets covered by software inventory tools",
                    "M1 = Count of GV7"
                ],
                "measure.id": [
                    "M3",
                    "M1"
                ],
                "equation": ":code:M3 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings for application allowlisting on systems, logs of software execution attempts (both allowed and blocked), and records of allowlist reassessment activities including timestamps and details of reviews.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of application allowlisting can be directly inspected on systems to confirm enablement and settings. Measurable because the effectiveness of blocking unauthorized software and the timeliness of reassessments can be quantified using data from logs and configuration checks over time.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves verifying configuration models and settings for allowlisting on systems. Data-driven evaluation uses statistical analysis of execution logs and reassessment records to measure block rates, coverage, and compliance with reassessment schedules.",
        "Inputs": [
            [
                "GV7: Software Capable Assets",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard",
                "Date of last assessment of this Safeguard"
            ]
        ],
        "Operations": [
            "Using GV7 identify and enumerate assets capable of supporting\n    allowlisting software (some assets may not enable third-party\n    software installation or otherwise have constrained environments\n    precluding the use of allowlisting software) (M1).",
            "Using GV5, identify all authorized allowlisting software within the\n    enterprise (GV8)",
            [
                "Using the output from Operation 1 and authorized allowlisting software GV8:",
                [
                    "Identify and enumerate allowlisting capable assets with allowlisting software installed (M2)",
                    "Identify and enumerate allowlisting capable assets without allowlisting software installed (M3)"
                ]
            ],
            "Use GV3 to identify allowlisting software configurations (GV9)",
            [
                "For each asset with allowlisting software installed (M2) from Operation 2, use the output from Operation 3 to:",
                [
                    "Identify and enumerate properly configured software (M4)",
                    "Identify and enumerate improperly configured software (M5)"
                ]
            ],
            "Compare Input 4 to the current date and note the timeframe in months (M6)"
        ],
        "Metric_as_text": [
            [
                "If M6 is greater than six months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of enterprise assets capable of supporting allowlisting with allowlisting installed",
                "measure.description": [
                    "M2 = Count of enterprise assets capable of supporting allowlisting    software and have the software installed",
                    "M1 = Count of enterprise assets capable of supporting allowlisting    software"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "System logs showing library load events (e.g., attempts to load .dll, .ocx, .so files), configuration files defining authorized libraries, records of reassessment activities, and evidence of blocked unauthorized loads.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of allowed libraries can be inspected against system settings to confirm compliance. Measurable because the effectiveness of blocking unauthorized loads can be quantified through analysis of event logs and reassessment frequencies.",
        "Evaluation_Method": "Model-based, Data-driven, Active testing",
        "Evaluation_Method.explanation": "Model-based evaluation involves checking system configurations to verify the list of authorized libraries. Data-driven evaluation uses statistics from event logs to measure block rates and load attempts. Active testing involves probing the system by attempting to load unauthorized libraries to test if controls are effective.",
        "Inputs": [
            [
                "GV8: Authorized Allowlisting Software",
                "The list of authorized software libraries",
                "GV9: Approved Configuration(s) for Allowlisting Software",
                "Date of the last assessment of this Safeguard"
            ]
        ],
        "Operations": [
            [
                "For each item identified in GV8, use the approved configurations from GV9 and authorized library list from Input 2:",
                [
                    "Identify and enumerate allowlisting software properly configured to allow process loading of authorized libraries (M2)",
                    "Identify and enumerate allowlisting software improperly configured to allow process loading of authorized libraries (M3)"
                ]
            ],
            "Compare the date from Input 4 to the current date and note the timeframe in\n    months (M4)."
        ],
        "Metric_as_text": [
            [
                "If M4 is greater than six months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of appropriately configured allowlisting software instances within the enterprise.",
                "measure.description": [
                    "M2 = Count of properly configured allowlisting software",
                    "M1 = Count GV8"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Script execution logs, configuration settings for digital signatures and version control, reassessment records, blocked script attempts logs",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist: We can check off items like digital signature requirement and version control integration through a predefined list. Verifiable: The configurations of technical controls can be verified against security policies. Measurable: Execution statistics, such as counts of authorized and blocked scripts, can be measured from logs and data.",
        "Evaluation_Method": "Data-driven, Model-based, Active testing",
        "Evaluation_Method.explanation": "Data-driven: Execution logs and event data provide statistics on script attempts and blocks. Model-based: Configuration settings define the expected model for script execution controls. Active testing: Probing the system with unauthorized scripts tests if they are blocked as expected.",
        "Inputs": [
            [
                "GV8: Authorized Allowlisting Software",
                "The list of authorized scripts",
                "GV3: Configuration Standard",
                "Date of last assessment of this Safeguard"
            ]
        ],
        "Operations": [
            "Use GV8 to identify and enumerate all enterprise authorized\n    software capable of executing scripts, including allowlisting\n    software, email client applications, and web client applications\n    (M1)",
            "Use GV3 to identify approved configurations for all software\n    identified in Operation 1",
            [
                "For each item identified in Operation 1, use the approved configurations from Operation 2:",
                [
                    "Identify and enumerate software properly configured to allow execution of authorized and signed scripts from Input 2 (M2)",
                    "Identify and enumerate software improperly configured to allow execution of authorized and signed scripts from Input 2 (M3)"
                ]
            ],
            "Compare the date from Input 4 to the current date and note the timeframe in\n    months (M4)."
        ],
        "Metric_as_text": [
            [
                "If M4 is greater than six months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of appropriately configured allowlisting software instances within the enterprise.",
                "measure.description": [
                    "M2 = Count of properly configured software",
                    "M1 = Count of authorized software capable of executing scripts"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The documented data management process, including its content addressing data sensitivity, data owner, handling of data, data retention limits, and disposal requirements; logs or records of reviews and updates, such as timestamps and version history.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the documentation can be inspected to confirm it contains all required elements. Measurable because aspects like completeness and review frequency can be quantified using data.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because timestamps and logs from document management systems can be analyzed to measure review frequency and update history. Model-based because the documented process serves as a configuration model that can be validated against enterprise standards and requirements.",
        "Inputs": [
            [
                "GV10: Enterprise's Data Management Process",
                "Date of last update to the Data Management Process"
            ]
        ],
        "Operations": [
            [
                "Review GV10 to determine if, at a minimum, it includes:",
                [
                    "Addressing data sensitivity. If so, M1 = 1. Otherwise M1 = 0. (GV11)",
                    "Captures data owner. If so, M2 = 1. Otherwise M2 = 0. (GV13)",
                    "Handling of data. If so, M3 = 1. Otherwise, M3 = 0. (GV14)",
                    "Data retention limits based on the sensitivity of data. If so, M4 = 1. Otherwise, M4 = 0. (GV15)",
                    "Disposal requirements based on the sensitivity of data. If so, M5 = 1. Otherwise, M5 = 0. (GV16)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M6 is not available or does not exist, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of completeness for the enterprise's data management process.",
                "measure.description": [
                    "M1 = Does the process address data sensitivity",
                    "M2 = Does the process capture data owners",
                    "M3 = Does the process include guidance for handling of data",
                    "M4 = Does the process include data retention limits based on    sensitivity of data",
                    "M5 = Does the process include guidance on disposal requirements    based on the sensitivity of the data"
                ],
                "measure.id": [
                    "M1",
                    "M2",
                    "M3",
                    "M4",
                    "M5"
                ],
                "equation": "(M1 + M2 + M3 + M4 + M5) / 5"
            }
        ]
    },
    {
        "Observable": "Presence of a data inventory system, records of sensitive data inclusion in the inventory, and logs or timestamps of annual reviews and updates to the inventory.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and configuration of the data inventory can be checked through system audits or inspections. Measurable because the coverage of sensitive data and the frequency of reviews can be quantified numerically using data from the inventory.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because assessment requires analyzing data from the inventory records and review logs to compute metrics like coverage and compliance. Model-based because it involves inspecting the configuration and setup of the data management process to verify its existence and rules.",
        "Inputs": [
            [
                "GV11: Portion of Data Management Process Addressing Data Sensitivity",
                "GV12: Sensitive Data Inventory",
                "GV1: Enterprise Asset Inventory",
                "Date of the last update to the sensitive data inventory"
            ]
        ],
        "Operations": [
            [
                "Use GV11 to map GV12 to sensitivity per the guidance in the data management process:",
                [
                    "Identify and enumerate items in the data set that have a mapping (M2)",
                    "Identify and enumerate items in the data set that do not have a mapping (M3)"
                ]
            ],
            [
                "Use GV1 and M2 from Operation 1 to map the data set to assets storing data:",
                [
                    "Identify and enumerate items that have complete and correct mapping to asset and sensitivity (M4)",
                    "Identify and enumerate items that have partial mapping to sensitivity (M5)"
                ]
            ],
            [
                "Use GV1 and M3 from Operation 2 to map the data set, without sensitivity mapping, to assets storing data:",
                [
                    "Identify and enumerate items that have partial mapping to assets (M6)",
                    "Identify and enumerate items that have no mapping at all (M7)"
                ]
            ],
            "Compare current date to Input 4 and capture timeframe in months (M8)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M9 is greater than 12 months, this Safeguard is scored at zero and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "Percentage of data with complete information",
                "measure.description": [
                    "M4 = Count of data with complete sensitivity and asset storage inventory",
                    "M9 = Count of items in GV12"
                ],
                "measure.id": [
                    "M4",
                    "M9"
                ],
                "equation": "M4 / M9"
            }
        ]
    },
    {
        "Observable": "Access control list configurations on file systems, databases, and applications; access logs showing user permissions and access attempts.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because ACL configurations can be directly inspected in system settings to check for proper setup based on need-to-know. Measurable because access patterns and permission alignments can be analyzed from logs and data to assess compliance with need-to-know principles.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves examining the configuration models of systems, such as file permissions, database roles, and application settings, to verify that ACLs are correctly applied. Data-driven evaluation involves generating statistics from access event logs, user activities, and permission records to analyze if access patterns and permissions align with need-to-know requirements.",
        "Inputs": [
            [
                "GV12: Sensitive Data Inventory",
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard",
                "GV13: Portion of Data Management Process Capturing Data Owners",
                "GV14: Portion of Data Management Process Addressing Data Handling",
                "GV22: Inventory of Accounts"
            ]
        ],
        "Operations": [
            [
                "Use the data management process, specifically GV13 and GV14, as guidelines to map user accounts to sensitive data in GV12:",
                [
                    "Identify and enumerate sensitive data correctly mapped to user accounts from GV22 (M1)",
                    "Identify and enumerate sensitive data not correctly mapped to user accounts from GV22 (M2)"
                ]
            ],
            [
                "For each enterprise asset in GV1 storing sensitive data, as outlined by GV12:",
                [
                    "Identify and enumerate all assets storing sensitive data (M3)",
                    "Use GV3 to check and enumerate assets that are properly configured to only allow users as identified in Operation 1 (M4)",
                    "Use GV3 to check and enumerate assets that are improperly configured to only allow users as identified in Operation 1 (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If either M7 or M8 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "Percentage of user accounts properly mapped to sensitive data",
                "measure.description": [
                    "M1 = Count of sensitive data correctly mapped to user accounts per the data management process",
                    "M6 = GV17"
                ],
                "measure.id": [
                    "M1",
                    "M6"
                ],
                "equation": "M1 / M6"
            }
        ]
    },
    {
        "Observable": "The documented data management process, data retention policies (including minimum and maximum timelines), system logs of data retention and deletion actions, and timestamps of data creation and access.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the existence and content of the documented data management process can be checked through configuration reviews and policy audits. Measurable because data retention times can be quantified and compared against the policy timelines to assess compliance.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because assessment requires analyzing data from logs, timestamps, and retention actions to compute compliance metrics. Model-based because the policy specifications (minimum and maximum retention times) must be modeled and verified against system configurations and data states.",
        "Inputs": [
            [
                "GV15: Data Retention Limits Outlined in the Data Management Process",
                "GV11: Portion of Data Management Process Addressing Data Sensitivity",
                "GV12: Sensitive Data Inventory"
            ]
        ],
        "Operations": [
            [
                "For each sensitive data type covered in GV11:",
                [
                    "Enumerate the number of types of sensitivity (GV17: M1), at a minimum one to differentiate sensitive data from other data",
                    "Identify and enumerate if each type has a minimum retention time (M2) as defined by GV15",
                    "Identify and enumerate if each type has a maximum retention time (M3) as defined by GV15"
                ]
            ],
            [
                "Using the output of Operation 1.1 and 1.2, check the data inventory GV12 for enforcement of data retention:",
                [
                    "Identify and enumerate items in the inventory that comply with retention timelines (M4)",
                    "Identify and enumerate items in the inventory that do not comply with retention timelines (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "IfGV15is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of sensitivity types that include minimum retention timelines",
                "measure.description": [
                    "M2 = Count of sensitivity types that include minimum retention times",
                    "M1 = Count of sensitivity types that require retention timelines"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Records of data disposal events, audit logs, documented data management process, sensitivity classifications of data, and evidence of disposal methods matching sensitivity levels.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the disposal process and method can be checked against documented standards and configurations. Measurable because compliance rates and sensitivity matching can be quantified from data logs and events.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because it involves analyzing disposal logs, sensitivity data, and event records to generate statistics. Model-based because it requires validating against the enterprise's documented data management process model for configuration and compliance.",
        "Inputs": [
            [
                "GV16: Data Disposal Requirements Outlined in the Data Management Process",
                "GV11: Portion of Data Management Process Addressing Data Sensitivity",
                "GV17: Sensitive Data Types",
                "GV12: Sensitive Data Inventory"
            ]
        ],
        "Operations": [
            [
                "For each sensitive data type covered in GV17:",
                [
                    "Identify and enumerate each type that has a disposal method and process as defined by GV16 (M2)",
                    "Identify and enumerate each type that does not have a disposal method and process as defined by GV16 (M3)"
                ]
            ],
            [
                "For each item in GV12, determine whether the data complies with the disposal requirements outlined in GV17:",
                [
                    "Enumerate data that does not comply with disposal requirements (M4)",
                    "Enumerate data that complies with disposal requirements (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "IfGV16is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of data sensitivity types that contain a disposal method and process",
                "measure.description": [
                    "M2 = Count of sensitive data types with an outlined disposal method",
                    "M1 = GV17"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Encryption status indicators on end-user devices, such as BitLocker enabled in Windows, FileVault enabled in macOS, or dm-crypt active in Linux, along with configuration settings and logs indicating encryption state.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard is verifiable because the encryption status can be directly checked through system configuration settings, command-line tools, or management consoles provided by the operating systems, allowing for confirmation without extensive data analysis or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is model-based as it involves examining the configuration models of devices, such as registry entries, configuration files, or system settings, to determine if encryption is enabled, without requiring statistical analysis of logs or active testing methods.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset in GV1, identify end-user devices:",
                [
                    "Enumerate the end-user devices (M1)",
                    "Use GV5 to identify and enumerate the assets that have encryption software installed (M2)",
                    "Use GV5 to identify and enumerate the assets without encryption software (M3)"
                ]
            ],
            [
                "For each encryption software installed on assets (M2), use GV3 to determine whether the software is properly configured:",
                [
                    "Enumerate the encryption software that is properly configured (M4)",
                    "Enumerate the encryption software that is improperly configured (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "Installed Software Coverage"
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "Existence of a data classification policy documentation, application of classification labels (e.g., 'Sensitive', 'Confidential', 'Public') to data assets, audit logs or records of classification activities, and documentation of annual reviews or reviews triggered by significant enterprise changes.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": [
            "Verifiable: The safeguard can be verified by inspecting the data classification policy, review records, and label applications to ensure they exist and are compliant with the scheme.",
            "Measurable: The enforcement quality can be quantified by measuring the coverage of data classification and the timeliness of scheme reviews using numerical data."
        ],
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": [
            "Model-based: Evaluation involves examining the configuration and documentation of the data classification scheme, such as policy files and review logs, to verify its existence and completeness.",
            "Data-driven: Evaluation requires analyzing data from assets, such as counts of classified data and timestamps of reviews, to compute metrics like coverage and review frequency."
        ],
        "Inputs": [
            [
                "Enterprise's Data Classification Scheme",
                "GV17: Sensitive Data Types",
                "GV12: Sensitive Data Inventory",
                "Date of last review of the Data Classification Scheme"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise has a data classification scheme (Input 1):",
                [
                    "If Input 1 exists, M = 1",
                    "Otherwise M1 = 0"
                ]
            ],
            [
                "Using GV17, determine if the enterprise has a way to categorize the type of data within the classification scheme:",
                [
                    "Enumerate the sensitivity types that are included in the classification scheme (M2)",
                    "Enumerate the sensitivity types that are not included in the classification scheme (M3)"
                ]
            ],
            [
                "Compare GV12 and Input 1:",
                [
                    "Identify and enumerate data that contains an accurate classification per the classification scheme (M4)",
                    "Identify and enumerate data that does not contain a classification or contains an inaccurate classification per the classification scheme (M5)"
                ]
            ],
            "Compare the current date to that provided in Input 4. Note the timeframe in months (M8)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M8 is greater than twelve, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of sensitive data types covered within the classification scheme.",
                "measure.description": [
                    "M2 = Sensitivity addressed by the classification scheme",
                    "M6 = Count of items in GV17"
                ],
                "measure.id": [
                    "M2",
                    "M6"
                ],
                "equation": "M2 / M6"
            }
        ]
    },
    {
        "Observable": "Data flow documentation files, review logs, update timestamps, records of significant changes, and metadata such as last review date and update history.",
        "Class": [
            "Verifiable"
        ],
        "Class.explanation": "The safeguard can be verified by inspecting the documentation and its metadata to ensure it exists, is complete, and is reviewed/updated as required, which involves checking system configurations or files without needing complex data analysis.",
        "Evaluation_Method": [
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Evaluation is based on examining the documented data flows, review records, and update logs, which are part of the system's configuration or process model, without requiring active probing or extensive data-driven analytics.",
        "Inputs": [
            [
                "Documentation outlining data flow for enterprise-owned data. Documentation should include, at a minimum, data flows to external enterprises.",
                "GV12: Sensitive Data Inventory",
                "Date of last review of the data flow documentation"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise has data flow documentation (Input 1):",
                [
                    "If Input 1 exists, M = 1",
                    "Otherwise M1 = 0"
                ]
            ],
            [
                "Using GV12, identify data that flows to external enterprises:",
                [
                    "Enumerate the data that flows to external enterprises (M2)"
                ]
            ],
            [
                "Compare Input 1 and the output of Operation 2:",
                [
                    "Enumerate data flows from Operation 2 that are included in Input 1 (M3)",
                    "Enumerate data flows from Operation 2 that are not included in Input 1 (M4)"
                ]
            ],
            "Compare the current date to that provided in Input 3. Note the timeframe in months (M5)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M5 is greater than twelve, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of existing data flows in the enterprise's data flow documentation.",
                "measure.description": [
                    "M3 = Count of data flows included in the data flow documentation",
                    "M2 = Count of data flows to external enterprises"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Encryption settings on removable media devices, configuration files, or logs indicating encryption status, such as BitLocker or similar encryption tools being enabled.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by checking the configuration of operating systems or device management tools to ensure that encryption is enabled for all removable media, as it involves inspecting settings rather than requiring data analytics or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation relies on examining the system configuration models, such as group policies, device settings, or management console configurations, to determine if encryption is required and enabled for removable media.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets authorized to support removable media (M1)",
            [
                "Use GV5 to identify encryption software installed on assets identified in Operation 1 (M1):",
                [
                    "Enumerate the number of assets with encryption software installed (M2)",
                    "Enumerate the number of assets without encryption software installed (M3)"
                ]
            ],
            [
                "For assets identified in Operation 2.1, use GV3 to check configurations of encryption software:",
                [
                    "Enumerate assets that have properly configured encryption software (M4)",
                    "Enumerate assets that have improperly configured encryption software (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of appropriately configured assets to support removable media.",
                "measure.description": [
                    "M4 = Count of authorized assets with properly configured encryption software",
                    "M1 = Count of assets authorized to support removable media"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Encrypted network connections for sensitive data in transit, such as TLS or SSH sessions, and configuration settings on systems enabling encryption.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because encryption can be confirmed by inspecting system configurations (e.g., TLS settings on servers). Measurable because the extent of encryption usage can be quantified through analysis of network traffic logs.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing network traffic logs to measure encryption usage. Model-based evaluation checks system configurations for encryption settings. Active testing includes performing network probes or scans to verify encryption functionality.",
        "Inputs": [
            [
                "GV12: Sensitive Data Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "For each item in GV12, identify the means and components for encrypting data in transit.",
            [
                "Compare the output of Operation 1 with GV3 to check appropriate approved configurations:",
                [
                    "Enumerate the data items in GV12 that are properly configured (M2)",
                    "Enumerate the data items in GV12 that are improperly configured (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of sensitive data properly configured to be encrypted in transit.",
                "measure.description": [
                    "M2 = Count of data with properly configured encryption components",
                    "M1 = Count of items in GV12 "
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Encryption configurations on servers, applications, and databases; encrypted data at rest; audit logs of encryption processes; settings indicating storage-layer or application-layer encryption.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because encryption settings can be inspected through system configurations, such as checking for enabled encryption in database management systems or server settings. Measurable because the amount and proportion of encrypted sensitive data can be quantified using data-driven analytics, such as comparing encrypted vs. unencrypted data volumes.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based by examining configuration files and system settings to verify if encryption is enabled on servers, applications, and databases. Active testing by probing the system, such as attempting to access data without proper decryption keys, to confirm that data is indeed encrypted and inaccessible in plain text.",
        "Inputs": [
            [
                "GV12: Sensitive Data Inventory",
                "GV4: Enterprise Network Architecture Documentation",
                "GV19: Enterprise Assets Storing Sensitive Data"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate all encryption tools requiring secondary authentication systems (M1)",
            "Use GV12 and GV1 to identify and enumerate all enterprise assets storing sensitive data (GV19: M2)",
            [
                "Compare the output of Operation 1 and Operation 2:",
                [
                    "Identify and enumerate assets with at least one encryption tool from M1 installed (M4)",
                    "Identify and enumerate assets without at least one encryption tool from M1 installed (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets storing sensitive data covered by an encryption tool.",
                "measure.description": [
                    "M3 = Count of assets with at least one encryption tool installed",
                    "M2 = Count of enterprise assets storing sensitive data"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Data classification labels, network segmentation configurations, access logs showing data flows restricted by sensitivity levels, and records of data processing events.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of data classification and segmentation rules can be checked through system inspections; Measurable because actual data processing and violations need to be analyzed using data from logs and flows to assess enforcement quality.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based for evaluating the configuration models of data segmentation and classification; Data-driven for generating statistics from data access logs and processing events to monitor compliance.",
        "Inputs": [
            [
                "GV12: Sensitive Data Inventory",
                "GV4: Enterprise Network Architecture Documentation"
            ]
        ],
        "Operations": [
            "For each item in GV12 identify the assets that store, process, or\n    transmit sensitive data (GV18: M1)",
            [
                "Use the output of Operation 1 and GV4 to identify networks/VLANs connected to the assets:",
                [
                    "Identify and enumerate any instances of properly separated assets from less sensitive networks (M2)",
                    "Identify and enumerate any instances of improperly separated assets from less sensitive networks (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly separated sensitive assets.",
                "measure.description": [
                    "M2 = Count of sensitive assets properly separated from less sensitive networks",
                    "M1 = Count of assets storing, processing, or transmitting sensitive data"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration of the DLP tool, logs from DLP scans showing identified sensitive data, and records of updated data inventory",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the installation and configuration of the DLP tool can be checked through system audits and configuration reviews. Measurable because assessing the identification of sensitive data and the frequency of inventory updates requires data analysis from scan logs and inventory records.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because evaluation involves generating statistics from DLP scan logs and inventory update logs to measure effectiveness. Model-based because it involves verifying the configuration and setup of the DLP tool against expected models.",
        "Inputs": [
            [
                "GV19: Enterprise Assets Storing, Processing, and Transmitting Sensitive Data",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate all data loss prevention software.",
            [
                "Compare GV19 and the output of Operation 1:",
                [
                    "Identify and enumerate each asset in GV19 with data loss prevention software installed (M2)",
                    "Identify and enumerate each asset in GV19 without data loss prevention software installed (M3)"
                ]
            ],
            [
                "For assets with data loss prevention installed from Operation 2.1, check GV3 for configuration information:",
                [
                    "Identify and enumerate assets with properly configured data loss prevention software (M4)",
                    "Identify and enumerate assets with improperly configured data loss prevention software (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets covered by at least one properly configured data loss prevention software instance.",
                "measure.description": [
                    "M4 = Count of assets with properly configured data loss prevention software",
                    "M1 = Count of GV19"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Logs recording access, modification, and disposal of sensitive data, including timestamps, user identities, and data identifiers.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the configuration of logging systems (e.g., enabling logs for sensitive data) can be checked against system settings and policies. Measurable because the volume, coverage, and completeness of logged events can be analyzed using data-driven methods to assess enforcement.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based because it involves inspecting system configurations and models to verify if logging is enabled for sensitive data. Data-driven because it requires collecting and analyzing log data, such as event counts and timestamps, to evaluate the actual logging activity.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV18: Enterprise Assets Storing Sensitive Data",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Using GV5, identify authorized logging software.",
            [
                "For each asset in GV18, use the output from Operation 1:",
                [
                    "Identify and enumerate assets with logging software installed (M2)",
                    "Identify and enumerate assets that do not have logging software installed (M3)"
                ]
            ],
            [
                "For logging software installed, check configuration using GV3:",
                [
                    "Identify and enumerate software that is properly configured (M4)",
                    "Identify and enumerate software that is improperly configured (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured logging on assets storing sensitive data.",
                "measure.description": [
                    "M4 = Count of assets with properly configured logging",
                    "M1 = Count of GV18"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "The documented secure configuration process file, its metadata (e.g., creation date, last modified date), and records of reviews and updates (e.g., audit logs or change management entries indicating when reviews occurred).",
        "Class": [
            "Verifiable",
            "Checklist"
        ],
        "Class.explanation": "The safeguard belongs to the Verifiable class because the documentation can be directly inspected for existence, content, and compliance with requirements. It belongs to the Checklist class because automated scripts or tools can check for the presence of the document, validate metadata such as dates, and ensure it covers specified asset types without deep analysis.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation method is used because it involves examining the configuration and state of the documentation system, such as file properties and content. Data-driven method is used because it requires analyzing temporal data from metadata and logs, such as review dates and update frequencies, to assess compliance.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard - This should include any enterprise-approved deviations from industry-standard baselines such as CIS benchmarks, DISA Security Technical Implementation Guides (STIGs), or U.S. government configuration baselines (USGCB).",
                "Date of last review and update of Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "Identify whether Input 2 exists:",
                [
                    "If it exists, M1 = 1",
                    "If it does not exist, M1 = 0"
                ]
            ],
            "Identify and enumerate end-user devices, including portable and mobile, non-computing/IoT devices, and servers in GV1 (M2)",
            "Using the output of Operation 2 (M2), identify and enumerate the software installed on the assets using GV5 (M3)",
            [
                "For each software identified in Operation 3 (M3):",
                [
                    "Enumerate software that is listed in the configuration standard GV3 (M4)",
                    "Enumerate software that is not listed in the configuration standard GV3 (M5)"
                ]
            ],
            "Compare the current date to the date provided in Input 4. Note the timeframe in months (M6)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M6 is greater than twelve, this Safeguard is measured at 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of authorized software with secure configuration standards documented and maintained.",
                "measure.description": [
                    "M4 = Count of software that is listed in the configuration standard",
                    "M3 = Count of software installed on applicable enterprise assets"
                ],
                "measure.id": [
                    "M4",
                    "M3"
                ],
                "equation": "M4 / M3"
            }
        ]
    },
    {
        "Observable": "The documented secure configuration process for network devices, records of annual reviews, and logs of updates made in response to significant enterprise changes.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be assessed by verifying the existence and content of the documentation through manual inspection or automated checks if the document is in a standard format, as it involves checking for the presence of documents and their adherence to requirements.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation relies on using the documented process as a model to compare against actual network device configurations or change management logs, assessing compliance and enforcement through configuration checks.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard - This should include any enterprise approved deviations from industry standard baselines such as CIS benchmarks, DISA Security Technical Implementation Guides (STIGs), or U.S. government configuration baselines (USGCB).",
                "Date of last review and update of the Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "Identify whether Input 2 exists:",
                [
                    "If it exists, M1 = 1",
                    "If it does not exist, M1 = 0"
                ]
            ],
            "Identify and enumerate network infrastructure assets in GV1 (M2)",
            "Using the output of Operation 2 (M2), identify and enumerate the software installed on the assets using GV5 (M3)",
            [
                "For each software identified in Operation 3 (M3):",
                [
                    "Enumerate software that is listed in the configuration standard GV3 (M4)",
                    "Enumerate software that is not listed in the configuration standard GV3 (M5)"
                ]
            ],
            "Compare the current date to the date provided in Input 4. Note the timeframe in months (M6)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M6 is greater than twelve, this Safeguard is measured at 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of authorized software with secure configuration standards documented and maintained.",
                "measure.description": [
                    "M4 = Count of software that is listed in the configuration standard",
                    "M3 = Count of software installed on applicable enterprise assets"
                ],
                "measure.id": [
                    "M4",
                    "M3"
                ],
                "equation": "M4 / M3"
            }
        ]
    },
    {
        "Observable": "Configuration settings for automatic session locking on enterprise assets, including inactivity timeout values and enablement status, as well as logs or records of session locking events.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be assessed by directly checking the system configuration on each device to verify that automatic session locking is configured with the correct inactivity periods (e.g., through registry settings, plist files, or system preferences), without requiring scripting or data analytics.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is based on inspecting the configuration model of the devices, such as examining settings in operating systems or management tools, to determine compliance with the timeout requirements, without needing active probing or analysis of event logs.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Identify and enumerate assets within GV1 that support automatic session locking due to inactivity (M1)",
            "Use GV5 to identify and enumerate assets from Operation 1 with authorized software installed (M2)",
            [
                "Check the configurations for the software using GV3:",
                [
                    "For general computing assets, enumerate those assets with properly configured automatic session locking (15 minutes or less) (M3)",
                    "For general computing assets, enumerate those assets with improperly configured automatic session locking (greater than 15 minutes) (M4)",
                    "For mobile assets, enumerate those assets with properly configured automatic session locking (2 minutes or less) (M5)",
                    "For mobile assets, enumerate those assets with improperly configured automatic session locking (greater than 2 minutes) (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured for automatic session locking.",
                "measure.description": [
                    "M3 = Count of general computing assets with properly configured automatic session locking",
                    "M5 = Count of mobile assets with properly configured automatic session locking",
                    "M1 = Count of assets capable of supporting automatic session locking"
                ],
                "measure.id": [
                    "M3",
                    "M5",
                    "M1"
                ],
                "equation": "(M3 + M5) / M1"
            }
        ]
    },
    {
        "Observable": "Firewall configuration files, system logs indicating firewall status, and presence of firewall software on servers.",
        "Class": [
            "Checklist",
            "Verifiable"
        ],
        "Class.explanation": "Checklist: Can be automated with scripts to check for firewall installation and basic settings. Verifiable: Configurations can be verified against security policies through manual or automated checks.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Use configuration data to assess if firewalls are implemented and configured correctly. Active testing: Perform tests to verify that the firewall is effectively blocking unauthorized access.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Identify and enumerate servers capable of hosting a firewall using GV1 (M1)",
            "Identify and enumerate applications capable of hosting a firewall using GV5 (M2)",
            [
                "Using configuration standards GV3 to check if firewalls are properly configured:",
                [
                    "Enumerate servers from Operation 1 with properly configured firewalls (M3)",
                    "Enumerate servers from Operation 1 with improperly configured firewalls (M4)",
                    "Enumerate applications from Operation 2 with properly configured firewalls (M3)",
                    "Enumerate applications from Operation 2 with improperly configured firewalls (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured firewalls within the enterprise",
                "measure.description": [
                    "M3 = Count of servers with properly configured firewalls",
                    "M5 = Count of applications with properly configured firewalls",
                    "M1 = Count of servers enterprise assets capable of hosting a firewall",
                    "M2 = Count of applications of hosting a firewall"
                ],
                "measure.id": [
                    "M3",
                    "M5",
                    "M1",
                    "M2"
                ],
                "equation": "(M3 + M5) / (M1 + M2)"
            }
        ]
    },
    {
        "Observable": "Configuration settings of host-based firewalls on end-user devices (e.g., rule sets, status), logs of firewall activities (e.g., traffic allowed or denied), presence of firewall software, and management tool configurations.",
        "Class": "Verifiable, Checklist",
        "Class.explanation": "This safeguard is verifiable because the firewall configuration can be inspected on each device to confirm the default-deny rule and explicitly allowed ports. It is checklist because a script or manual process can check for the presence and basic configuration of the firewall on all devices.",
        "Evaluation_Method": "Model-based, Active testing",
        "Evaluation_Method.explanation": "Model-based evaluation involves examining the firewall configuration files or settings to verify rules. Active testing involves probing the firewall with test traffic to ensure unauthorized traffic is dropped and allowed traffic passes.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Identify and enumerate end-user devices capable of hosting a firewall or a deny rule using GV1 (M1)",
            [
                "Using configuration standards GV3 to check if firewalls or deny rules are properly configured on end-user devices:",
                [
                    "Enumerate assets from Operation 1 with properly configured firewalls or a configured default deny rule (M3)",
                    "Enumerate assets from Operation 1 with improperly configured firewalls and lacking a configured default deny rule (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured firewalls or deny rule on end-user devices",
                "measure.description": [
                    "M2 = Count of end-user devices with a properly configured firewall or default deny rule",
                    "M1 = Count of end-user devices capable of hosting a firewall"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Presence of Infrastructure-as-Code (IaC) management tools and repositories, configuration files, access logs showing use of secure protocols (SSH, HTTPS) for administrative interfaces, and absence of insecure protocol (Telnet, HTTP) usage where not operationally essential.",
        "Class": [
            "Verifiable",
            "Checklist",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because system configurations for IaC and protocol settings can be checked; Checklist because automated scripts can verify protocol configurations and IaC usage; Measurable because proportions of secure management and protocol usage can be quantified from data.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based by examining system configurations and IaC definitions; Active testing by probing interfaces to detect protocol usage; Data-driven by analyzing access logs and management data to measure compliance.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Using GV5, identify and enumerate authorized management software (M1)",
            "Using GV1, identify and enumerate assets capable of supporting management software (M2)",
            "Using the output of Operations 1 and 2, identify and enumerate assets with authorized management software installed (M3)",
            [
                "Using configuration standards GV3 to check if management software is configured properly:",
                [
                    "Enumerate assets from Operation 3 with properly configured management software (M4)",
                    "Enumerate assets from Operation 1 with improperly configured management software (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets with properly configured authorized management software",
                "measure.description": [
                    "M4 = Count of assets with properly configured management software",
                    "M2 = Count of enterprise assets capable of supporting management software"
                ],
                "measure.id": [
                    "M4",
                    "M2"
                ],
                "equation": "M4 / M2"
            }
        ]
    },
    {
        "Observable": "The enabled/disabled status of default accounts (e.g., root, administrator), configuration settings indicating account management (e.g., account disable flags), and audit logs of account disablement or modification actions.",
        "Class": [
            "Checklist",
            "Verifiable"
        ],
        "Class.explanation": "Checklist because automated scripts can be used to inventory and check the status of default accounts; Verifiable because system configurations can be inspected to confirm if accounts are disabled or managed as required.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based because we can use configuration data and models to evaluate compliance with account management policies; Active testing because we can probe accounts by attempting authentication to test if they are disabled or unusable.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV20: Unique Password Policy"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate authorized operating software, applications, and third-party software that contain default accounts (M1)",
            "Use GV1 to identify and enumerate assets with software from Operation 1, installed (M2)",
            "For each asset identified in Operation 2, enumerate default accounts (M3)",
            [
                "Check if default accounts can be disabled:",
                [
                    "Enumerate accounts that are disabled (M4)",
                    "Enumerate accounts that are enabled (M5)"
                ]
            ],
            [
                "If accounts cannot be disabled, ensure to change default passwords according to GV20: the enterprise's unique password policy:",
                [
                    "Enumerate accounts with changed passwords (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of default accounts that have been rendered unusable",
                "measure.description": [
                    "M4 = Count of default accounts that have been disabled",
                    "M6 = Count of enabled default accounts with changed passwords",
                    "M3 = Count of default accounts identified"
                ],
                "measure.id": [
                    "M4",
                    "M6",
                    "M3"
                ],
                "equation": "M4 + M6 / M3"
            }
        ]
    },
    {
        "Observable": "If the safeguard is enforced, unnecessary services are uninstalled or disabled on enterprise assets, observable through system configuration checks, service status logs, or asset management tools showing disabled or absent services.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by inspecting the configuration of services on devices, such as checking service status in operating systems or configuration management systems, to ensure unnecessary services are not enabled, which aligns with verifiable class as it involves configuration checks without extensive data analytics.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation involves examining the model of the system configuration, i.e., the current state of services on devices, to determine if unnecessary services are disabled or uninstalled, which is model-based as it relies on configuration data rather than active probing or data-driven analytics.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate authorized services (M1)",
            "Use GV1 to identify and enumerate services on enterprise assets (M2)",
            [
                "Compare outputs from Operations 1 and 2:",
                [
                    "Identify and enumerate authorized services on assets (M3)",
                    "Identify and enumerate unauthorized services on assets (M4)"
                ]
            ],
            [
                "For authorized services in Operation 3.2, use GV3 to check configurations:",
                [
                    "Identify and enumerate services that are configured correctly (disabled) (M5)",
                    "Identify and enumerate services that are configured improperly (enabled) (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of services installed/running that are enterprise essential",
                "measure.description": [
                    "M3 = Count of authorized services on assets",
                    "M5 = Count of unauthorized services that are disabled",
                    "M2 = Count of services on enterprise assets"
                ],
                "measure.id": [
                    "M3",
                    "M5",
                    "M2"
                ],
                "equation": "(M3 + M5) / M2"
            }
        ]
    },
    {
        "Observable": "DNS server configuration settings on network infrastructure devices, including the IP addresses of configured DNS servers and whether they match a list of trusted DNS servers (e.g., enterprise-controlled or reputable external ones).",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by inspecting the configuration settings of network devices, such as routers or switches, to confirm if DNS servers are set to trusted IP addresses. It does not require data-driven analytics or active probing; instead, it relies on checking static configurations, which can be done through manual audits or automated scripts.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is based on the configuration model of the network devices. By examining the configured DNS server IPs against a predefined whitelist of trusted DNS servers, we can assess compliance without generating statistics from logs or performing active tests. This approach uses the system's configuration data to determine enforcement.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate authorized DNS servers (M1)",
            "Use GV1 to identify and enumerate assets configured for authorized DNS servers (M2)",
            [
                "Use GV3 to check the configuration of DNS servers identified on assets in Operation 2:",
                [
                    "Identify and enumerate assets with DNS servers that are properly configured (M3)",
                    "Identify and enumerate assets with DNS servers that are improperly configured (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets with properly configured DNS servers",
                "measure.description": [
                    "M3 = Count of assets with properly configured DNS servers",
                    "M2 = Count of enterprise assets configured for DNS servers"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Configuration settings for device lockout policies (e.g., enablement status and threshold values in management tools like Microsoft InTune or Apple Configuration Profiles), logs of failed authentication attempts, and lockout events on portable end-user devices.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by inspecting the device configuration settings to ensure that automatic lockout is enabled with the correct thresholds for failed authentication attempts, which can be done through scripting or manual checks of system configurations.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation is based on examining the configuration models of devices, such as those managed by tools like InTune or Apple profiles, to confirm that lockout policies are set according to the specified thresholds, without needing active probing or extensive data analysis.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate all portable devices (M1)",
            [
                "Use GV3 to check failed authentication configuration for all portable devices:",
                [
                    "Identify and enumerate failed authentication on laptops that are properly configured (20 failed attempts or less) (M2)",
                    "Identify and enumerate failed authentication on laptops that are not properly configured (greater than 20 failed attempts) (M3)",
                    "Identify and enumerate failed authentication on mobile devices that are properly configured (10 failed attempts or less) (M4)",
                    "Identify and enumerate failed authentication on mobile devices that are not properly configured (greater than 10 failed attempts) (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of portable devices with properly configured failed authentication.",
                "measure.description": [
                    "M2 = Count of properly configured laptops",
                    "M4 = Count of properly configured mobile devices",
                    "M1 = Count of portable devices"
                ],
                "measure.id": [
                    "M2",
                    "M4",
                    "M1"
                ],
                "equation": "(M2 + M4) / M1"
            }
        ]
    },
    {
        "Observable": "Logs and records of remote wipe commands, confirmation of data wipes, MDM (Mobile Device Management) configuration settings, and event reports for devices being lost, stolen, or users departing.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the presence and configuration of remote wipe systems can be checked through administrative interfaces and system settings. Measurable because the execution, frequency, and success of wipe operations can be quantified and analyzed from event logs and data records.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven evaluation utilizes statistics from wipe event logs, success rates, and timeliness data. Model-based evaluation involves assessing the configuration, policies, and setup of the remote wipe system in MDM or similar tools.",
        "Inputs": [
            [
                "GV21: Portable End-User Devices",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV21 to identify and enumerate portable end-user devices that support remote wipe (M1)",
            [
                "Use GV3 to check configuration for remote wipe on portable devices capable of supporting as identified in Operation 1:",
                [
                    "Identify and enumerate portable devices with properly configured remote wipe (M2)",
                    "Identify and enumerate portable devices with improperly configured remote wipe (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of portable devices with properly configured remote wipe.",
                "measure.description": [
                    "M2 = Count of properly configured portable devices",
                    "M1 = Count of portable devices capable of supporting remote wipe"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The configuration status of mobile devices indicating if a separate enterprise workspace is enabled, such as work profile settings, MDM configuration logs, or the presence of enterprise applications in isolated containers.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by checking the configuration of mobile devices through Mobile Device Management (MDM) systems or device settings to confirm if a work profile or similar separation is implemented, as it involves inspecting system configurations rather than scripting or data analytics.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation can be done by examining the configuration models of mobile devices, such as reviewing MDM policies, device configuration profiles (e.g., Apple Configuration Profile or Android Work Profile), to ensure that separate workspaces are set up correctly, without requiring data-driven statistics or active probing.",
        "Inputs": [
            [
                "GV21: Portable End-User Devices",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate authorized mobile device management software (M1)",
            "Use GV21 to identify mobile devices capable of supporting mobile device management software (M2)",
            [
                "Compare the output of Operations 1 and 2:",
                [
                    "Identify and enumerate mobile devices with authorized mobile device management software (M3)",
                    "Identify and enumerate mobile devices without authorized mobile device management software (M4)"
                ]
            ],
            [
                "Use GV3 to check configurations of mobile devices with mobile device management software:",
                [
                    "Identify and enumerate mobile devices with properly configured mobile device management software to separate enterprise workspace (M5)",
                    "Identify and enumerate mobile devices with improperly configured mobile device management software (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of mobile devices with properly separated enterprise workspace.",
                "measure.description": [
                    "M5 = Count of assets with properly configured mobile device management software",
                    "M2 = Count of mobile devices capable of supporting mobile device management software"
                ],
                "measure.id": [
                    "M5",
                    "M2"
                ],
                "equation": "M5 / M2"
            }
        ]
    },
    {
        "Observable": "An account inventory containing details such as person's name, username, start/stop dates, department for all user, administrator, and service accounts, along with records of validation checks for authorization performed at least quarterly.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the inventory's existence and configuration can be checked against system settings and databases. Measurable because data analytics can be used to assess completeness, metadata quality, and validation frequency and effectiveness.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because evaluation requires analyzing statistics from inventory data and validation logs. Model-based because it involves verifying the configuration and setup of the inventory system to ensure it meets requirements.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV22: Inventory of Accounts",
                "Date of last review of the inventory of accounts"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise maintains an inventory of user and administrative accounts (Input 2):",
                [
                    "If the inventory exists, M1 = 1",
                    "If the inventory does not exist, M1 = 0"
                ]
            ],
            [
                "Using the inventory of accounts GV22, determine if the inventory captures the following elements: person's name, username, start/stop dates, and department:",
                [
                    "Each element is assigned a value of 1 if it exists and 0 if it does not. Total the number of elements that exist (M3)."
                ]
            ],
            [
                "Using GV22, check each account for elements: person's name, username, start/stop dates, and department:",
                [
                    "Identify and enumerate accounts with all elements (M4)",
                    "Identify and enumerate accounts missing or with incomplete elements (M5)"
                ]
            ],
            "Use GV5 to identify authentication systems or other software that manages accounts GV23.",
            "Using the output of Operation 4, enumerate all current user and administrative accounts throughout the enterprise (M6)",
            [
                "Compare the output of Operation 5 with GV22:",
                [
                    "Identify and enumerate accounts that are supposed to be active/enabled (M7)",
                    "Identify and enumerate accounts that are supposed to be disabled/removed (M8)"
                ]
            ],
            "Compare the current date to the date provided in Input 3 and enumerate the timeframe in months (M9)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score, and other metrics don't apply.",
                "If M9 is greater than three, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of minimum elements included in the inventory.",
                "measure.description": [
                    "M3 = Count of elements provided in the inventory"
                ],
                "measure.id": [
                    "M3"
                ],
                "equation": "M3 / 4"
            }
        ]
    },
    {
        "Observable": "Password policy configurations in identity management systems, MFA settings, authentication logs, password compliance records, and account statuses.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because password policies and MFA settings can be checked directly in system configurations (e.g., Active Directory or IAM systems). Measurable because assessing password uniqueness and compliance with length requirements requires data-driven analysis from logs, audits, and user account data.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves verifying configuration settings and policies in identity management systems. Data-driven evaluation requires collecting and analyzing data from authentication logs, password audits, and account databases to measure compliance and uniqueness.",
        "Inputs": [
            [
                "GV20: Unique Password Policy"
            ]
        ],
        "Operations": [
            "Check if the enterprise has a unique password policy GV20:",
            "If the policy is available, M1 = 1",
            "Otherwise M1 = 0",
            "Review the policy and determine whether it includes password guidance for accounts without MFA:",
            [
                "If guidance is included, M2 = 1",
                [
                    [
                        "Does guidance, at a minimum, require a fourteen-character password:",
                        [
                            "If password guidance is fourteen characters or longer, M3 = 1",
                            "Otherwise M3 = 0"
                        ]
                    ]
                ]
            ],
            "Otherwise M2 = 0",
            "Review the policy and determine whether it includes password guidance for accounts with MFA:",
            [
                "If guidance is included, M4 = 1",
                [
                    "Does guidance, at a minimum, require an eight-character password:",
                    "If password guidance is eight characters or longer, M5 = 1",
                    "Otherwise M5 = 0"
                ]
            ],
            "Otherwise M4 = 0"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, the Safeguard receives a failing score. Other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of completeness of the unique password policy",
                "measure.description": [
                    "M2 = Does guidance exist for accounts without MFA?",
                    "M4 = Does guidance exist for accounts with MFA?"
                ],
                "measure.id": [
                    "M2",
                    "M4"
                ],
                "equation": "(M2 + M4) / 2"
            }
        ]
    },
    {
        "Observable": "Account lists with last login timestamps, logs of account disablement or deletion actions, and identity management system configurations showing account status and policies.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the enforcement can be checked by verifying system configurations and logs for account management policies. Measurable because it requires quantitative analysis of inactivity periods and disablement actions over time.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because assessment involves generating statistics from event logs and user activity data to determine inactivity and actions. Model-based because it can involve checking configuration settings in identity management systems for account policies.",
        "Inputs": [
            [
                "GV22: Inventory of Accounts",
                "Enterprise-defined policy for dormant threshold"
            ]
        ],
        "Operations": [
            "Review Input 2 and note the dormant threshold in terms of days (M2).",
            [
                "For each account in GV22, query the interface and collect:",
                [
                    "The date of the last activity for each account.",
                    "Whether the account is disabled or not."
                ]
            ],
            [
                "Using the output of Operation 2.1 and Input 2:",
                [
                    "Identify and enumerate accounts that have exceeded the dormant threshold (M3).",
                    "Identify and enumerate accounts that are still within the dormant threshold (M4)."
                ]
            ],
            [
                "Use the output of Operation 2.2 and 3.1 (M3):",
                [
                    "Identify and enumerate accounts that are disabled (M5).",
                    "Identify and enumerate accounts that are still enabled (M6)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of dormant accounts still included in the inventory.",
                "measure.description": [
                    "M6 = Count of dormant accounts still enabled",
                    "M1 = Count of accounts in GV22"
                ],
                "measure.id": [
                    "M6",
                    "M1"
                ],
                "equation": "M6 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration of user accounts showing privilege levels (e.g., admin vs. non-privileged), activity logs indicating which account is used for specific actions like web browsing, email, or administrative tasks, and evidence of policy enforcement such as account separation.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because account configurations and privilege settings can be directly inspected through system audits or configuration checks. Measurable because compliance can be quantified by analyzing activity logs to determine the frequency of correct account usage for general versus administrative activities.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves examining the configuration of accounts and policies to ensure dedicated admin accounts are set up. Data-driven evaluation uses logs of user activities to analyze patterns and measure adherence to the safeguard, such as counting activities from appropriate accounts.",
        "Inputs": [
            [
                "GV22: Inventory of Accounts",
                "List of users identified as administrators"
            ]
        ],
        "Operations": [
            [
                "Using GV22 and Input 2:",
                [
                    "Identify and enumerate users identified as administrators with active administrator accounts (M1).",
                    "Identify and enumerate users identified as administrators without active administrator accounts (M2).",
                    "Identify and enumerate users not identified as administrators with active administrator accounts (M3)."
                ]
            ],
            [
                "Using GV22 and the output of Operation 1.1:",
                [
                    "Identify and enumerate users identified as administrators that have an active non-administrator account (M4).",
                    "Identify and enumerate users identified as administrators that do not have an active non-administrator account (M5)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of administrator users with both an administrator account and a non-administrator account.",
                "measure.description": [
                    "M4 = Count of authorized administrator users with an active administrator and non-administrator account",
                    "M6 = Count of Input 2"
                ],
                "measure.id": [
                    "M4",
                    "M6"
                ],
                "equation": "M4 / M6"
            }
        ]
    },
    {
        "Observable": "The maintained inventory of service accounts with metadata including department owner, review date, and purpose, along with audit logs of review activities and records of account status changes.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the inventory's existence, configuration, and metadata completeness can be checked against system settings and policies; Measurable because quantitative metrics such as inventory completeness and review frequency can be derived from data analysis.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based for assessing the configuration of the inventory system and policy adherence; Data-driven for analyzing event logs, review records, and account data to compute enforcement metrics.",
        "Inputs": [
            [
                "GV23: Inventory of Authentication and Authorization Systems ",
                "Inventory of Service Accounts",
                "Date of last review of the inventory of service accounts"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise maintains an inventory of service accounts (Input 2):",
                [
                    "If the inventory exists, set M1 = 1.",
                    "If the inventory does not exist, set M1 = 0."
                ]
            ],
            [
                "Using the inventory of accounts (Input 2), determine if the inventory captures the following elements: department owner, review date, and purpose:",
                [
                    "Each element is assigned a value of 1 if it exists and 0 if it does not. Total the number of elements that exist (M3)."
                ]
            ],
            [
                "Using Input 2, check each account for elements: department owner, review date, and purpose:",
                [
                    "Identify and enumerate accounts with all elements (M4).",
                    "Identify and enumerate accounts missing or with incomplete elements (M5)."
                ]
            ],
            "Use GV23 to identify authentication systems or other software that manages service accounts.",
            "Using the output of Operation 4, enumerate all current service accounts throughout the enterprise (M6).",
            [
                "Compare the output of Operation 5 with Input 2:",
                [
                    "Identify and enumerate accounts that are supposed to be active/enabled (M7).",
                    "Identify and enumerate accounts that are supposed to be disabled/removed (M8)."
                ]
            ],
            "Compare the current date to the date provided in Input 3 and enumerate the timeframe in months (M9)."
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score and other metrics don't apply.",
                "If M9 is greater than three, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of minimum elements included in the inventory.",
                "measure.description": [
                    "M3 = Count of elements provided in inventory"
                ],
                "measure.id": [
                    "M3"
                ],
                "equation": "M3 / 4"
            }
        ]
    },
    {
        "Observable": "Logs of account management activities, configuration settings of directory or identity services (e.g., Active Directory, LDAP), integration status of systems with the centralized service, and user provisioning records.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of directory services can be checked through system settings and scripts. Measurable because data on account management (e.g., counts and logs) can be analyzed to assess the degree of centralization.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves verifying system configurations and integration settings. Data-driven evaluation requires analyzing logs, account counts, and audit events to measure centralization effectiveness.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory"
            ]
        ],
        "Operations": [
            "Using GV1 identify and enumerate centralized authentication points (M1)",
            [
                "For each centralized authentication point identified in Operation 1, determine whether it is necessary or can be consolidated:",
                [
                    "Identify and enumerate authentication points that are unnecessary or can be consolidated (M2)",
                    "Identify and enumerate authentication points that are necessary and cannot be consolidated (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "Percentage of properly centralized authentication points.",
                "measure.description": [
                    "M3 = Count of necessary centralized authentication points",
                    "M1 = Count of centralized authentication points in the enterprise"
                ],
                "measure.id": [
                    "M3",
                    "M1"
                ],
                "equation": "M3 / M1"
            }
        ]
    },
    {
        "Observable": "Documented access grant process, automation configuration in identity management systems, access logs, user change records, and policy documents",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence of documentation and system configuration for automation can be checked through audits or reviews. Measurable because the rate of process adherence and automation can be calculated from data such as access logs and user activity records.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven evaluation uses statistics from access logs and user activity data to measure adherence and automation rates. Model-based evaluation involves checking the configuration of identity management systems to verify automation settings and documentation existence.",
        "Inputs": [
            [
                "Enterprise process for granting access to enterprise assets"
            ]
        ],
        "Operations": [
            [
                "Check to see if Input 1 exists:",
                [
                    "If the enterprise has an access granting process, M1 = 1",
                    "If the enterprise does not have an access granting process, M1 = 0"
                ]
            ],
            [
                "Using Input 1, check to see if the process includes, at a minimum, a way to grant access upon new hire, rights grat, and role change of a user:",
                [
                    "For each element that is included, assign a value of 1. Sum the value of the elements included. (M2)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, the Safeguard receives a failing score. The other metric don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of elements included in the access granting process",
                "measure.description": [
                    "M2 = Count of elements included in the access granting process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "Documented process for access revocation, automated disablement scripts or tools, logs of account disablement actions, timestamps indicating when accounts were disabled relative to termination or role change events, audit trails showing disabled accounts.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and configuration of the process can be checked through system audits and documentation reviews. Measurable because the effectiveness, timeliness, and compliance of access revocation can be quantified using data from logs and events.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because analysis of event logs, timestamps, and account status changes provides statistical insights into disablement patterns. Model-based because the process configuration, automation settings, and documentation can be verified against established models or policies.",
        "Inputs": [
            [
                "Enterprise process for revoking access to enterprise assets"
            ]
        ],
        "Operations": [
            [
                "Check to see if Input 1 exists:",
                [
                    "If the enterprise has an access revoking process, set M1 = 1.",
                    "If the enterprise does not have an access revoking process, set M1 = 0."
                ]
            ],
            [
                "Using Input 1, check to see if the process includes, at a minimum, a way to revoke access upon termination, rights revocation, and role change of a user:",
                [
                    "For each element that is included, assign a value of 1. Sum the value of the elements included (M2)."
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, the Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of elements included in the access granting process",
                "measure.description": [
                    "M2 = Count of elements included in the access revoking process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "MFA configuration settings on externally-exposed applications, integration with directory services or SSO for MFA enforcement, and authentication logs indicating MFA usage.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be verified by inspecting the configuration of applications and identity providers to ensure MFA is enabled where supported, as it involves checking system settings and policies without requiring extensive data analysis or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Model-based evaluation is used because it involves examining the configuration models and policies of applications and identity providers to determine if MFA is enforced as required, relying on system configuration checks rather than data logs or active tests.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV22: Inventory of Accounts",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate externally exposed and third-party applications.",
            "Using the output of Operation 1 and GV22, identify and enumerate all user accounts associated with the applications (M1).",
            [
                "For each account identified in Operation 2, use GV3 to:",
                [
                    "Identify and enumerate accounts properly configured to require MFA (M2).",
                    "Identify and enumerate accounts not properly configured to require MFA (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of externally exposed and third-party application accounts properly configured for MFA",
                "measure.description": [
                    "M2 = Count of accounts properly configured to require MFA",
                    "M1 = Count of accounts associated with externally exposed and third-party applications"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings in remote access systems (e.g., VPN, RDP gateways) requiring MFA, authentication logs showing MFA challenges and successes for remote access, user account settings indicating MFA enrollment for remote access.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be verified by inspecting the configuration of remote access systems and identity providers to confirm that MFA is required for network access, as it involves checking system settings rather than requiring complex data analysis or active probing alone.",
        "Evaluation_Method": "Model-based, Data-driven, Active testing",
        "Evaluation_Method.explanation": "Model-based: Evaluation involves analyzing configuration models of systems to ensure MFA is enforced. Data-driven: Statistics from authentication logs and event data are used to compute enforcement rates. Active testing: Probing the remote access endpoints by attempting access without MFA to verify blocking behavior.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Using GV1 as a guide, identify and enumerate all authorized remote assets (M1).",
            [
                "For each asset identified in Operation 1, check configurations GV3:",
                [
                    "Identify and enumerate assets properly configured to require MFA (M2).",
                    "Identify and enumerate assets not properly configured to require MFA (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of remote assets properly configured to require MFA",
                "measure.description": [
                    "M2 = Count of remote assets properly configured to require MFA",
                    "M1 = Count of remote assets"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "MFA configuration settings for administrative accounts in identity management systems, authentication event logs showing MFA usage, and list of enterprise assets with MFA support capabilities",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because MFA settings can be inspected and confirmed through system configurations such as IAM policies. Measurable because enforcement and usage can be quantified through data analysis of authentication logs and account settings.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves examining configuration models of identity and access management systems to verify MFA requirements. Data-driven evaluation uses authentication log data and event statistics to assess actual MFA usage and compliance.",
        "Inputs": [
            [
                "GV22: Inventory of Accounts ",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Using GV22, identify and enumerate all administrative accounts (M1).",
            [
                "For each administrative account identified in Operation 1, check configurations in GV3:",
                [
                    "Identify and enumerate administrative accounts properly configured to require MFA (M2).",
                    "Identify and enumerate administrative accounts not properly configured to require MFA (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of administrative accounts properly configured to require MFA",
                "measure.description": [
                    "M2 = Count of administrative accounts properly configured to require MFA",
                    "M1 = Count of administrative accounts "
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Inventory document or database listing authentication and authorization systems, logs of review and update activities, and records from discovery tools.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the inventory's existence and content can be checked against system configurations and logs; Measurable because the coverage ratio and review frequency can be quantified using data analytics.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because evaluation requires analyzing data from inventory logs, discovery tools, and timestamps; Model-based because it involves comparing the inventory against a conceptual model of expected authentication and authorization systems.",
        "Inputs": [
            [
                "GV23: Inventory of Authentication and Authorization Systems",
                "GV5: Authorized Software Inventory",
                "Date of last update to the authentication and authorization system inventory"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise maintains a GV23 Authentication and Authorization System Inventory of all on-site and remote service providers:",
                [
                    "If the inventory exists, M1 = 1.",
                    "If the inventory does not exist or is not provided, M1 = 0."
                ]
            ],
            "Use GV5 to identify and enumerate authorized authentication and authorization systems within the enterprise.",
            [
                "Use the output of Operation 2 to compare to the existing inventory GV23:",
                [
                    "Identify and enumerate systems that are authorized and currently in the inventory (M2).",
                    "Identify and enumerate systems that are authorized and not currently in the inventory (M3).",
                    "Identify and enumerate systems that are not authorized but listed in the current inventory (M4)."
                ]
            ],
            "Compare the date of Input 3 to the current date and capture the timeframe in months (M6)."
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M6 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "What percentage of the authorized authentication and authorization systems are accounted for in the current enterprise inventory?",
                "measure.description": [
                    "M2 = Count of authorized and properly inventoried systems",
                    "M5 = Count of systems in the current inventory GV23"
                ],
                "measure.id": [
                    "M2",
                    "M5"
                ],
                "equation": "M2 / M5"
            }
        ]
    },
    {
        "Observable": "Configuration settings of a central directory service or SSO provider, integration status of enterprise assets with the central service, and logs of access control events indicating centralized authentication and authorization.",
        "Class": "Verifiable, Checklist",
        "Class.explanation": "Verifiable because the enforcement can be assessed by inspecting system configurations to confirm integration with the central service; Checklist because a list of assets can be used to systematically verify each one's integration status.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Model-based because the evaluation relies on examining the configuration models of enterprise assets to determine if they are set up to use the central directory service or SSO provider for access control.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV5 to identify all directory and SSO services.",
            "Use GV1 to identify and enumerate assets that support directory and SSO services (M1).",
            [
                "Check the output of Operations 1 and 2 to ensure each asset is covered by at least one directory or SSO service:",
                [
                    "Identify and enumerate assets that are covered by at least one directory or SSO service (M2).",
                    "Identify and enumerate assets that are not covered by at least one directory or SSO service (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets that can support directory and SSO service covered by at least one directory or SSO service.",
                "measure.description": [
                    "M2 = Count of assets covered by at least one directory or SSO    service",
                    "M1 = Count of assets capable of supporting directory and/or SSO    services"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Role definitions in identity management systems, documentation of access rights for each role (including department owner, review date, and purpose), logs of access control reviews, records of unauthorized privileges identified during reviews.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and correctness of role definitions and documentation can be checked by inspecting system configurations and policy documents. Measurable because the frequency and outcomes of access control reviews require data analysis to assess compliance and effectiveness.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation is used to verify the configuration of role-based access control systems by examining role definitions and access rights. Data-driven evaluation is used to analyze review logs, timestamps, and findings to measure review frequency and compliance rates.",
        "Inputs": [
            [
                "Enterprise documented process for assigning role-based access control",
                "GV22: Inventory of Accounts",
                "Date of last validation of role-based access control"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise has a process for assigning role-based access control:",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            [
                "Use GV22 and check if each account is assigned a role or group as outlined by the role-based access control process:",
                [
                    "Identify and enumerate accounts that are assigned a role or group (M3)",
                    "Identify and enumerate accounts that are not assigned a role or group (M4)"
                ]
            ],
            "Compare the date in Input 3 to the current date and capture the timeframe in months (M5)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M5 is greater than twelve months, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of account inventory with a properly assigned role or group.",
                "measure.description": [
                    "M3 = Count of accounts found in the inventory with assigned roles or groups",
                    "M2 = Count of GV22."
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "The documented vulnerability management process, including its existence, content, review dates, update records, and evidence of updates after significant enterprise changes.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be assessed by verifying the existence and details of the documentation through manual inspection or automated checks of document metadata, such as review and update timestamps.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation involves examining the configuration and properties of the documentation, which are part of the system's model, including document existence, review dates, update history, and integration with change management systems, without requiring active probing or extensive data analytics.",
        "Inputs": [
            [
                "Enterprise Vulnerability Management Process",
                "Date of the last update to the Vulnerability Management Process"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise maintains a vulnerability management process:",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            "Compare the date from Input 1 to the current date and enumerate the timeframe in months (M2)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M2 is greater than twelve, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "The documented remediation process, logs of review activities, and records of monthly reviews.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and content of the documentation can be confirmed through inspection; Measurable because the frequency and timeliness of reviews can be quantified and analyzed over time.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based as it involves evaluating the documented remediation strategy as a configuration item; Data-driven as it requires collecting and analyzing data on review timestamps and frequencies from logs.",
        "Inputs": [
            [
                "Enterprise Remediation Strategy Process",
                "Date of the last review of the process",
                "GV18: Enterprise assets storing, processing, and transmitting sensitive data"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise maintains a documented remediation process:",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            [
                "Check the documented remediation process to identify whether it includes a risk-based process based on the following elements: Sensitive assets GV18 and criticality of vulnerability:",
                [
                    "Each element, if included, gets a value of 1. Sum all elements (M2)"
                ]
            ],
            "Compare the date from Input 2 and the current date. Enumerate the timeframe in terms of days (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, the Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than thirty, the Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of elements included in the process",
                "measure.description": [
                    "M2 = Sum of elements included in the remediation process."
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 2"
            }
        ]
    },
    {
        "Observable": "Presence of automated patch management systems, logs of patch deployments, system update statuses, and timestamps of last updates for enterprise assets.",
        "Class": "Measurable",
        "Class.explanation": "This safeguard requires measuring the frequency and completeness of operating system updates, which involves data analysis from logs, reports, and system inventories to assess compliance, rather than just verifying configurations or using a checklist.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation involves collecting and analyzing data from patch management tools, event logs, and system inventories to generate statistics on update frequencies, automation coverage, and compliance rates, which is characteristic of a data-driven approach.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV1: Enterprise Asset Inventory",
                "Authoritative source of information indicating version details by product",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV5 to identify authorized operating systems within the enterprise.",
            "Use GV1 and the output of Operation 1 to identify the operating system currently running on each asset (M1).",
            [
                "For each asset, compare the version of the operating system to that listed in Input 4:",
                [
                    "Identify and enumerate operating systems that are up to date (M2).",
                    "Identify and enumerate operating systems that are not up to date (M3)."
                ]
            ],
            [
                "For each operating system identified in Operation 2.2, determine whether there is a documented exception:",
                [
                    "Identify and enumerate operating systems with a documented exception (M4).",
                    "Identify and enumerate operating systems without a documented exception (M5)."
                ]
            ],
            "Use GV5 to identify authorized automated patch management software (M6).",
            [
                "Compare the output of Operation 5 and Operation 1:",
                [
                    "Identify and enumerate operating systems covered by at least one automated patch management software (M7).",
                    "Identify and enumerate operating systems not covered by at least one automated patch management software (M8)."
                ]
            ],
            [
                "Check configurations of automated patch management software identified in Operation 5 using GV3:",
                [
                    "Identify and enumerate those configured to run every 30 days or less (M9).",
                    "Identify and enumerate those not configured to run every 30 days or less (M10)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percent of operating systems on an asset that is up-to-date",
                "measure.description": [
                    "M2 = Count of up-to-date operating systems installed on an asset.",
                    "M4 = Count of not up-to-date operating systems with a documented exception.",
                    "M1 = Count of the authorized operating systems installed on an asset."
                ],
                "measure.id": [
                    "M2",
                    "M4",
                    "M1"
                ],
                "equation": "(M2 + M4) / M1"
            }
        ]
    },
    {
        "Observable": "Automated patch management system configurations, patch deployment logs, application inventory with update status, and update schedules.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "This safeguard can be assessed through scripting to check if automated patch management is configured (Checklist), verifying system settings and configurations (Verifiable), and measuring update frequencies and compliance using data analytics (Measurable).",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation uses logs and data from patch management systems to analyze update frequencies and compliance; Model-based evaluation relies on configuration models to assess if automated patch management is properly set up; Active testing involves probing systems to test if updates are being applied as required.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV1: Enterprise Asset Inventory",
                "Authoritative source of information indicating version details by product",
                "GV3: Configuration Standard",
                "GV24: Authorized Automated Patch Management Software"
            ]
        ],
        "Operations": [
            "Use GV5 to identify authorized applications within the enterprise.",
            "Use GV1 and the output of Operation 1 to identify the applications currently running on each asset (M1).",
            [
                "For each asset, compare the version of the application to that listed in GV3:",
                [
                    "Identify and enumerate applications that are up to date (M2).",
                    "Identify and enumerate applications that are not up to date (M3)."
                ]
            ],
            [
                "For each application identified in Operation 2.2, determine whether there is a documented exception:",
                [
                    "Identify and enumerate applications with a documented exception (M4).",
                    "Identify and enumerate applications without a documented exception (M5)."
                ]
            ],
            [
                "Compare GV24 and Operation 1:",
                [
                    "Identify and enumerate applications covered by at least one automated patch management software (M7).",
                    "Identify and enumerate applications not covered by at least one automated patch management software (M8)."
                ]
            ],
            [
                "Check configurations of automated patch management software GV24 using GV3:",
                [
                    "Identify and enumerate those configured to run every 30 days or less (M9).",
                    "Identify and enumerate those not configured to run every 30 days or less (M10)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percent of applications on an asset that are up to date",
                "measure.description": [
                    "M2 = Count of up-to-date applications installed on an asset.",
                    "M4 = Count of not up to date applications with a documented exception.",
                    "M1 = Count of authorized applications installed on an asset."
                ],
                "measure.id": [
                    "M2",
                    "M4",
                    "M1"
                ],
                "equation": "(M2 + M4) / M1"
            }
        ]
    },
    {
        "Observable": "Vulnerability scan reports, logs of scan activities, and configuration settings of scanning tools indicating scan schedules and types.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of scanning tools can be checked for scheduled scans and scan types (e.g., cron jobs or tool settings). Measurable because actual scan data from logs can be analyzed to compute frequency, coverage, and types of scans.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven evaluation uses historical scan log data to assess scan frequency and coverage. Model-based evaluation checks the configured settings of scanning tools to verify intended scan schedules and types.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "Use the GV5authorized software inventory to:",
                [
                    "Identify and enumerate GV25 vulnerability scanning software (M1)",
                    "Identify and enumerate authenticated vulnerability scanning software (M2)"
                ]
            ],
            "Use the GV1 enterprise asset inventory to identify and enumerate all internal assets (M3)",
            [
                "Use the output of Operation 2 and Operation 1.1:",
                [
                    "Identify and enumerate internal assets covered by at least one vulnerability scanning software (M4)",
                    "Identify and enumerate internal assets not covered by at least one vulnerability scanning software (M5)"
                ]
            ],
            [
                "Use the output of Operation 2 and Operation 1.2:",
                [
                    "Identify and enumerate internal assets covered by at least one authenticated vulnerability scanner (M6)",
                    "Identify and enumerate internal assets not covered by at least one authenticated vulnerability scanner (M7)"
                ]
            ],
            [
                "Use the output of Operation 1.1 and GV3:",
                [
                    "Identify and enumerate vulnerability scanners properly configured to scan every 3 months or less (M8)",
                    "Identify and enumerate vulnerability scanners not properly configured to scan every 3 months or less (M9)"
                ]
            ],
            [
                "Use the output of Operation 1.2 and GV3:",
                [
                    "Identify and enumerate authenticated vulnerability scanners properly configured to scan every 3 months or less (M10)",
                    "Identify and enumerate authenticated vulnerability scanners not properly configured to scan every 3 months or less (M11)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of internal assets covered by a vulnerability scanner",
                "measure.description": [
                    "M4 = Count of internal assets covered by a vulnerability scanner.",
                    "M3 = Count of internal enterprise assets."
                ],
                "measure.id": [
                    "M4",
                    "M3"
                ],
                "equation": "M4 / M3"
            }
        ]
    },
    {
        "Observable": "Scan reports or logs showing automated vulnerability scans performed on externally-exposed assets, including timestamps of scans and lists of assets covered.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": {
            "Checklist": "Automated scripts can check for the existence and execution of scan jobs by verifying logs or scheduling systems.",
            "Verifiable": "The configuration of vulnerability scanning tools can be inspected to ensure they are set up correctly for external assets.",
            "Measurable": "Data from scan logs and results can be quantified to assess frequency, coverage, and compliance with scanning policies."
        },
        "Evaluation_Method": [
            "Data-driven",
            "Active testing",
            "Model-based"
        ],
        "Evaluation_Method.explanation": {
            "Data-driven": "Evaluation involves analyzing statistics from scan logs, such as timestamps and asset coverage, to compute metrics like frequency and coverage.",
            "Active testing": "Vulnerability scans actively probe the externally-exposed assets to identify vulnerabilities, making this a form of active testing.",
            "Model-based": "The configuration models of scanning tools can be verified against policies to ensure proper setup and scheduling."
        },
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV25: Vulnerability Scanning Software",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use the GV1 enterprise asset inventory to identify and enumerate all external assets (M2)",
            [
                "Use the output of Operation 1 and GV25 to:",
                [
                    "Identify and enumerate external assets covered by at least one vulnerability scanning software (M3)",
                    "Identify and enumerate external assets not covered by at least one vulnerability scanning software (M4)"
                ]
            ],
            [
                "Use the GV25 and GV3 to:",
                [
                    "Identify and enumerate vulnerability scanners properly configured to scan every 30 days or less (M5)",
                    "Identify and enumerate vulnerability scanners not properly configured to scan every 30 days or less (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of external assets covered by a vulnerability scanner",
                "measure.description": [
                    "M3 = Count of external assets covered by a vulnerability scanner.",
                    "M2 = Count of external enterprise assets."
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Logs of vulnerability detections and remediations, including timestamps, status changes, and records from vulnerability management tools and processes.",
        "Class": "Measurable",
        "Class.explanation": "The safeguard requires quantifying the time between vulnerability detection and remediation to ensure it is within a monthly period, which involves measurement of numerical values such as counts and time intervals, rather than simple checklist verification or configuration checks.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation involves collecting and analyzing data from vulnerability management systems, such as event logs, scan reports, and remediation records, to compute statistics on remediation times and rates, which is characteristic of a data-driven approach.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "Current vulnerability scan",
                "Previous vulnerability scan",
                "Date of current vulnerability scan",
                "Date of the previous vulnerability scan"
            ]
        ],
        "Operations": [
            [
                "For each asset in GV1, compare Inputs 2 and 3:",
                [
                    "Identify and enumerate assets listed with the same vulnerability on both scans (M2)",
                    "Identify and enumerate assets previously found in Input 3 that are no longer listed in Input 2 with the same vulnerability (M3)"
                ]
            ],
            "Compare Inputs 4 and 5 and capture the timeframe between scans in days (M4)"
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of remediated vulnerabilities",
                "measure.description": [
                    "M3 = Count of remediated vulnerabilities",
                    "M1 = Count of vulnerabilities identified in Input 3"
                ],
                "measure.id": [
                    "M3",
                    "M1"
                ],
                "equation": "M3 / M1"
            }
        ]
    },
    {
        "Observable": "The documented audit log management process, including its content addressing collection, review, and retention of audit logs, as well as records of annual reviews and updates triggered by significant changes.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be verified by inspecting the documentation to ensure it exists, covers the required elements (collection, review, retention), and has evidence of reviews and updates, which can be done through manual checks or automated validation of document metadata.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is performed by reviewing the documented process model and associated records (e.g., document versions, review logs) to assess compliance with the requirements, without requiring active probing or statistical analysis of event data.",
        "Inputs": [
            [
                "GV26: Enterprise's Audit Log Management Process",
                "Date of the last review of the Audit Log Management Process"
            ]
        ],
        "Operations": [
            [
                "Check if GV26 the audit log management process exists:",
                [
                    "If it exists, M1 = 1",
                    "If it does not exist, M1 = 0"
                ]
            ],
            [
                "Review GV26 for elements of the process and, at a minimum, address the collection, review, and retention of audit logs for enterprise assets:",
                [
                    "For each element that exists, assign a value of 1. Sum the values of existing elements. (M2)",
                    "Identify and enumerate vulnerability scanners not properly configured to scan every 30 days or less (M6)"
                ]
            ],
            "Compare the date from Input 2 and the current date. Capture the timeframe in terms of months. (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of elements included in the audit log",
                "measure.description": [
                    "M2 = Count of elements included in the audit log management process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "Audit logs, configuration settings indicating logging enabled, and records from the audit log management process.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "The safeguard is verifiable through inspection of system configurations to check if logging is enabled, and measurable through analysis of log data volumes and coverage.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves checking the configuration models of assets to verify logging enablement. Data-driven evaluation involves analyzing audit log data to ensure collection and coverage.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard",
                "GV26: Enterprise's Audit Log Management Process"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets capable of supporting logging GV27 (M1):",
            [
                "Use GV26 and GV3 as guides to determine, for each asset identified in Operation 1, if it is configured to log events as outlined by the enterprise's process",
                [
                    "Identify and enumerate assets properly configured to log events per the process (M2)",
                    "Identify and enumerate assets not properly configured to log events per the process (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The ratio of logging-capable assets properly configured per the audit log management process.",
                "measure.description": [
                    "M2 = Count of properly configured assets to log events per the audit log management process",
                    "M1 = Count of assets capable of supporting logging"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Storage capacity settings and current usage data of logging destinations, such as configuration files, monitoring dashboards, and log files indicating storage status.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because storage adequacy can be checked by reviewing configuration settings of logging systems to ensure they meet policy requirements. Measurable because storage usage data can be collected and analyzed over time to assess compliance with the audit log management process.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven evaluation involves generating statistics from storage usage logs and monitoring data to track adequacy. Model-based evaluation uses the configured storage limits and policy requirements to model and verify compliance without active probing.",
        "Inputs": [
            [
                "GV27: Assets Capable of Supporting Logging",
                "GV26: Enterprise's Audit Log Management Process"
            ]
        ],
        "Operations": [
            "For each asset in GV27, collect the asset's logging configuration.",
            [
                "Compare the output of Operation 1 and the retention portion of G26:",
                [
                    "Identify and enumerate assets configured to comply with the retention portion of the process (M2).",
                    "Identify and enumerate assets not configured to comply with the retention portion of the process (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets compliant with the organization's logging policy",
                "measure.description": [
                    "M2 = Count of assets properly configured to meet retention requirements",
                    "M1 = Count of GV27 assets capable of supporting logging"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings for time synchronization sources on assets, logs from time synchronization services (e.g., NTP), status reports indicating time synchronization status and sources.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the presence and configuration of at least two time sources can be checked through system inspection of configuration files or settings. Measurable because the degree of synchronization (e.g., time drift) can be quantified using data from logs and monitoring tools.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves verifying configuration files or system settings to confirm the number of time sources configured. Data-driven evaluation uses statistics from time synchronization logs to measure synchronization accuracy and compliance over time.",
        "Inputs": [
            [
                "GV27: Assets Capable of Supporting Logging",
                "List of approved network time sources/NTP servers"
            ]
        ],
        "Operations": [
            "Using GV27, identify and enumerate assets capable of supporting time synchronization (M1):",
            [
                "Check the configurations of the assets identified in Operation 1:",
                [
                    "Identify and enumerate the assets configured using at least two approved time sources from Input 2 (M2)",
                    "Identify and enumerate the assets configured using time sources not on the approved list (M3)",
                    "Identify and enumerate the assets not configured using time sources (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured with at least two approved synchronized time sources",
                "measure.description": [
                    "M2 = Count of properly configured assets using at least two approved time sources",
                    "M1 = Count of logging-capable assets that support time synchronization"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Audit logs generated by enterprise assets containing sensitive data, including elements such as event source, date, username, timestamp, source addresses, destination addresses, and other forensic details, along with configuration settings for audit logging.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": [
            "Scripts can be used to automatically check if audit logging is configured with the required elements, such as by parsing configuration files or using command-line tools.",
            "System configuration can be verified manually or through automated checks to ensure audit logging is enabled and includes specified details like event source and timestamps.",
            "Log data must be analyzed using data-driven methods to assess the completeness and presence of required elements in the logs, which involves statistical analysis."
        ],
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": [
            "Evaluation relies on analyzing event log data to check for the presence and completeness of required elements, such as by aggregating and examining log entries.",
            "Evaluation uses the configuration model of the system, such as checking audit policy settings or configuration files, to verify if logging is properly set up.",
            "Evaluation involves probing the system by generating test events and checking if they are captured in the logs with all required details, ensuring functional logging."
        ],
        "Inputs": [
            [
                "GV18: Enterprise Assets Storing, Processing, and Transmitting Sensitive Data",
                "GV26: Enterprise's Audit Log Management Process",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "Review GV26 for detailed logging requirements such as event source, date, username, timestamp, source addresses, and destination addresses.",
                [
                    "For each detailed logging requirement included, assign a value of 1. Sum all requirements included. (M2)"
                ]
            ],
            [
                "For each asset in GV18 check configuration using GV3 as a guide",
                [
                    "Identify and enumerate assets properly configured to collect detailed logging requirements (M3)",
                    "Identify and enumerate assets not properly configured to collect detailed logging requirements (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of detailed logging requirements included in the logging management process",
                "measure.description": [
                    "M2 = Count of detailed logging requirements included in the log management process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 6"
            }
        ]
    },
    {
        "Observable": "DNS query audit logs being generated, stored, and the logging configuration on enterprise assets where supported.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard is verifiable because it can be assessed by examining the configuration settings of assets to confirm that DNS query logging is enabled where appropriate and supported, without necessarily requiring complex data analysis.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Data-driven evaluation is appropriate because assessing the collection of DNS query logs involves analyzing the actual log data to verify that logs are being captured, which is essential for detection purposes in security monitoring.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use Input 1 GV1 to identify and enumerate internal DNS Servers (M1)",
            [
                "Check the configurations GV3 of each DNS Server identified in Operation 1",
                [
                    "Identify and enumerate DNS servers properly configured to collect logs (M2).",
                    "Identify and enumerate DNS servers not properly configured to collect logs (M3)."
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured DNS servers to meet logging requirements",
                "measure.description": [
                    "M2 = Count of properly configured DNS servers",
                    "M1 = Count of internal DNS servers"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "URL request audit logs being collected on enterprise assets, and configuration settings indicating that URL request logging is enabled where supported.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because system configurations can be inspected to check if URL request logging is enabled on assets. Measurable because the volume, frequency, and coverage of log collection can be quantified and analyzed using data from logs.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves examining system configurations and settings to verify if URL request logging is enabled. Data-driven evaluation involves analyzing collected log data, such as the number of log entries and timestamps, to assess the effectiveness and completeness of log collection.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets that support URL logging\n    (M1)",
            [
                "For each asset identified in Operation 1, use GV3 to check configurations for URL logging",
                [
                    "Identify and enumerate assets properly configured for logging (M2)",
                    "Identify and enumerate assets not properly configured for logging (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured for URL logging",
                "measure.description": [
                    "M2 = Count of assets properly configured for URL logging",
                    "M1 = Count of assets capable of supporting URL logging"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Command-line audit logs being collected and stored in a centralized log management system or repository, visible through log entries from sources like PowerShell, BASH, and remote administrative terminals.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the configuration of logging can be checked on systems (e.g., registry settings in Windows, configuration files in Linux). Measurable because the actual log data needs to be analyzed for volume, coverage, and timeliness to assess enforcement quality.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven: Analyze collected logs to generate statistics on log volume and coverage. Model-based: Inspect system configurations to verify if logging is enabled and properly set up. Active testing: Execute command-line commands to probe systems and verify that logs are generated and collected.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets that support command-line auditing of command shells (M1)",
            [
                "For each asset identified in Operation 1, use GV3 to check configurations for command-line auditing of command shells",
                [
                    "Identify and enumerate assets properly configured (M2)",
                    "Identify and enumerate assets not properly configured (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured for command-line auditing of command shells",
                "measure.description": [
                    "M2 = Count of assets properly configured for command-line auditing of command shells",
                    "M1 = Count of assets capable of supporting command-line auditing of command shells"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Centralized audit log collection system (e.g., SIEM), logs being ingested from enterprise assets, configured retention policies in the system, documentation of the audit log management process, and evidence of log retention compliance.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the enforcement can be checked by inspecting system configurations, such as SIEM settings and log source integrations, against the documented process. Measurable because quantitative metrics like coverage percentages and compliance ratios can be derived from data counts and periods.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing log data, event volumes, and retention logs to assess centralization and compliance. Model-based evaluation involves reviewing configuration files, SIEM settings, and process documentation to verify adherence to the safeguard.",
        "Inputs": [
            [
                "GV27: Assets Capable of Supporting Logging",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use the software inventory GV5 to identify and enumerate log\n    aggregating software GV28",
            [
                "For each asset capable of supporting logging GV27, check if asset is covered by at least one log aggregating software",
                [
                    "Identify and enumerate assets covered by at least one aggregating software (M2)",
                    "Identify and enumerate assets not covered by at least one aggregating software (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of log-producing assets covered by aggregating software",
                "measure.description": [
                    "M2 = Count of assets covered by at least one aggregating software",
                    "M1 = Count of GV27"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Audit log files and their retention configurations across all enterprise assets, including log timestamps and policy settings.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the retention policy can be checked against system configurations (e.g., via scripts or manual inspection). Measurable because the actual retention duration needs to be calculated from log timestamps using data analysis.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves inspecting configured log retention policies in systems (e.g., checking settings in log management tools). Data-driven evaluation requires analyzing timestamps of audit logs to determine the actual retention duration (e.g., from event logs or database entries).",
        "Inputs": [
            [
                "GV28: Log Aggregating Software",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each log aggregating software GV28 use GV3 to check configuration standards",
                [
                    "Identify and enumerate aggregating software configured to retain logs for 90 days or more (M2)",
                    "Identify and enumerate aggregating software configured to retain logs for less than 90 days (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of aggregating software properly configured to retain logs for 90 days or more",
                "measure.description": [
                    "M2 = Count of aggregating software properly configured to retain    logs for 90 days or more",
                    "M1 = Count of log aggregating software GV28"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Audit logs being reviewed, records of review activities (including timestamps), and reports of detected anomalies or abnormal events.",
        "Class": [
            {
                "name": "Measurable",
                "explanation": "The safeguard involves measuring the frequency of reviews and the rate of anomaly detection from audit log data, requiring data-driven analytics rather than simple checklist or configuration verification."
            }
        ],
        "Class.explanation": "The safeguard involves measuring the frequency of reviews and the rate of anomaly detection from audit log data, requiring data-driven analytics rather than simple checklist or configuration verification.",
        "Evaluation_Method": [
            {
                "name": "Data-driven",
                "explanation": "Evaluation requires generating statistics from audit logs, review timestamps, and anomaly counts to assess compliance with the review frequency and detection effectiveness."
            }
        ],
        "Evaluation_Method.explanation": "Evaluation requires generating statistics from audit logs, review timestamps, and anomaly counts to assess compliance with the review frequency and detection effectiveness.",
        "Inputs": [
            [
                "Timestamp for two consecutive log reviews"
            ]
        ],
        "Operations": [
            "Compare each timestamp to determine the timeframe between log reviews in days (M1)"
        ],
        "Metric_as_text": [
            [
                "If M1 is greater than seven, this Safeguard is measured at a 0 and receives a failing score."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "Logs from service providers including authentication, authorization, data creation, data disposal, and user management events, as well as the configuration of log collection systems.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of log collection tools can be inspected to check if they are set up correctly. Measurable because the actual log data needs to be analyzed for volume, coverage, and timeliness to assess enforcement quality.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves examining the configuration models of log collection systems to verify settings. Data-driven evaluation involves generating statistics from log data, such as event counts and timestamps, to analyze compliance and effectiveness.",
        "Inputs": [
            [
                "GV29: Inventory of Service Providers",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "For each service provided in GV29 identify and enumerate service providers that support logging (M1)",
            [
                "Use service provider identified in Operation 1, use GV3 to check configurations",
                [
                    "Identify and enumerate service providers properly configured to collect logs (M2)",
                    "Identify and enumerate service providers not properly configured to collect logs (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of service providers properly configured to collect logs",
                "measure.description": [
                    "M2 = Count of service providers configured to collect logs",
                    "M1 = Count of service providers that support logging"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The inventory of browsers and email clients executing on enterprise assets, including their versions and comparison to vendor-provided lists of supported and latest versions.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be assessed by verifying the configuration of systems to ensure only supported and latest versions of browsers and email clients are installed, which involves checking software inventories and comparing them against vendor support lists, making it verifiable through configuration inspection.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Enforcement is evaluated by modeling the system's software inventory data against the list of supported versions provided by the vendor, using configuration-based assessment without the need for active probing or extensive data analysis from logs.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "Authoritative source of information indicating supported/unsupported    details by product"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate web browser and email client\n    software (M1)",
            [
                "Compare each software identified in Operation 1 to Input 2",
                [
                    "Identify and enumerate software labeled as \"supported\" that is currently supported (M2)",
                    "Identify and enumerate software labeled as \"supported\" that is currently unsupported (M3)",
                    "Identify and enumerate software labeled as \"unsupported\" that is currently unsupported (M4)",
                    "Identify and enumerate software labeled as \"unsupported\" that is currently supported (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of unsupported web browser and email client software in use",
                "measure.description": [
                    "M3 = Count of software labeled as \"supported\" and currently    unsupported",
                    "M4 = Count of software labeled as \"supported\" and currently    unsupported",
                    "M1 = Count of authorized web browser and email client software"
                ],
                "measure.id": [
                    "M3",
                    "M4",
                    "M1"
                ],
                "equation": "(M3 + M4) / M1"
            }
        ]
    },
    {
        "Observable": "DNS filtering configuration settings on end-user devices, DNS query logs showing blocked or allowed domains, reports from DNS filtering services indicating blocked access attempts, and lists of known malicious domains used for filtering.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist: Can be assessed through automated scripts that check DNS settings on devices. Verifiable: Can be verified by inspecting system configurations and service settings. Measurable: Requires data-driven analysis from logs to quantify blocking effectiveness and coverage.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven: Analyze DNS query logs and statistics to measure blocking rates and coverage. Model-based: Examine configuration models of devices to verify DNS filtering settings. Active testing: Probe the network by attempting to access known malicious domains and observe if they are blocked.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets that support DNS\n    filtering (M1)",
            "Use GV5 to identify and enumerate authorized DNS filtering\n    services",
            [
                "For each asset identified in Operation 1, check to see if it is configured properly GV3 to support authorized DNS filtering services from Operation 2",
                [
                    "Identify and enumerate assets properly configured (M2)",
                    [
                        "Identify and enumerate assets not properly configured (M3)",
                        [
                            "Identify and enumerate assets not properly configured (M3)"
                        ]
                    ]
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets configured to use authorized DNS filtering services",
                "measure.description": [
                    "M2 = Count of assets properly configured to support DNS filtering",
                    "M1 = Count of enterprise assets capable of supporting DNS filtering"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network traffic logs indicating blocked and allowed URL connections, configuration settings of URL filtering systems (e.g., firewall rules, proxy settings), and records of filter list updates (e.g., update timestamps, change logs).",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable: The configuration of URL filters can be inspected on network devices or systems to ensure they are enabled and set up according to standards (e.g., category-based or block lists). Measurable: The effectiveness and enforcement can be quantified through data analysis of network traffic logs to compute rates of blocking, update frequencies, and coverage.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based: Evaluation involves examining the configuration models of the URL filtering system to verify compliance with enforcement policies (e.g., checking if filters are applied to all assets). Data-driven: Evaluation requires analyzing historical network traffic data and update logs to derive metrics such as blocking rates and update frequencies from event logs and traffic flows.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate enterprise assets capable of\n    supporting network-based URL filters (M1)",
            "Use GV5 to identify authorized web browsers/clients",
            [
                "For each asset identified in Operation 1 check to see if it is configured properly GV3 to support authorized web browsers/clients from Operation 2",
                [
                    "Identify and enumerate assets properly configured (M2)",
                    "Identify and enumerate assets not properly configured (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets configured to use authorized network-based URL filters",
                "measure.description": [
                    "M2 = Count of assets properly configured to support network-based    URL filters",
                    "M1 = Count of enterprise assets capable of supporting network-based    URL filters"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The list of installed plugins, extensions, and add-ons in browsers and email clients, along with their status (enabled or disabled), and evidence of uninstallation or disablement actions.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be assessed by verifying the configuration settings of browsers and email clients to ensure that unauthorized or unnecessary plugins are either uninstalled or disabled, which involves checking system configurations rather than requiring data analytics or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is performed by examining the configuration models and inventory of plugins in browsers and email clients, using system settings and logs to determine compliance, without the need for generating statistics from event logs or active testing.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets subject to browser/email\n    plugin restrictions (M1)",
            "Use GV5 to identify authorized browser and email plugins",
            [
                "For each asset listed in Operation 1, collect the list of installed browser plugins and compare to the output of Operation 2",
                [
                    "Identify and enumerate assets with only authorized browser plugins installed or enabled (M2)",
                    "Identify and enumerate assets with one or more unauthorized browser plugins installed or enabled (M3)"
                ]
            ],
            [
                "For each asset listed in Operation 1, collect the list of installed email plugins and compare to the output of Operation 2",
                [
                    "Identify and enumerate assets with only authorized email plugins installed or enabled (M4)",
                    "Identify and enumerate assets with one or more unauthorized browser plugins installed or enabled (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets compliant with authorized browser plugins",
                "measure.description": [
                    "M2 = Count of assets with only authorized browser plugins installed    or enabled",
                    "M1 = Count of assets subject to browser/email plugin restrictions"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "DNS records for SPF, DKIM, and DMARC policies; email headers indicating SPF, DKIM, and DMARC validation results; logs of email transactions showing policy enforcement",
        "Class": [
            "Checklist",
            "Verifiable"
        ],
        "Class.explanation": "Checklist because the safeguard can be assessed through automated scripting to check DNS records for SPF, DKIM, and DMARC. Verifiable because it involves verifying the configuration settings of these DNS records to ensure they are correctly implemented.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based because evaluation relies on inspecting the configured DNS records for SPF, DKIM, and DMARC to assess compliance. Active testing because it involves sending test emails to probe the system and verify that email validation policies are enforced correctly.",
        "Inputs": [
            [
                "DMARC Policy",
                "TXT record published in DNS",
                "The Mail Transfer Agent used by the enterprise",
                "The Mail User Agent used by the enterprise"
            ]
        ],
        "Operations": [
            [
                "Check if enterprise has a DMARC policy",
                [
                    "If the enterprise has a DMARC policy, M1 = 1",
                    "If the enterprise does not have a DMARC policy, M1 = 0"
                ]
            ],
            [
                "Examine Input 2 for a value indicative of the use of DMARC",
                [
                    "If a value for DMARC is identified, M2 = 1",
                    "If a value for DMARC is not identified, M2 = 0"
                ]
            ],
            [
                "Examine Input 2 for a value indicative of the use of SPF",
                [
                    "If a value for SPF is identified, M3 = 1",
                    [
                        "If a value for SPF is not identified, M3 = 0",
                        [
                            "If a value for SPF is not identified, M3 = 0"
                        ]
                    ]
                ]
            ],
            [
                "Examine Input 2 for a value indicative of the use of DKIM",
                [
                    "If a value for DKIM is identified, M4 = 1",
                    "If a value for DKIM is not identified, M4 = 0"
                ]
            ],
            [
                "Check if enterprise uses a Mail Transfer Agent",
                [
                    "If the enterprise uses a Mail Transfer Agent, M5 = 1",
                    "If the enterprise does not use a Mail Transfer Agent, M5 = 1"
                ]
            ],
            [
                "Check if enterprise uses a Mail User Agent",
                [
                    "If the enterprise uses a Mail User Agent, M6 = 1",
                    "If the enterprise does not use a Mail User Agent, M6 = 1"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "Usage and configuration of DMARC/SPF/DKIM",
                "measure.description": [
                    "M1 = Output of Operation 1",
                    "M2 = Output of Operation 2",
                    "M3 = Output of Operation 3",
                    "M4 = Output of Operation 4",
                    "M5 = Output of Operation 5",
                    "M6 = Output of Operation 6"
                ],
                "measure.id": [
                    "M1",
                    "M2",
                    "M3",
                    "M4",
                    "M5",
                    "M6"
                ],
                "equation": "(M1 + M2 + M3 + M4 + M5 + M6) / 6"
            }
        ]
    },
    {
        "Observable": "Configuration settings of email gateways defining blocked file types, and log entries of blocked email attempts.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration can be directly inspected to ensure unnecessary file types are blocked. Measurable because the number of blocked attempts can be quantified from logs.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves checking the configuration models of email gateways. Data-driven evaluation involves analyzing log data to measure the effectiveness of blocking.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets configured as email  gateways (M1)",
            [
                "Using GV3 check the attachment blocking configuration for every asset identified in Operation-1",
                [
                    "Identify and enumerate email gateways properly configured to block unnecessary attachments (M2)",
                    "Identify and enumerate email gateways not properly configured to block unnecessary attachments (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured email gateways",
                "measure.description": [
                    "M2 = Count of properly configured email gateways",
                    "M1 = Count of email gateways"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings of email servers indicating anti-malware is enabled, logs of email scans including attachment scanning and sandboxing events, detection alerts, and timestamps of anti-malware definition updates.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the presence and configuration of anti-malware protections can be checked through system inspections or configuration files. Measurable because operational metrics like scan rates and detection effectiveness can be calculated from log data and event records.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves inspecting configuration settings of email servers to verify that anti-malware features are deployed and configured. Active testing involves probing the system by sending test emails with attachments to verify that scanning, sandboxing, and detection are functioning correctly.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate all email servers within the\n    enterprise (M1)",
            [
                "For each email server identified in Operation 1, use GV3 to check if native or external anti-malware protections are configured",
                [
                    "Identify and enumerate email servers with configured anti-malware protection (M2)",
                    "Identify and enumerate email servers without configured anti-malware protection (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured email servers",
                "measure.description": [
                    "M2 = Count of properly configured email servers",
                    "M1 = Count of email servers"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Anti-malware software installation status, configuration settings, scan logs, update logs, and detection events on enterprise assets.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable: The deployment of anti-malware can be verified by checking system configurations, installation records, and presence on devices. Measurable: The maintenance and effectiveness can be measured through data on update frequencies, scan rates, and detection counts, requiring quantitative analysis.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Installation and configuration compliance can be assessed using system models and configuration checks. Data-driven: Metrics like update status and scan frequencies are derived from logs and event data. Active testing: The system can be probed with test malware to verify detection capabilities and response.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets capable of supporting\n    anti-malware software: GV30 (M1)",
            "Use GV5 to identify authorized anti-malware software: GV31",
            [
                "For each asset identified in Operation 1, use the output of Operation 2",
                [
                    "Identify and enumerate assets with at least one authorized anti-malware software installed: GV32 (M2)",
                    "Identify and enumerate assets with only unauthorized anti-malware software installed (M3)",
                    "Identify and enumerate assets without any anti-malware software installed (M4)"
                ]
            ],
            [
                "For each asset with a least one authorized anti-malware software installed from Operation 3.1, use GV3 to check configurations",
                [
                    "Identify and enumerate assets with properly configured anti-malware software (M5)",
                    "Identify and enumerate assets with improperly configured anti-malware software (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets with properly configured authorized anti-malware installed",
                "measure.description": [
                    "M5 = Count of assets with properly configured authorized    anti-malware software installed",
                    "M1 = Count of assets capable of supporting anti-malware software"
                ],
                "measure.id": [
                    "M5",
                    "M1"
                ],
                "equation": "M5 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings of anti-malware software indicating automatic updates are enabled for signature files, and logs or records of update events showing regular and successful updates.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be verified by inspecting the configuration settings of anti-malware software on each asset to confirm that automatic updates are enabled, without requiring complex data analytics or active probing.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": [
            "Model-based: Evaluation involves examining the configuration models or settings of the anti-malware software to verify that automatic updates are configured correctly.",
            "Data-driven: Evaluation uses data from update logs, event histories, and success rates to analyze the frequency and effectiveness of automatic updates.",
            "Active testing: Evaluation involves probing the system, such as forcing an update check, to verify that automatic updates are functioning as intended."
        ],
        "Inputs": [
            [
                "GV30: Assets Capable of Supporting Anti-Malware Software",
                "GV32: Assets with at Least One Authorized Anti-Malware Software Installed",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset in Input 2 GV32, check configurations GV3 to determine if anti-malware software is configured to autmatically update signature files",
                [
                    "Identify and enumerate assets properly configured for automatic updates (M2)",
                    "Identify and enumerate assets not properly configured for automatic updates (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured to automatically update signature files",
                "measure.description": [
                    "M2 = Count of assets configured to automatically update signature    files",
                    "M1 = Count of GV30"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings on devices indicating that autorun and autoplay are disabled for removable media, and system logs showing no automatic execution events upon media insertion.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be assessed by verifying the configuration settings of the operating system or device management policies, such as checking registry keys or group policies, which does not require data-driven analytics or active testing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Enforcement is evaluated by comparing the actual configuration state to a predefined model where autorun and autoplay are disabled, using system configuration data without the need for active probing or extensive log analysis.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate enterprise assets capable of\n    performing autorun, autoplay, and auto-execute functions (M1)",
            [
                "Check the configurations GV3 of each asset identified in Operation 1 to see if the autorun, autoplay, and auto-execute functions are disabled",
                [
                    "Identify and enumerate properly configured assets (M2)",
                    "Identify and enumerate improperly configured assets (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured to disable autorun, autoplay, and auto-execute functions",
                "measure.description": [
                    "M2 = Count of assets properly configured to disable functions",
                    "M1 = Count of assets capable of performing autorun, autoplay, and    auto-execute functions"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings of anti-malware software indicating automatic scanning for removable media is enabled, and logs of scans performed on removable media.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable: The configuration can be directly inspected in the anti-malware software settings to confirm if automatic scanning is enabled. Measurable: Data from scan logs can be analyzed over time to assess scan frequency and coverage, requiring data-driven analytics.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Evaluation involves checking the configuration model of the anti-malware software. Data-driven: Analysis of scan log statistics, such as count of scans and insertion events. Active testing: Probing the system by inserting removable media to observe if it is scanned automatically.",
        "Inputs": [
            [
                "GV30: Assets Capable of Supporting Anti-Malware Software",
                "GV32: Assets with at Least One Authorized Anti-Malware Software Installed",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset in Input 2 GV32, use configurations GV3 to identify if the software is configured to automatically scan removable media",
                [
                    "Identify and enumerate assets with properly configured software (M2)",
                    "Identify and enumerate assets with improperly configured software (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets with properly configured software to automatically scan removable media",
                "measure.description": [
                    "M2 = Count of assets with anti-malware properly configured to scan    removable media",
                    "M1 = Count of GV30"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings and logs indicating the enablement status of anti-exploitation features such as Microsoft Data Execution Prevention (DEP), Windows Defender Exploit Guard (WDEG), Apple System Integrity Protection (SIP), and Gatekeeper on enterprise devices.",
        "Class": [
            {
                "class": "Checklist",
                "explanation": "Can be assessed through automated scripts or tools that check the configuration status of anti-exploitation features on each device, allowing for systematic verification."
            },
            {
                "class": "Verifiable",
                "explanation": "Can be verified by inspecting system settings, configuration files, or management consoles to confirm that anti-exploitation features are enabled as required."
            },
            {
                "class": "Measurable",
                "explanation": "The enforcement quality can be quantified by measuring metrics such as the percentage of devices with features enabled out of those that support them, providing a data-driven assessment."
            }
        ],
        "Class.explanation": "Can be assessed through automated scripts or tools that check the configuration status of anti-exploitation features on each device, allowing for systematic verification.",
        "Evaluation_Method": [
            {
                "method": "Data-driven",
                "explanation": "Evaluation involves analyzing data from device inventories, configuration management databases, or security logs to determine the status and coverage of anti-exploitation features across the enterprise."
            },
            {
                "method": "Model-based",
                "explanation": "Assessment is based on comparing actual system configurations against a predefined model or policy that specifies the required anti-exploitation settings, using configuration management tools."
            }
        ],
        "Evaluation_Method.explanation": "Evaluation involves analyzing data from device inventories, configuration management databases, or security logs to determine the status and coverage of anti-exploitation features across the enterprise.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset in GV1, use configuration standards GV3 to determine if it is properly configured to enable anti-exploitation features",
                [
                    "Identify and enumerate assets properly configured to enable anti-exploitation features (M2)",
                    "Identify and enumerate assets not properly configured to enable anti-exploitation features (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets properly configured to enable anti-exploitation features",
                "measure.description": [
                    "M2 = Count of assets properly configured to enable anti-exploitation features",
                    "M1 = Count of GV1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Central management console status, anti-malware configuration logs indicating central server settings, deployment records from the management system, and update logs showing centralized push of definitions and scans.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of anti-malware software on devices and central servers can be checked through system settings and logs to confirm central management. Measurable because metrics such as coverage and compliance rates can be quantified using data from logs and configurations.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based as it involves verifying system configurations against expected models for central management. Data-driven as it requires analyzing event logs, management activities, and update frequencies to derive statistical metrics.",
        "Inputs": [
            [
                "GV30: Assets Capable of Supporting Anti-Malware Software",
                "GV31: Authorized Anti-Malware Software"
            ]
        ],
        "Operations": [
            [
                "For each authorized anti-malware software GV31, check if it is centrally managed",
                [
                    "Identify and enumerate anti-malware software that is centrally managed (M2)",
                    "Identify and enumerate anti-malware software that is not centrally managed (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of anti-malware centrally managed",
                "measure.description": [
                    "M2 = Count of authorized anti-malware software that is centrally    managed",
                    "M1 = Count of GV31"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Presence of behavior-based anti-malware software on devices, configuration settings indicating it is enabled and updated, and logs of detection events or missed detections.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the installation, configuration, and enablement of anti-malware software can be checked through system audits and configuration reviews. Measurable because the detection performance, such as rates of detection and false negatives, can be quantified using data from logs and incident reports.",
        "Evaluation_Method": "Data-driven, Active testing",
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing historical data from logs, such as detection events and incident reports, to assess performance. Active testing involves deploying controlled test malware samples to verify the software's behavior-based detection capabilities in real-time.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets capable of supporting behavior-based anti-malware software (M1)",
            "Use GV5 to identify authorized behavior-based anti-malware software",
            [
                "For each asset identified in Operation 1, use the output of Operation 2",
                [
                    "Identify and enumerate assets with at least one authorized behavior-based anti-malware software installed (M2)",
                    "Identify and enumerate assets without any behavior-based anti-malware software installed (M3)"
                ]
            ],
            [
                "For each asset with a least one authorized behavior-based anti-malware software installed from Operation 3.1, use GV3 to check configurations",
                [
                    "Identify and enumerate assets with properly configured behavior-based anti-malware software (M4)",
                    "Identify and enumerate assets with improperly configured behavior-based anti-malware software (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets with properly configured authorized behavior-based anti-malware installed",
                "measure.description": [
                    "M4 = Count of assets with properly configured authorized    behavior-based anti-malware software installed",
                    "M1 = Count of assets capable of supporting behavior-based    anti-malware software"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "The documented data recovery process, including the document itself, records of review and update activities, audit logs, and evidence of addressing scope, recovery prioritization, and backup data security.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the documentation can be inspected for presence and content through manual or automated checks. Measurable because aspects like review frequency, update timeliness, and completeness can be quantified using data.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because statistics from audit logs, timestamps of reviews and updates, and change records can be analyzed. Model-based because the documentation serves as a configuration model for the recovery process, and its structure can be assessed.",
        "Inputs": [
            [
                "Data Recovery Process for the enterprise",
                "Date of last update to the Data Recovery Process"
            ]
        ],
        "Operations": [
            [
                "Check if the enterprise has a data recovery process Input 1",
                [
                    "If so, M1 = 1",
                    "If not, M1 = 0"
                ]
            ],
            [
                "Examine the enterprise's data recovery process and determine if it addresses, at a minimum, the scope of data recovery activities, recovery prioritization, and the security of backup data",
                [
                    "For each element included within the process, assign the element a value of 1. M2 = sum of all the values."
                ]
            ],
            "Compare the date of the last update to the data recovery process to the curren date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, the Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve, this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of elements included in the data recovery process",
                "measure.description": [
                    "M2 = Sum of elements included in the data recovery process",
                    "M3 = Timeframe in months of the last update to the data recovery process"
                ],
                "measure.id": [
                    "M2",
                    "M3"
                ],
                "equation": "M2 / M3"
            }
        ]
    },
    {
        "Observable": "Backup execution logs, configuration settings for automated backups, timestamps of backup events, success/failure statuses of backup attempts, and records of backup schedules based on data sensitivity.",
        "Class": [
            {
                "name": "Verifiable",
                "explanation": "The safeguard can be verified by inspecting the configuration of backup systems to ensure that automated backups are enabled and schedules are set according to data sensitivity."
            },
            {
                "name": "Measurable",
                "explanation": "The enforcement quality can be measured by analyzing quantitative data from backup logs, such as frequency, timeliness, and success rates of backups."
            }
        ],
        "Class.explanation": "The safeguard can be verified by inspecting the configuration of backup systems to ensure that automated backups are enabled and schedules are set according to data sensitivity.",
        "Evaluation_Method": [
            {
                "name": "Data-driven",
                "explanation": "Evaluation requires analyzing data from backup logs, including event timestamps and success indicators, to compute metrics like frequency compliance and success rate."
            },
            {
                "name": "Model-based",
                "explanation": "Evaluation involves checking the system configuration models, such as backup software settings, to verify that automation is configured and schedules align with data sensitivity policies."
            }
        ],
        "Evaluation_Method.explanation": "Evaluation requires analyzing data from backup logs, including event timestamps and success indicators, to compute metrics like frequency compliance and success rate.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            "For each asset in GV1 identify and enumerate assets that are in-scope for automated backups: GV33 (M1)",
            [
                "Use GV5 to identify authorized backup software and for each asset identified in Operation 1",
                [
                    "Identify and enumerate assets covered by at least one authorized backup software: GV34 (M2)",
                    "Identify and enumerate assets not covered by at least one authorized backup software (M3)"
                ]
            ],
            [
                "Use GV3 to check if the software on assets identified in Operation 2.1 is configured correctly",
                [
                    "Identify and enumerate assets with properly configured backup software (M4)",
                    "Identify and enumerate assets with improperly configured backup software (M5)"
                ]
            ],
            [
                "For each asset with backup software identified in Operation 2.1, examine logs to determine the most recent successful backup date. Compare that date to the current date and capture the timeframe in days.",
                [
                    "Identify and enumerate assets that have been backup within seven days or less (M6)",
                    "Identify and enumerate assets that have been backed up outside of a seven-day window (M7)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of in-scope assets with properly configured authorized backup software",
                "measure.description": [
                    "M4 = Count of in-scope assets with properly configured backup    software",
                    "M1 = Count of assets within scope for automated backups"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings for encryption and data separation on recovery data, access control logs, audit trails of data protection measures, and records of equivalent controls compared to original data.",
        "Class": "Verifiable, Measurable, Checklist",
        "Class.explanation": "Verifiable because the configurations for encryption and data separation can be directly inspected and verified against requirements; Measurable because compliance rates and effectiveness can be quantified over time using data; Checklist because automated scripts can assess the settings and configurations.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based: Evaluation relies on checking system configurations and models to ensure equivalent controls are in place; Data-driven: Analysis of access logs, encryption status, and incident reports provides statistical insights into protection effectiveness.",
        "Inputs": [
            [
                "GV33: Assets that are In-Scope for Automated Backups",
                "GV34: Assets with Authorized Backup Software Installed",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset with backup software installed GV34, use GV3 to check if encryption is configured for backups",
                [
                    "Identify and enumerate assets with software configured to encrypt backups (M2)",
                    "Identify and enumerate assets with software not configured to encrypt backups (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of in-scope assets with backup software properly configured to encrypt backups",
                "measure.description": [
                    "M2 = Count of software configured to encrypt backups",
                    "M1 = Count of Input 1: GV33"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings of backup systems indicating isolation (e.g., offline, off-site, cloud with isolation), logs of backup operations showing version control, records of backup instances and their properties.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the isolation and version control settings can be checked against configuration standards and system models. Measurable because the proportion of compliant backup instances and the extent of version control can be quantified using data from logs and configurations.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based because system configurations and models can be used to verify isolation and version control settings. Data-driven because backup logs, version histories, and instance data provide statistical information for analysis and measurement.",
        "Inputs": [
            [
                "GV33: Assets that are In-Scope for Automated Backups",
                "GV34: Assets with Authorized Backup Software Installed",
                "GV3: Configuration Standard"
            ]
        ],
        "Operations": [
            [
                "For each asset in GV34, use configuration standards in GV3 to check the destination of backups",
                [
                    "Identify and enumerate assets properly configured to send backups to an isolated instance (M2)",
                    "Identify and enumerate assets not properly configured to send backups to an isolated instance (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets configured to send backups to an isolated instance",
                "measure.description": [
                    "M2 = Count of assets with backups sent to an isolated instance",
                    "M1 = Count of Input 1 GV33"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Records of backup recovery tests, including test logs, timestamps, lists of assets tested, and reports indicating the frequency and coverage of tests.",
        "Class": "Measurable",
        "Class.explanation": "Assessing this safeguard requires analyzing data from backup recovery test logs and reports to measure the frequency of tests and the coverage of assets, which involves data-driven analytics rather than simple checklist or configuration verification.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "We evaluate the enforcement by generating statistics from event logs of backup recovery tests, such as counting the number of tests conducted, the assets involved, and the timestamps, to assess compliance with quarterly testing and sampling requirements.",
        "Inputs": [
            [
                "Current set of backups for the enterprise",
                "Date of last backup recovery test"
            ]
        ],
        "Operations": [
            [
                "Use Input 1 to restore a sampling of the backups to a temporary location",
                [
                    "Enumerate the total number of backups restored (M1)",
                    "Identify and enumerate backups that are properly working after being restored (M2)",
                    "Identify and enumerate backups that did not properly work after being restored (M3)"
                ]
            ],
            "Compare Input 2 to the current date and capture the time frame in months\n    (M4)"
        ],
        "Metric_as_text": [
            [
                "If M4 is greater than three months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of restored backup sampling deemed to be properly working",
                "measure.description": [
                    "M2 = Count of properly working backups after restoration",
                    "M1 = Count of backups being tested"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Software versions of network infrastructure, support status of NaaS offerings, and timestamps of software version reviews.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because software versions and support status can be checked through configuration inspection and vendor documentation. Measurable because the compliance rates (e.g., proportion of up-to-date devices) and review frequencies can be quantified and tracked over time.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves collecting and analyzing data from version histories, support status logs, and review records. Model-based evaluation compares current software versions against a model of supported versions (e.g., vendor lists). Active testing may involve probing network devices with scanning tools to check for vulnerabilities or update status.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "Authoritative source of latest version information",
                "Date of last review of network infrastructure"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets that are part of the\n    network infrastructure GV35 (M1)",
            [
                "Compare the network infrastructure asset version to the version in Input 2",
                [
                    "Identify and enumerate assets that match the most recent version (M2)",
                    "Identify and enumerate assets that don't match the most recent version (M3)"
                ]
            ],
            "Compare Input 3 to the current date and capture the timeframe in days (M4)"
        ],
        "Metric_as_text": [
            [
                "If M4 is greater than thirty days, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of network infrastructure assets that are up to date",
                "measure.description": [
                    "M2 = Count of network infrastructure assets up to date",
                    "M1 = Count of network infrastructure assets"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network architecture diagrams, configuration files for network devices (e.g., routers, firewalls), traffic flow logs, access control policies, design documentation, and records of maintenance activities.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because network configurations and documentation can be inspected against design standards and policies to check for compliance. Measurable because data from traffic logs, performance monitors, and access controls can be quantified to assess segmentation, least privilege, and availability enforcement.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves using network configuration models and design documents to verify architectural adherence to principles. Data-driven evaluation utilizes collected traffic statistics, log data, and performance metrics to measure actual enforcement and effectiveness over time.",
        "Inputs": [
            [
                "GV4: Enterprise Network Architecture Documentation",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use the network architecture GV4 to identify and enumerate the segments within the enterprise network GV36 (M1)",
            [
                "For each network segment identified in Operation 1, attempt to connect an unauthorized device",
                [
                    "Identify and enumerate segments that allow you to connect unauthorized devices (M2)",
                    "Identify and enumerate segments that do not allow you to connect unauthorized devices (M3)"
                ]
            ],
            "Use GV5 to identify authorized availability monitoring software",
            [
                "For each network segment identified in Operation 1, determine whether an authorized availability monitoring software from Operation 3 covers the segment",
                [
                    "Identify and enumerate segments that are covered by availability monitoring software (M4)",
                    "Identify and enumerate segments that are not covered by availability monitoring software (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "If M1 is equal to 1, this metric is measured at a 0. Subsequent metrics can still be assessed.",
                "measure.description": [
                    "M1 = Count of network segments within the enterprise"
                ],
                "measure.id": [
                    "M1",
                    "M1"
                ],
                "equation": "If M1 <= 1, Fail or If M1 >= 1, Pass"
            }
        ]
    },
    {
        "Observable": "Version-controlled Infrastructure-as-Code (IaC) repositories, network configuration files, traffic logs showing protocol usage (e.g., SSH, HTTPS, insecure protocols), and management activity logs.",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist: Automated scripts can verify if IaC is version-controlled. Verifiable: Network configurations can be inspected to ensure secure protocols like SSH and HTTPS are enabled. Measurable: Traffic data can be analyzed quantitatively to measure secure protocol usage.",
        "Evaluation_Method": "Data-driven, Model-based, Active testing",
        "Evaluation_Method.explanation": "Data-driven: Statistical analysis of traffic logs and event data to measure protocol usage. Model-based: Assessment of configuration models from IaC or device settings to verify compliance. Active testing: Probing network services to test if they respond only with secure protocols.",
        "Inputs": [
            [
                "GV36: Segments within the Enterprise Network",
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            [
                "For each asset in GV35, use GV37 to check for the use of encrypted sessions",
                [
                    "Identify and enumerate assets using encrypted sessions (M2)",
                    "Identify and enumerate assets not using encrypted sessions (M3)"
                ]
            ],
            [
                "For each network segment in GV36, check for the use of infrastructure-as-code",
                [
                    "Identify and enumerate network segments that use infrastructure-as-code for the whole segment or partial (M5)",
                    "Identify and enumerate network segments that do not use infrastructure-as-code for any portion of the segment (M6)"
                ]
            ],
            [
                "For each network segment identified in Operation 1, use GV37 to determine whether the infrastructure-as-code is managed using version control",
                [
                    "Identify and enumerate network segments covered by version-controlled infrastructure-as-code (M7)",
                    "Identify and enumerate network segments covered by infrastructure-as-code is not managed through version control (M8)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network infrastructure assets using encrypted sessions",
                "measure.description": [
                    "M2 = Count of network infrastructure assets using encrypted sessions",
                    "M1 = Count of GV35 assets that are part of the network    infrastructure"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Architecture diagrams, documentation files, review logs with timestamps, update records, and logs of significant enterprise changes.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard is verifiable because it can be assessed by directly inspecting the documentation files and their metadata, such as creation dates, modification dates, and review history, to ensure they exist and are maintained according to the policy of annual reviews or updates after significant changes.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is model-based as it relies on examining the current state and configuration of the documentation system, including file properties, audit logs, and metadata, without requiring active testing or extensive data-driven statistical analysis.",
        "Inputs": [
            [
                "GV4: Enterprise Network Architecture Documentation",
                "Date of last review or update to documentation"
            ]
        ],
        "Operations": [
            [
                "Determine if GV4 exists within the enterprise",
                [
                    "If the network architecture documentation exists, M1 = 1",
                    "If the network architecture documentation does not exist, M1 = 0"
                ]
            ],
            "Compare Input 2 to the current date. Capture the timeframe in\n    months."
        ],
        "Metric_as_text": [
            [
                "If M1 is not provided or available, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply.",
                "If M2 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "Centralized AAA server configuration, network device AAA settings pointing to a central server, logs of authentication, authorization, and accounting events from the central system.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be assessed by verifying the configuration of network devices to ensure they are set to use a central AAA service, which is typically done through manual or automated checks of device settings and server configurations.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is performed by examining the configuration models of network devices and AAA servers to confirm that AAA services are centralized, using static configuration data rather than dynamic logs or active tests.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV35: Assets that are Part of the Network Infrastructure"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate all AAA services within\n    the enterprise GV35 (M1)",
            [
                "For each centralized AAA point identified in Operation 1, determine whether it is necessary or can be consolidated",
                [
                    "Identify and enumerate authentication points that are unnecessary or can be consolidated (M2)",
                    "Identify and enumerate authentication points that are necessary and cannot be consolidated (M3)"
                ]
            ],
            [
                "Use the output of Operation 1 to check if each asset in GV35 is covered by at least one AAA system",
                [
                    "Identify and enumerate network infrastructure assets that are covered by at least one AAA system (M4)",
                    "Identify and enumerate network infrastructure assets that are not covered by an AAA system (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "Percentage of properly centralized AAA services",
                "measure.description": [
                    "M3 = Count of necessary AAA services",
                    "M1 = Count of AAA services within the enterprise"
                ],
                "measure.id": [
                    "M3",
                    "M1"
                ],
                "equation": "M3 / M1"
            }
        ]
    },
    {
        "Observable": "Network device configurations showing enabled 802.1X and WPA2 Enterprise protocols, and network traffic encrypted using these protocols.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "This safeguard is verifiable because it involves checking configuration settings on network devices through scripts or manual inspection. It is measurable because usage statistics and compliance can be derived from network logs, traffic analysis, and authentication events.",
        "Evaluation_Method": "Model-based, Active testing",
        "Evaluation_Method.explanation": "Model-based evaluation is used to inspect device configurations and settings for protocol adoption. Active testing is used to probe the network by attempting connections with insecure protocols to verify enforcement and functionality.",
        "Inputs": [
            [
                "GV36: Segments within the Enterprise Network",
                "GV37: Network Infrastructure Configuration Standards",
                "Authorized list of secure network management and communication    protocols"
            ]
        ],
        "Operations": [
            [
                "For each network segment in GV36, use Input 3 to identify communication protocols",
                [
                    "Identify and enumerate segments using only communication protocols on the authorized list (M2)",
                    "Identify and enumerate segments using communication protocols not on the authorized list (M3)"
                ]
            ],
            [
                "For each communication protocol identified in Operation 1.1, check configuration standards GV37",
                [
                    "Identify and enumerate segments using properly configured communication protocols (M4)",
                    "Identify and enumerate segments using improperly configured communication protocols (M5)"
                ]
            ],
            [
                "For each network segment in GV36, use Input 3 to identify network management protocols",
                [
                    "Identify and enumerate segments using only network management protocols on the authorized list (M6)",
                    "Identify and enumerate segments using network management protocols not on the authorized list (M7)"
                ]
            ],
            "For each communication protocol identified in Operation 1.1, check configuration standards GV37",
            "Identify and enumerate segments using properly configured network management protocols (M8)",
            "Identify and enumerate segments using improperly configured network management protocols (M9)"
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network segments using properly configured and authorized communication protocols",
                "measure.description": [
                    "M4 = Count of segments using properly configured authorized    communication protocols",
                    "M1 = Count of GV36"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Authentication logs from VPN and authentication services, access logs to enterprise resources with timestamps indicating authentication prior to access, and configuration settings of VPN and authentication services.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the configuration of VPN and authentication services can be inspected to ensure authentication is required before access. Measurable because authentication and access logs can be analyzed quantitatively to assess compliance rates.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves checking the configuration settings of VPN and authentication services to verify they enforce authentication. Data-driven evaluation involves analyzing authentication and access logs to measure compliance through statistical data.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory",
                "GV38: AAA Services within the Enterprise",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate remote enterprise assets\n    GV39 (M1)",
            "Use GV1 and GV5 to identify and enumerate all\n    VPN devices and software (M2)",
            [
                "Use the output of Operation 2 and GV37 to check the configuration of the VPN",
                [
                    "Identify and enumerate VPN devices and software properly configured to require authentication prior to granting access (M3)",
                    "Identify and enumerate VPN devices and software not properly configured to require authentication prior to granting access (M4)"
                ]
            ],
            [
                "For each asset identified in Operation 1, check if is covered by a VPN device or software identified in Operation 3.1",
                [
                    "Identify and enumerate assets that are covered by a VPN (M5)",
                    "Identify and enumerate assets that are not covered by a VPN (M6)"
                ]
            ],
            [
                "Use GV38 and GV37 to check configuration of AAA services",
                [
                    "Identify and enumerate AAA services properly configured to require authentication prior to granting access (M7)",
                    "Identify and enumerate AAA services not properly configured to require authentication prior to granting access (M8)"
                ]
            ],
            [
                "For each asset identified in Operation 1, check if it is covered by an AAA service identified in Operation 5.1",
                [
                    "Identify and enumerate assets that are covered by an AAA service (M9)",
                    "Identify and enumerate assets that are not covered by an AAA service (M10)"
                ]
            ],
            [
                "Compare the output of Operation 4.1 and 6.1",
                [
                    "Identify and enumerate assets covered by both VPN and AAA (M1)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured VPN devices and software",
                "measure.description": [
                    "M3 = Count of properly configured VPN devices and software",
                    "M2 = Count of VPN devices and software"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Dedicated computing resources for administrative tasks, network segmentation configurations indicating isolation from the enterprise's primary network, and settings showing no internet access on these resources. If not enforced, administrative tasks may be performed on non-dedicated resources, lack of network segmentation, or internet access on admin resources.",
        "Class": [
            {
                "name": "Checklist",
                "explanation": "Automated scripts can check for the existence and basic configuration of dedicated administrative resources, such as verifying dedicated servers or VMs and their network settings."
            },
            {
                "name": "Verifiable",
                "explanation": "System and network configurations, including firewall rules and access control lists, can be reviewed to confirm segmentation and the absence of internet access on dedicated resources."
            },
            {
                "name": "Measurable",
                "explanation": "Data from event logs and task execution records can be analyzed to measure the proportion of administrative tasks performed on dedicated resources and compliance with segmentation and access policies."
            }
        ],
        "Class.explanation": "Automated scripts can check for the existence and basic configuration of dedicated administrative resources, such as verifying dedicated servers or VMs and their network settings.",
        "Evaluation_Method": [
            {
                "name": "Data-driven",
                "explanation": "Analysis of event logs, network traffic flows, and administrative task records can show if tasks are confined to dedicated resources and if internet access is blocked, providing statistical insights into enforcement."
            },
            {
                "name": "Model-based",
                "explanation": "Configuration models and network diagrams can be used to verify that dedicated resources are segmented from the primary network and have no internet access, based on system settings and rules."
            },
            {
                "name": "Active testing",
                "explanation": "Probing the network through penetration tests or access attempts can validate isolation and internet blockages on dedicated administrative resources by simulating real-world scenarios."
            }
        ],
        "Evaluation_Method.explanation": "Analysis of event logs, network traffic flows, and administrative task records can show if tasks are confined to dedicated resources and if internet access is blocked, providing statistical insights into enforcement.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets used for\n    administrative purposes (M1)",
            [
                "For each asset identified in Operation 1, use GV37 to check configurations",
                [
                    "Identify and enumerate assets that do not have internet access (M2)",
                    "Identify and enumerate assets that have internet access (M3)",
                    "Identify and enumerate assets that are physically or logically separated from the primary network (M4)",
                    "Identify and enumerate assets that are not physically or logically separated from the primary network (M5)"
                ]
            ],
            [
                "Compare the output of Operation 2.1 and 2.3",
                [
                    "Identify and enumerate assets that do not have internet access and are physically or logically separated (M6)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured administrative assets",
                "measure.description": [
                    "M6 = Count of assets configured to not allow internet access and are    physically or logically separated",
                    "M1 = Count of assets used for administrative purposes"
                ],
                "measure.id": [
                    "M6",
                    "M1"
                ],
                "equation": "M6 / M1"
            }
        ]
    },
    {
        "Observable": "Centralized security event alerting system (e.g., SIEM or log analytics platform), configuration settings for log ingestion and correlation alerts, logs of events and alerts generated, records of alert correlations and analyses.",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist: Automated scripts can check if assets are configured to send logs and if correlation alerts are set up. Verifiable: Manual inspection can confirm the configuration of the SIEM and alert rules. Measurable: Data analysis is required to assess performance metrics like coverage and alert effectiveness.",
        "Evaluation_Method": "Data-driven, Model-based, Active testing",
        "Evaluation_Method.explanation": "Data-driven: Analysis of log data, alert statistics, and event correlations to evaluate enforcement. Model-based: Inspection of configuration settings in the SIEM or log analytics platform. Active testing: Probing the system by generating test events to verify if alerts trigger appropriately.",
        "Inputs": [
            [
                "Location of GV42: Log Correlation or Log Analytic Tool",
                "GV1: Enterprise Asset Inventory"
            ]
        ],
        "Operations": [
            [
                "Check if Input 1 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    [
                        "If Input 1 does not exist, M1 = 0",
                        [
                            "If Input 1 does not exist, M1 = 0"
                        ]
                    ]
                ]
            ],
            "Use GV1 to identify and enumerate enterprise assets that produce security event logs (M2)",
            [
                "For every asset identified in Operation 2, check if logs are centralized at the location of the log correlation or log analytic tool Input 1",
                [
                    "Identify and enumerate assets whose logs are centralized (M3)",
                    "Identify and enumerate assets whose logs are not centralized (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of assets whose security logs are centralized",
                "measure.description": [
                    "M3 = Count of assets with security event logs being centralized",
                    "M2 = Count of assets that produce security event logs"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Presence of host-based intrusion detection software on enterprise assets, its configuration settings, and logs of detection events.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the deployment and configuration of HIDS can be checked through system audits and configuration reviews against policies. Measurable because the coverage and potential detection performance can be quantified using data from asset inventories and logs.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based for evaluating HIDS configuration against security models or policies. Data-driven for generating statistics on deployment coverage and detection events from system logs.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets capable of supporting host based intrusion detection systems (M1)",
            "Use GV5 to identify authorized host-based intrusion detection software",
            [
                "For each asset identified in Operation 1, check if it is covered by at least one authorized host-based intrusion detection software",
                [
                    "Identify and enumerate assets with host-based intrusion detection software installed (M2)",
                    "Identify and enumerate assets without host-based intrusion detection software installed (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets capable of supporting host-based intrusion detection systems with host-based intrusion detection software installed",
                "measure.description": [
                    "M2 = Count of assets with host-based intrusion detection systems",
                    "M1 = Count of enterprise assets capable of supporting host-based    intrusion detection systems"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Deployment of network intrusion detection solutions (e.g., NIDS or CSP services), their configuration settings, alert logs generated, and coverage of network segments.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist: Deployment can be assessed through scripting to check if NIDS is installed on assets. Verifiable: Configuration settings can be verified against best practices or standards. Measurable: Detection performance, such as alert rates and accuracy, can be measured using data analytics from logs.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven: Evaluation involves analyzing logs and alert data to compute metrics like detection rates. Model-based: Configuration files or settings are checked against a security model or policy. Active testing: The system is probed with simulated intrusions to test if NIDS detects them.",
        "Inputs": [
            [
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV4: Enterprise Network Architecture Documentation"
            ]
        ],
        "Operations": [
            "Use GV35 to identify the network intrusion detection\n    solutions for the enterprise",
            "Use GV4 to identify and enumerate network boundaries (M1)",
            [
                "For each network boundary identified in Operation 2, determine whether it is covered by at least one network intrusion detection solution",
                [
                    "Identify and enumerate boundaries covered by at least one network intrusion detection solution (M2)",
                    "Identify and enumerate boundaries not covered by at least one network intrusion detection solution (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network boundaries covered by network intrusion detection solutions",
                "measure.description": [
                    "M2 = Count of network boundaries covered by a network intrusion    detection solution",
                    "M1 = Count of network boundaries"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Configuration settings of network devices (e.g., firewalls, routers) showing traffic filtering rules, network traffic logs indicating filtered and allowed traffic, and network segmentation diagrams.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the presence and configuration of traffic filtering can be checked by inspecting network device settings against policies. Measurable because the coverage and effectiveness can be assessed through data analysis of traffic flows and configuration compliance.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based because network configuration models can be used to verify the setup of filtering rules. Data-driven because analysis of traffic data from logs and flows is required to evaluate filtering performance and compliance.",
        "Inputs": [
            [
                "GV36: Segments within the Enterprise Network",
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            "Use GV36 to identify and enumerate network segments that\n    require communication with other network segments (M1)",
            "For each network segment identified in Operation 1, use GV35 to identify network infrastructure assets responsible for\n    traffic filtering",
            [
                "For each network infrastructure asset identified in Operation 1, check configurations using GV37 to determine whether each segment is properly configured to filter traffic",
                [
                    "Identify and enumerate network segments with properly configured filtering assets (M2)",
                    "Identify and enumerate network segments with improperly configured filtering assets (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network segments properly configured to filter traffic between segments",
                "measure.description": [
                    "M2 = Count of network segments with properly configured filtering    assets",
                    "M1 = Count of network segments that communicate with other networks    segments"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Logs of access control decisions for remote connections, status reports indicating anti-malware version and update status, configuration compliance checks, and operating system and application update status for assets remotely connecting to enterprise resources.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the configuration of access control systems and the status of assets (e.g., anti-malware, OS updates) can be checked through audits or automated scripts. Measurable because compliance rates (e.g., percentage of assets meeting criteria) can be calculated from collected data, allowing for quantitative assessment.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because evaluation involves analyzing data from logs, status reports, and event records to compute metrics. Model-based because it requires comparing actual system configurations and states against a predefined secure configuration model to assess compliance.",
        "Inputs": [
            [
                "GV23: Inventory of Authentication and Authorization Systems",
                "GV3: Configuration Standard",
                "GV39: Remote Enterprise Assets"
            ]
        ],
        "Operations": [
            "Use GV23 to identify and enumerate authorization systems\n    that allow remote logins (M1)",
            [
                "For each authorization system identified in Operation 1, use GV3 to check if the configuration for each type of policy",
                [
                    "Identify and enumerate authorization systems properly configured for all the policies (M2)",
                    "Identify and enumerate authorization systems for which at least one configuration does not comply with the policies (M3)"
                ]
            ],
            [
                "For each remote enterprise asset from GV39, compared to the output of Operation 2.1",
                [
                    "Identify and enumerate assets that are covered by at least one compliant authorization system (M4)",
                    "Identify and enumerate assets that are not covered by a compliant authorization system (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of properly configured authorization systems that allow remote login",
                "measure.description": [
                    "M2 = Count of authorization systems properly configured to comply    with policies",
                    "M1 = Count of authorization systems that allow remote logins"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network traffic flow logs being collected and alerts generated based on reviews from network devices.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the configuration of network devices can be inspected to verify if flow logging is enabled. Measurable because quantifiable metrics such as log volume and alert rate can be derived from data analysis.",
        "Evaluation_Method": [
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Data-driven because evaluating this safeguard requires collecting and analyzing data from flow logs, traffic flows, and alert logs to assess enforcement, rather than relying solely on configuration checks or active probing.",
        "Inputs": [
            [
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            "Use GV35 to identify and enumerate network boundary assets\n    (M1)",
            [
                "For each network boundary asset identified in Operation 1, check configuration GV37 to determine if network traffic or network traffic flow logging is enabled",
                [
                    "Identify and enumerate assets with either network traffic flow or network traffic logging enabled (M2)",
                    "Identify and enumerate assets that have neither network traffic flow nor network traffic logging enabled (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network boundary assets properly configured to log network traffic flow or network traffic",
                "measure.description": [
                    "M2 = Count of properly configured network boundary assets",
                    "M1 = Count of network boundary assets"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Presence of host-based IPS or EDR agents on enterprise assets, their configuration settings (e.g., enabled status, signature updates), and deployment or installation logs.",
        "Class": [
            "Verifiable",
            "Checklist"
        ],
        "Class.explanation": "Verifiable because the deployment and configuration of IPS can be confirmed by examining system settings and agent status. Checklist because a script can be used to systematically check for installation on each asset, creating a verifiable list.",
        "Evaluation_Method": [
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves using configuration data from systems, such as management interfaces or agent status reports, to assess compliance with deployment and configuration policies without active probing.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate assets capable of supporting host-based intrusion prevention systems (M1)",
            "Use GV5 to identify authorized host-based intrusion prevention software",
            [
                "For each asset identified in Operation 1, check if it is covered by at least one authorized host-based intrusion prevention software",
                [
                    "Identify and enumerate assets with host-based intrusion prevention software installed (M2)",
                    "Identify and enumerate assets without host-based intrusion prevention software installed (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of assets capable of supporting host-based intrusion prevention systems with software installed",
                "measure.description": [
                    "M2 = Count of assets with host-based intrusion prevention systems",
                    "M1 = Count of enterprise assets capable of supporting host-based    intrusion prevention systems"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network intrusion prevention system configuration, logs of intrusion alerts, deployment records, and traffic monitoring data",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the deployment and configuration of NIPS can be checked through system inspections and configuration reviews. Measurable because its effectiveness can be quantified through data analysis of intrusion detection, prevention rates, and alert logs.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing event logs, traffic flows, and alert data to assess intrusion patterns. Model-based evaluation checks the configuration settings and rules of the NIPS against best practices. Active testing involves probing the network with simulated attacks to test the NIPS's response and detection capabilities.",
        "Inputs": [
            [
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV40: Network Boundaries"
            ]
        ],
        "Operations": [
            "Use GV35 to identify the network intrusion prevention\n    solutions for the enterprise",
            [
                "For each network boundary identified in Input 2, determine whether it is covered by at least one network intrusion prevention solution",
                [
                    "Identify and enumerate boundaries covered by at least one network intrusion prevention solution (M2)",
                    "Identify and enumerate boundaries not covered by at least one network intrusion prevention solution (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network boundaries covered by network intrusion prevention solutions",
                "measure.description": [
                    "M2 = Count of network boundaries covered by a network intrusion    prevention solution",
                    "M1 = Count of network boundaries GV40"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network device configurations showing 802.1x or similar NAC settings, authentication logs indicating successful or failed access attempts, and access control lists or event logs.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist: Can be assessed through automated scripts that check device configurations for 802.1x settings. Verifiable: Configuration settings on network devices can be manually or automatically verified against standards. Measurable: Data from authentication logs and port configurations can be analyzed to measure coverage and success rates.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Evaluation involves using configuration models or snapshots of network devices to check for 802.1x implementation. Data-driven: Analysis of authentication event logs, traffic flows, and user/device activities to derive statistics. Active testing: Probing the network by attempting unauthorized access to verify if port-level controls are enforced.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "GV38: AAA Services within the Enterprise",
                "GV41: List of Change Management Database (CMDB) Servers",
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            [
                "If the enterprise uses an 802.1x network design to control network access:",
                [
                    "Use GV5 to identify and enumerate 802.1x authenticators"
                ]
            ],
            [
                "For each authenticator identified in Operation 1, use GV37 to check configurations",
                [
                    "Identify and enumerate properly configured authenticators (M2)",
                    "Identify and enumerate improperly configured authenticators (M3)"
                ]
            ],
            "Use GV38 to identify 802.1x authentication servers (M4)",
            [
                "For each authentication server identified in Operation 3, use GV37 to check configurations to ensure a connection to at least one CMDB server from GV41",
                [
                    "Identify and enumerate properly configured authentication servers (M5)",
                    "Identify and enumerate improperly configured authentication servers (M6)"
                ]
            ],
            [
                "If the enterprise does not use 802.1x network design to control network access:",
                [
                    [
                        "For each asset in GV35, use GV37 to check client authentication certificate configuration",
                        [
                            "Identify and enumerate properly configured assets (M8)",
                            "Identify and enumerate improperly configured assets (M9)"
                        ]
                    ]
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If the enterprise uses an 802.1x network design to control network access:"
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of properly configured authenticators",
                "measure.description": [
                    "M2 = Count of 802.1x properly configured authenticators",
                    "M1 = Count of 802.1x authenticators"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Logs from application layer filtering devices (e.g., proxy, firewall, gateway) showing filtered traffic, including allowed and blocked requests, and configuration settings of these devices.",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist: The presence and basic configuration of filtering devices can be checked via scripting or automated tools. Verifiable: The configuration settings, such as rule sets and enabled features, can be examined for correctness. Measurable: Data from traffic logs can be analyzed quantitatively to assess coverage and effectiveness.",
        "Evaluation_Method": "Data-driven, Model-based, Active testing",
        "Evaluation_Method.explanation": "Data-driven: Statistics from event logs and traffic flows can be used to compute metrics like coverage and block rates. Model-based: The configuration models of filtering devices can be inspected to verify enforcement. Active testing: Probing the system with test requests (e.g., malicious or benign) can validate filtering behavior.",
        "Inputs": [
            [
                "GV35: Assets that are Part of the Network Infrastructure",
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV5 to identify software used for application layer filtering",
            [
                "For each asset in `GV35, determine whether it is covered by at least one software identified in Operation 1",
                [
                    "Identify and enumerate assets covered by application layer filtering software (M2)",
                    "Identify and enumerate assets not covered by application layer filtering software (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of network infrastructure assets covered by application layering software",
                "measure.description": [
                    "M2 = Count of network infrastructure assets covered by the application    layer filtering software",
                    "M1 = Count of network infrastructure assets"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Logs of tuning activities for alerting thresholds on network security devices (e.g., firewalls, IDS/IPS), including timestamps of when tuning was performed, configuration changes, and records of threshold adjustments.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the occurrence of tuning activities can be confirmed by inspecting system logs, configuration management systems, and audit trails. Measurable because the frequency of tuning events can be quantified using timestamps from logs to calculate intervals and compliance rates.",
        "Evaluation_Method": [
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Data-driven because it requires collecting and analyzing historical data from security event logs, configuration change logs, or audit trails to determine the timing and frequency of tuning activities, rather than relying solely on static configurations or active probing.",
        "Inputs": [
            [
                "Date of last tuning of security event alert thresholds of GV42 Log Correlation or Log Analytic Tool"
            ]
        ],
        "Operations": [
            "Compare Input 1 to the current date and capture the timeframe in days"
        ],
        "Metric_as_text": [
            [
                "If M1 is greater than thirty days, then this Safeguard is measured at a 0 and receives a failing score."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "Records of security awareness training completion (e.g., logs from training systems), documentation of the security awareness program (e.g., policy documents, training materials), logs of content reviews and updates (e.g., revision dates, change logs), and records of significant enterprise changes that might trigger updates.",
        "Class": "Measurable",
        "Class.explanation": "This safeguard involves quantitative assessment of training completion rates and review frequencies, which requires data-driven analysis rather than simple checklist verification or configuration checks.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation requires collecting and analyzing data from training completion records, employee databases, and review logs to generate statistics on compliance with training schedules and content update policies.",
        "Inputs": [
            [
                "Security Awareness Program",
                "GV43: List of Workforce Members",
                "List of most recent security awareness training completion dates for    each workforce member",
                "Date of last review or update to security awareness program content"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            "Compare the date in Input 4 to the current date and capture\n    the timeframe in months (M2)",
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M4)",
                    "Identify and enumerate members who have not completed any  training (M5)"
                ]
            ],
            "For every member of the workforce identified in Operation 3.1, Identify the date of most recently completed security awareness\n    training",
            [
                "For every member of the workforce identified in Operation 3.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M6)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M7)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M2 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M4 = Count of workforce members that have completed training",
                    "M3 = Count of Input 2 GV43"
                ],
                "measure.id": [
                    "M4",
                    "M3"
                ],
                "equation": "M4 / M3"
            }
        ]
    },
    {
        "Observable": "Training completion records, test scores from recognition assessments, incident reports related to social engineering, and results from simulated attacks (e.g., phishing simulations).",
        "Class": "Measurable",
        "Class.explanation": "This safeguard involves quantifiable aspects such as training participation rates, test performance scores, and incident reduction metrics, which can be measured using data from training systems, assessments, and security logs.",
        "Evaluation_Method": "Data-driven, Active testing",
        "Evaluation_Method.explanation": "Data-driven evaluation uses statistics from training completion logs, test scores, and incident reports to assess enforcement. Active testing involves conducting simulated social engineering attacks (e.g., phishing campaigns) to test and measure recognition skills directly.",
        "Inputs": [
            [
                "Recognizing Social Engineering Attacks training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1, identify the date of the most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Records of training completion, assessment scores, and logs from learning management systems indicating that workforce members have been trained on authentication best practices, such as MFA, password composition, and credential management.",
        "Class": "Measurable",
        "Class.explanation": "Assessing this safeguard requires data-driven analysis of training completion rates and assessment scores, which involves measuring and analyzing data rather than simply checking configurations or using scripts, as it relies on quantitative metrics to evaluate enforcement.",
        "Evaluation_Method": [
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves collecting and analyzing statistics from training logs, completion records, and assessment scores to determine the extent and effectiveness of training, using metrics derived from this data.",
        "Inputs": [
            [
                "Authentication Best Practices training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    [
                        "If Input 1 does not exist, M1 = 0",
                        [
                            "If Input 1 does not exist, M1 = 0"
                        ]
                    ]
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1,\n    identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Training completion records, screen lock event logs, data mishandling incident reports, audit observations of desk cleanliness and whiteboard erasure, and records of data storage and destruction practices.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because training completion and compliance with practices like screen locking can be checked through records and direct observations; Measurable because outcomes such as incident rates and compliance percentages can be quantified and tracked over time.",
        "Evaluation_Method": [
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation utilizes historical data from training logs, incident reports, and system logs to assess trends and compliance; Active testing involves conducting audits, simulations, or direct observations to test current employee behavior and knowledge.",
        "Inputs": [
            [
                "Data Handling Best Practices training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1,\n    identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Training completion records, data exposure incident logs, awareness survey results, and training session details",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because training attendance and completion can be confirmed through records such as certificates or logs; Measurable because the effectiveness of training can be quantified through metrics like incident rates and survey scores.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation relies on analyzing data from training completion logs, incident reports, and survey responses to assess the enforcement and effectiveness of the training program.",
        "Inputs": [
            [
                "Causes of Unintentional Data Exposure training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    [
                        "If Input 1 does not exist, M1 = 0",
                        [
                            "If Input 1 does not exist, M1 = 0"
                        ]
                    ]
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1,\n    identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": [
            "Training completion records",
            "Incident report logs",
            "Simulation test results"
        ],
        "Class": [
            {
                "name": "Measurable",
                "explanation": "The safeguard requires data-driven analysis to measure the effectiveness of training in enabling users to recognize and report incidents, based on metrics such as training completion rates and incident reporting frequencies."
            }
        ],
        "Class.explanation": "The safeguard requires data-driven analysis to measure the effectiveness of training in enabling users to recognize and report incidents, based on metrics such as training completion rates and incident reporting frequencies.",
        "Evaluation_Method": [
            {
                "name": "Data-driven",
                "explanation": "Evaluate by collecting and analyzing statistics from training records and incident reports to assess training completion and reporting behavior."
            },
            {
                "name": "Active testing",
                "explanation": "Probe the system by simulating potential incidents to test if users recognize and report them, providing direct evidence of training effectiveness."
            }
        ],
        "Evaluation_Method.explanation": "Evaluate by collecting and analyzing statistics from training records and incident reports to assess training completion and reporting behavior.",
        "Inputs": [
            [
                "Recognizing and Reporting Security Incidents training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    [
                        "If Input 1 does not exist, M1 = 0",
                        [
                            "If Input 1 does not exist, M1 = 0"
                        ]
                    ]
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1,\n    identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Training completion records, incident reports from employees about out-of-date software patches or tool failures, and notifications to IT personnel.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "It is verifiable because training records and incident reports can be inspected to confirm implementation. It is measurable because the proportion of trained employees and the rate of reporting can be quantified.",
        "Evaluation_Method": "Data-driven, Active testing",
        "Evaluation_Method.explanation": "Data-driven evaluation involves collecting and analyzing data on training completions and reported incidents. Active testing involves simulating failures to test if employees report them as trained.",
        "Inputs": [
            [
                "How to Identify and Report if Their Enterprise Assets are Missing    Security Updates training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    [
                        "If Input 1 does not exist, M1 = 0",
                        [
                            "If Input 1 does not exist, M1 = 0"
                        ]
                    ]
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1, identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training  date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Training completion records, survey responses on network security knowledge, configuration reports for home networks of remote workers, and logs of training sessions",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because training completion and configuration reports can be checked against organizational records; Measurable because knowledge and behavior changes can be assessed through data from surveys and monitoring",
        "Evaluation_Method": [
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven as it involves analyzing training completion data, survey results, and configuration reports; Active testing as it may require simulating insecure network scenarios to test user awareness and responses",
        "Inputs": [
            [
                "Dangers of Connecting to and Transmitting Enterprise Data Over    Insecure Networks training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1,\n    identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Records of training completion, assessment scores, and logs of training activities for role-specific security awareness training.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the completion of training can be checked through records and system configurations. Measurable because the effectiveness can be quantified using data such as test scores or incident rates.",
        "Evaluation_Method": [
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven because we analyze data from training platforms and security incident reports. Active testing because we can conduct knowledge assessments or simulations to probe employees' skills.",
        "Inputs": [
            [
                "Role-Specific Security Awareness and Skills Training module",
                "GV43: List of Workforce Members",
                "List of most recent module training completion dates for each    workforce member"
            ]
        ],
        "Operations": [
            [
                "Check enterprise to determine if Input 1 exists",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "For every member of the workforce in GV43, determine whether the member has completed training",
                [
                    "Identify and enumerate members who have completed at least initial training (M3)",
                    "Identify and enumerate members who have not completed any training (M4)"
                ]
            ],
            "For every member of the workforce identified in Operation 2.1, identify the date of most recently completed module training",
            [
                "For every member of the workforce identified in Operation 2.1, use the output of Operation 4 and compare the date to the current date. Capture timeframe in months.",
                [
                    "Identify and enumerate members whose most recent training date is less than or equal to twelve months from the current date (M5)",
                    "Identify and enumerate members whose most recent training date is greater than twelve months from the current date (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is measured at a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of workforce members that have received initial training",
                "measure.description": [
                    "M2 = Count of GV43",
                    "M1 = Output of Operation 1"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "The service provider inventory document or database, including listings of service providers, their classifications, enterprise contacts, and records of reviews and updates.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the inventory can be directly inspected to confirm the existence of required elements such as provider names, classifications, and contacts. Measurable because quantitative metrics for completeness and review frequency can be derived from the data.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based as the inventory's structure and configuration can be examined against requirements. Data-driven as statistics from review logs and update records are analyzed to assess compliance and timeliness.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV46: Date of Last Review or Update of the  Service Provider Inventory"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise maintains a service provider inventory list by checking for GV44,",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 2 does not exist, M1 = 0"
                ]
            ],
            [
                "Review Input 1 and determine if it includes, at a minimum, the following components: service provider, classification of provider, and an enterprise contact for the provider",
                [
                    "For each component included, assign a value of 1. Sum all values. (M2)"
                ]
            ],
            [
                "For each service provider identified in GV44, determine whether they are accurately listed",
                [
                    "Identify and enumerate providers that are accurately listed (M4)",
                    "Identify and enumerate providers that are erroneously listed (M5)",
                    "Identify and enumerate providers that should be listed but are missing (M6)"
                ]
            ],
            "Compare the date from GV46 with the current date and capture the time frame in months (M7)"
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M7 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the inventory",
                "measure.description": [
                    "M2 = Count of components included in the inventory"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "The service provider management policy document, including sections on classification, inventory, assessment, monitoring, and decommissioning of service providers, as well as records of policy reviews (e.g., dates) and updates triggered by significant changes.",
        "Class": [
            "Checklist",
            "Verifiable"
        ],
        "Class.explanation": "This safeguard is checklist-based because it can be assessed by verifying the presence and completeness of the policy against a predefined checklist of required elements. It is verifiable as the policy content can be examined to confirm it addresses all specified aspects, such as classification and monitoring.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves inspecting the policy document's configuration and content to ensure it meets the requirements. Data-driven evaluation can be applied by analyzing timestamps from review and update logs to compute metrics like review frequency and compliance.",
        "Inputs": [
            [
                "GV45: Service Provider Management Policy",
                "Date of last review or update of the policy"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise maintains a service provider management policy by checking for GV45,",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 2 does not exist, M1 = 0"
                ]
            ],
            [
                "Review GV45 and determine if it includes, at a minimum, the following components: service provider inventory, classification, assessment, monitoring, and decommissioning of service providers",
                [
                    "For each component included, assign a value of 1. Sum all values. (M2)"
                ]
            ],
            "Compare the date from Input 2 with the current date and capture the time frame in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the policy",
                "measure.description": [
                    "M2 = Count of components included in the policy"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 5"
            }
        ]
    },
    {
        "Observable": "A documented classification system for service providers, including records of classifications with attributes such as data sensitivity, data volume, etc., and logs of review activities and updates.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard can be verified by inspecting documentation and logs to ensure that service providers are classified and reviews are conducted as required, without needing complex data analytics or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation uses the configuration of the classification system, such as documented policies, classification records, and review schedules, which can be modeled and checked against requirements.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV45: Service Provider Management Policy",
                "GV46: Date of Last Review or Update of the Service Provider Inventory"
            ]
        ],
        "Operations": [
            [
                "Use GV45 to determine if the enterprise policy includes the classification process of service providers by one or more characteristics",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            "Compare the date of GV46 to the current date and capture timeframe in months (M2)",
            [
                "Review GV44 and determine whether service providers are classified using one or more characteristics per the enterprise's policy",
                [
                    "Identify and enumerate service providers with an assigned classification (M4)",
                    "Identify and enumerate service providers without a classification (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M2 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of service providers with a classification",
                "measure.description": [
                    "M4 = Count of service providers with classification",
                    "M3 = Count of service providers in inventory"
                ],
                "measure.id": [
                    "M4",
                    "M3"
                ],
                "equation": "M4 / M3"
            }
        ]
    },
    {
        "Observable": "Service provider contracts, review records, and policy documents",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the presence of security requirements in contracts can be checked against a policy checklist through inspection. Measurable because the compliance rate and review frequency can be quantified over time using data analysis.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Data-driven evaluation is used because it involves collecting and analyzing data from contract databases and review logs to generate statistics on compliance with security requirements and the timeliness of reviews.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV45: Service Provider Management Policy",
                "Date of last update or review of contracts"
            ]
        ],
        "Operations": [
            [
                "Use GV45 to determine if the enterprise policy includes security program requirements for service providers",
                [
                    "If the security requirements exist, M1 = 1",
                    "If the security requirements do not exist, M1 = 0"
                ]
            ],
            [
                "Use GV44 to determine if each listed service provider has a contract",
                [
                    "Identify and enumerate service providers with contracts (M3)",
                    "Identify and enumerate service providers without contracts (M4)"
                ]
            ],
            [
                "For each service provider with a contract identified in Operation 2.1, compare the date from input 3 to the current date and capture the timeframe in months",
                [
                    "Identify and enumerate service providers whose contract has been reviewed within twelve months or less (M5)",
                    "Identify and enumerate service providers whose contract has been reviewed outside the twelve-month window (M6)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of service providers with up-to-date contract",
                "measure.description": [
                    "M5 = Count of service providers with up-to-date contracts",
                    "M2 = Count of service providers in inventory"
                ],
                "measure.id": [
                    "M5",
                    "M2"
                ],
                "equation": "M5 / M2"
            }
        ]
    },
    {
        "Observable": "Assessment reports (e.g., SOC 2, PCI AoC), customized questionnaires, contract documents with assessment clauses, logs of review activities, and records of reassessments.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard is verifiable because enforcement can be checked by inspecting documents and records, such as assessment reports and policy compliance evidence, to confirm that assessments are conducted and aligned with the enterprise's service provider management policy.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Data-driven evaluation is used because it requires collecting and analyzing statistical data from assessment logs, contract dates, and review records to compute metrics like coverage, timeliness, and method compliance, which involve historical data and frequencies.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV45: Service Provider Management Policy"
            ]
        ],
        "Operations": [
            [
                "Use GV45 to determine if the enterprise policy includes monitoring guidance for service providers",
                [
                    "If the assessment scope exists, M1 = 1",
                    "If the assessment scope does not exist, M1 = 0"
                ]
            ],
            [
                "Use GV44 to determine if each listed service provider has monitoring guidance included in the policy",
                [
                    "Identify and enumerate service providers with monitoring guidance (M3)",
                    "Identify and enumerate service providers without monitoring guidance (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of service providers with monitoring guidance included in policy",
                "measure.description": [
                    "M3 = Count of service providers with monitoring guidance",
                    "M2 = Count of service providers in inventory"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Logs of monitoring activities, reassessment reports, records of release note checks, and dark web monitoring alerts.",
        "Class": "Measurable",
        "Class.explanation": "The safeguard requires quantitative analysis of monitoring data, compliance reports, and external scans to assess enforcement, as it involves measuring frequencies, coverage, and effectiveness rather than simple checklist verification or configuration checks.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Evaluation relies on collecting and analyzing data from various sources such as monitoring tool logs, reassessment outcomes, release note review records, and dark web scan results to generate statistics on compliance, coverage, and incident handling.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV45: Service Provider Management Policy"
            ]
        ],
        "Operations": [
            [
                "Use GV45 to determine if the enterprise policy includes monitoring guidance for service providers",
                [
                    "If the monitoring guidance exists, M1 = 1",
                    "If the monitoring guidance does not exist, M1 = 0"
                ]
            ],
            [
                "Use GV44 to determine if each listed service provider has monitoring guidance provided in the policy",
                [
                    "Identify and enumerate service providers with monitoring guidance provided (M3)",
                    "Identify and enumerate service providers without monitoring guidance provided (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of service providers with up-to-date assessments",
                "measure.description": [
                    "M3 = Count of service providers with monitoring guidance provided",
                    "M2 = Count of service providers in inventory"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Logs of user and service account deactivation, records of data flow termination, certificates of secure data disposal, inventory of decommissioned service providers.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because system configurations and logs can be inspected to confirm deactivation and termination actions. Measurable because event data from logs and activities can be analyzed to compute rates and completeness of decommissioning.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven for analyzing event logs, such as deactivation and disposal events, to measure decommissioning activities. Model-based for verifying configurations, like account status and data flow settings, to ensure compliance.",
        "Inputs": [
            [
                "GV44: Service Provider Inventory List",
                "GV45: Service Provider Management Policy"
            ]
        ],
        "Operations": [
            [
                "Use GV45 to determine if the enterprise policy includes guidance for securely decommissioning service providers",
                [
                    "If the monitoring guidance exists, M1 = 1",
                    "If the monitoring guidance does not exist, M1 = 0"
                ]
            ],
            "Use GV44 to identify and enumerate any service providers terminated over the last twelve months (M2)",
            [
                "For each service provider identified in Operation 2, determine if the provider was decommissioned per the policy",
                [
                    "Identify and enumerate service providers properly terminated (M3)",
                    "Identify and enumerate service providers improperly terminated (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is a 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of service providers properly terminated",
                "measure.description": [
                    "M3 = Count of service providers properly terminated",
                    "M2 = Count of service providers terminated over the last twelve    months"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Secure application design standards document, secure coding practices guidelines, records of developer training, vulnerability management reports, security assessments of third-party code, application security testing procedures, and logs of documentation reviews and updates.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the existence and content of documentation can be directly inspected to confirm compliance. Measurable because quantitative aspects such as the number of documented items and the time between reviews can be calculated and assessed.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based because evaluation involves comparing the documentation against a predefined model of required items (e.g., the six specified process aspects). Data-driven because it requires collecting and analyzing data from documents, logs, and records to derive metrics.",
        "Inputs": [
            [
                "GV49: Secure Application Development Process",
                "Date of last update or review of the secure application development    process"
            ]
        ],
        "Operations": [
            [
                "Determine whether GV49 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "Review GV49 and determine whether it includes, at a minimum, the following components: secure application design standards, secure coding practices, developer training, vulnerability management, security of third-party code, and application security testing procedures",
                [
                    "For each component included in the process, assign a value of 1. Sum all values (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the secure application development process",
                "measure.description": [
                    "M2 = Count of components included in the process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 6"
            }
        ]
    },
    {
        "Observable": "Vulnerability handling policy document, vulnerability tracking system (e.g., software like JIRA) with configured metrics and severity ratings, logs of vulnerability reports and their handling status (intake, assignment, remediation, testing), records of policy reviews and updates, and means for external reporting (e.g., web form or email).",
        "Class": "Checklist, Verifiable, Measurable",
        "Class.explanation": "Checklist: The existence of key components like the policy and tracking system can be verified through automated scripts or checklists. Verifiable: The content of the policy can be inspected to ensure it includes required elements such as reporting process and responsible party. Measurable: Quantitative aspects like timing metrics and address rates can be measured from data collected by the tracking system.",
        "Evaluation_Method": "Model-based, Data-driven, Active testing",
        "Evaluation_Method.explanation": "Model-based: The policy documentation and system configurations can be evaluated against established standards and requirements. Data-driven: Metrics from the tracking system, such as time deltas and report counts, require statistical analysis of event logs and data. Active testing: The reporting process can be tested by submitting simulated vulnerability reports to verify intake and handling.",
        "Inputs": [
            [
                "GV48: Process to Accept and Address Software Vulnerabilities",
                "Date of last update or review of process"
            ]
        ],
        "Operations": [
            [
                "Determine whether GV48 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "Review GV48 and determine whether it includes, at a minimum, the following components: a reporting process, a responsible party for handling vulnerability reports, a process for intake, assignment, remediation, remediation testing, and a vulnerability tracking system",
                [
                    "For each component included in the process, assign a value of 1. Sum all values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the secure application development process",
                "measure.description": [
                    "M2 = Count of components included in the process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 7"
            }
        ]
    },
    {
        "Observable": "Reports, logs, and documentation of root cause analyses performed on security vulnerabilities, including timestamps of analysis, findings, implementation status of recommendations, and records of vulnerability identifications.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the presence and configuration of root cause analysis processes can be checked through documentation reviews and system configurations; Measurable because the frequency, timeliness, and effectiveness of root cause analyses can be quantified using data from logs and reports.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves verifying the setup and configuration of root cause analysis tools and processes in systems like issue trackers or security management platforms; Data-driven evaluation involves analyzing statistical data from RCA logs, vulnerability databases, and implementation records to compute metrics such as coverage and timeliness.",
        "Inputs": [
            [
                "Root Cause Analysis Process",
                "Vulnerabilities addressed over the last twelve months"
            ]
        ],
        "Operations": [
            [
                "Determine whether Input 1 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "Review Input 1 and determine whether it includes, at a minimum, the following components: categorization of vulnerabilities, guidance for how lessons learned are incorporated into the development process",
                [
                    "For each component included in the process, assign a value of 1. Sum all values. (M2)"
                ]
            ],
            [
                "For each vulnerability addressed over the last twelve months, assess whether the root cause analysis process was followed",
                [
                    "Identify and enumerate vulnerabilities for which the process was followed (M4)",
                    "Identify and enumerate vulnerabilities for which the process was not followed (M5)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the secure application development process",
                "measure.description": [
                    "M2 = Count of components included in the process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 2"
            }
        ]
    },
    {
        "Observable": [
            "Bill of materials inventory document or database",
            "Logs of monthly evaluations",
            "Records of risk assessments for each third-party component",
            "Validation records for component support status"
        ],
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist: The existence of the inventory and basic properties like presence of risk information can be checked via automated scripts or manual checks. Verifiable: The content and completeness, such as whether all components have risk assessments and support validations, can be inspected and verified against system configurations. Measurable: Quantitative aspects like the proportion of components with risk info, the time since last evaluation, and the rate of support validation can be measured using data from the inventory.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven: Evaluation involves analyzing data from the inventory, evaluation logs, and risk records to compute statistics like coverage rates and frequencies. Model-based: The setup and configuration of the inventory system, such as database schemas or file structures, can be assessed to ensure proper management. Active testing: The system can be probed by querying the inventory for specific components or externally validating support status through APIs or manual checks.",
        "Inputs": [
            [
                "GV47: Inventory of Third-Party Software Components",
                "Date of last review or update of the inventory"
            ]
        ],
        "Operations": [
            [
                "Determine whether GV47 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "Use GV47 and determine whether each software component listed includes, at a minimum, the following information: risk associated with components, whether the component is supported",
                [
                    "Identify and enumerate software components with complete information (M3)",
                    "Identify and enumerate software components with missing information (M4)"
                ]
            ],
            "Compare the date of Input 2 to the current date and capture the timeframe in days (M5)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M5 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percent of components included in the secure application development process",
                "measure.description": [
                    "M3 = Count of software components with complete information",
                    "M2 = Count of GV47"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Lists of third-party software components with versions, acquisition sources (e.g., trusted repositories), and records of vulnerability evaluations performed before use or periodically.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because we can inspect configuration files, dependency lists, and logs to confirm the use of trusted sources and the performance of vulnerability evaluations. Measurable because we can quantify the proportions and frequencies using data analysis on software inventories and vulnerability databases.",
        "Evaluation_Method": [
            "Data-driven",
            "Model-based"
        ],
        "Evaluation_Method.explanation": "Data-driven because it involves analyzing data from software inventories, vulnerability databases (e.g., NVD), and update logs to assess compliance. Model-based because we can model expected behaviors, such as sourcing from trusted repositories or following evaluation protocols, and compare against actual system configurations.",
        "Inputs": [
            [
                "GV47: Inventory of Third-Party Software Components"
            ]
        ],
        "Operations": [
            [
                "For each software component in GV47, determine whether the latest component is being used",
                [
                    "Identify and enumerate software components that are up-to-date (M2)",
                    "Identify and enumerate software components that are not up-to-date (M3)"
                ]
            ],
            [
                "For each software component identified in Operation 1.1, determine whether they are explicitly trusted by the enterprise",
                [
                    "Identify and enumerate software components that are trusted by the enterprise (M4)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of up-to-date and trusted software components",
                "measure.description": [
                    "M4 = Count of software components that are up-to-date and trusted",
                    "M1 = Count of GV47"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Documentation of the severity rating system, records of vulnerability assessments with severity ratings, annual review reports, and evidence of prioritization processes in action (e.g., from bug tracking systems).",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and content of the severity rating documentation and process can be inspected through checks of policy documents and configuration settings. Measurable because aspects like the coverage of severity ratings, compliance with annual reviews, and effectiveness of prioritization can be quantified using data from vulnerability management systems.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven because evaluation involves analyzing statistical data from vulnerability logs, review records, and prioritization actions to assess enforcement. Model-based because it requires verifying against the documented process model of the severity rating system, such as checking if the system adheres to the defined criteria and update schedules.",
        "Inputs": [
            [
                "GV48: Process to Accept and Address Software Vulnerabilities",
                "Date of last update or review of the severity rating system and    process"
            ]
        ],
        "Operations": [
            [
                "Using GV48 determine whether the enterprise has a severity rating system and process for application vulnerabilities",
                [
                    "If the system and process exist, M1 = 1",
                    "If the system and process do not exist, M1 = 0"
                ]
            ],
            [
                "Review GV48 and determine whether it includes, at a minimum, the following components: guidance for prioritizing the order vulnerabilities are fixed, level of security acceptability for releasing code or applications",
                [
                    "For each component included in the process, assign a value of 1. Sum all values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the secure application development process",
                "measure.description": [
                    "M2 = Count of components included in the process"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 2"
            }
        ]
    },
    {
        "Observable": "Configuration files, system settings, audit logs of configuration changes, presence of standard hardening templates, absence of configuration alterations by in-house software",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because system configurations can be checked against industry-standard templates; Measurable because compliance rates and weakening incidents can be quantified and analyzed over time",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based by comparing configurations to standard hardening models; Data-driven by collecting and analyzing data on compliance and weakening events from logs and scans",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory",
                "GV37: Network Infrastructure Configuration Standards"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate application\n    infrastructure components GV50 (M1)",
            [
                "For each infrastructure component identified in Operation 1, check configurations using GV37 and determine if they meet industry-recommended hardening configuration standards",
                [
                    "Identify and enumerate infrastructure components that meet industry standards (M2)",
                    "Identify and enumerate infrastructure components that do not meet industry standards (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of application infrastructure components that meet industry configuration standards",
                "measure.description": [
                    "M2 = Count of components that meet industry standards",
                    "M1 = Count of application infrastructure components"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Network segmentation configurations, system environment assignments, and network traffic logs indicating separation between production and non-production systems.",
        "Class": [
            "Verifiable",
            "Checklist"
        ],
        "Class.explanation": "Verifiable because the separation can be confirmed by inspecting network and system configurations. Checklist because automated scripts can be written to verify the setup and check for compliance.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based because evaluation uses configuration data and models of the network to assess separation. Active testing because probing the network (e.g., sending test traffic) can verify isolation between environments.",
        "Inputs": [
            [
                "GV1: Enterprise Asset Inventory"
            ]
        ],
        "Operations": [
            "Use GV1 to identify and enumerate production systems (M1)",
            [
                "For each production system identified in Operation 1, use GV1 to identify if at least one non-production system exists for the system",
                [
                    "Identify and enumerate production systems with at least one non-production system (M2)",
                    "Identify and enumerate production systems without a non-production system (M3)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of non-production systems with an existing production system",
                "measure.description": [
                    "M2 = Count of production systems with a non-production system to    complement",
                    "M1 = Count of production systems"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Training completion records, attendance logs, training schedules, certificates of completion, and documentation of training design promoting security culture.",
        "Class": "Measurable, Verifiable",
        "Class.explanation": "Measurable because training completion rates and frequency can be quantified using data from records. Verifiable because training schedules and completion logs can be inspected for compliance.",
        "Evaluation_Method": "Data-driven",
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing statistics from training attendance records, session logs, and potentially survey data to assess enforcement.",
        "Inputs": [
            [
                "List of software developing personnel with assigned roles and    development environments",
                "List of required courses for each role and development environment",
                "Date of last training course"
            ]
        ],
        "Operations": [
            [
                "For each individual in Input 1, determine whether they have taken the applicable courses per role and environment",
                [
                    "Identify and enumerate personnel that have completed the appropriate courses (M2)",
                    "Identify and enumerate personnel that have not completed the appropriate courses (M3)"
                ]
            ],
            [
                "For each individual who has completed the appropriate courses, compare the date of the last training from Input 3 to the current date and capture the timeframe in months",
                [
                    "Identify and enumerate personnel that have completed all appropriate training within twelve months or less (M4)",
                    "Identify and enumerate personnel that have not completed all appropriate training within twelve months or less (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of software development personnel with all appropriate training courses in scope",
                "measure.description": [
                    "M4 = Count of software developing personnel with training in scope",
                    "M1 = Count of software-developing personnel"
                ],
                "measure.id": [
                    "M4",
                    "M1"
                ],
                "equation": "M4 / M1"
            }
        ]
    },
    {
        "Observable": "Application configuration files, design documents documenting secure principles, system logs showing input validation errors and error checking, settings for port and service management (e.g., disabled ports, removed programs), account configuration details (e.g., renamed default accounts), and evidence of least privilege implementation in access controls.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because secure design principles can be checked through inspection of application configurations, code reviews, and architecture documents; Measurable because the extent of implementation can be quantified using data from logs and metrics such as error rates, adoption percentages, and attack surface reduction scores.",
        "Evaluation_Method": [
            "Model-based",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves using system configurations and design models to assess adherence to secure principles; Active testing includes probing applications with inputs to validate error handling, input validation, and other security measures through techniques like penetration testing.",
        "Inputs": [
            [
                "GV49: Secure Application Development Process",
                "GV50: Application Infrastructure Components"
            ]
        ],
        "Operations": [
            [
                "Use GV49 to determine whether the process outlines a secure software framework that includes secure design principles",
                [
                    "If the framework exists, M1 = 1",
                    "If the framework does not exist, M1 = 0"
                ]
            ],
            [
                "For each application infrastructure component in GV50, determine whether the secure design principles were applied per the framework",
                [
                    "Identify and enumerate application infrastructure components where design principles are applied (M3)",
                    "Identify and enumerate application infrastructure components where design principles are not applied (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of applications infrastructure components where design principles were applied",
                "measure.description": [
                    "M3 = Count of applications infrastructure components with design    principles applied",
                    "M2 = Count of GV50"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Configuration settings indicating use of vetted security modules (e.g., for identity management, encryption, auditing, logging), audit logs showing secure components in use, and absence of custom or unvetted security implementations.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the use of vetted modules can be confirmed through inspection of system configurations, module settings, and documentation. Measurable because the proportion of applications complying with the use of standardized components can be quantified and tracked over time.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves examining configuration files, system settings, and module specifications to verify the implementation of vetted security components. Data-driven evaluation analyzes log data, usage patterns, and application behaviors to ensure that the security components are functioning as intended and to detect any deviations.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate application security\n    components (M1)",
            [
                "For each application security component identified in Operation 1, determine whether custom code exists",
                [
                    "Identify and enumerate components that contain custom code (M2)",
                    "Identify and enumerate components that do not contain custom code (M3)"
                ]
            ],
            [
                "For each application security component identified in Operation 2.1, determine whether vetted modules or services exist",
                [
                    "Identify and enumerate components for which vetted modules or services exist (M4)",
                    "Identify and enumerate components for which vetted modules or services do not exist (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of application security components using vetted modules or services when available",
                "measure.description": [
                    "M3 = Count of application security components not containing custom    code",
                    "M5 = Count of application security components containing custom code    and vetted modules or services do not exist",
                    "M1 = Count of application security components"
                ],
                "measure.id": [
                    "M3",
                    "M5",
                    "M1"
                ],
                "equation": "(M3 + M5) / M1"
            }
        ]
    },
    {
        "Observable": "Scan reports from static and dynamic analysis tools (e.g., SAST and DAST outputs), tool configuration settings in CI/CD pipelines, integration logs showing scan executions, and records of vulnerabilities detected and fixed.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the presence and configuration of analysis tools can be checked through system settings and logs. Measurable because the effectiveness of following secure coding practices can be assessed through data analytics on scan results and vulnerability counts.",
        "Evaluation_Method": "Model-based, Data-driven",
        "Evaluation_Method.explanation": "Model-based evaluation involves examining the configuration and integration of static and dynamic analysis tools in the application lifecycle. Data-driven evaluation requires analyzing data from scan reports, such as the number of scans and vulnerabilities, to assess compliance with secure coding practices.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory"
            ]
        ],
        "Operations": [
            "Use GV5 to identify and enumerate in-house developed software (M1)",
            "Use GV5 to identify static analysis tools",
            [
                "For each software identified in Operation 1, determine if it is verified by a static tool identified in Operation 2",
                [
                    "Identify and enumerate software verified by a static tool (M2)",
                    "Identify and enumerate software not verified by a static tool (M3)"
                ]
            ],
            "Use GV5 to identify dynamic analysis tools",
            [
                "For each software identified in Operation 1, determine if it is verified by a dynamic tool identified in Operation 4",
                [
                    "Identify and enumerate software verified by a dynamic tool (M4)",
                    "Identify and enumerate software not verified by a dynamic tool (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percentage of in-house developed software verified by a static analysis tool",
                "measure.description": [
                    "M2 = Count of in-house developed software verified by a static    analysis tool",
                    "M1 = Count of in-house developed software"
                ],
                "measure.id": [
                    "M2",
                    "M1"
                ],
                "equation": "M2 / M1"
            }
        ]
    },
    {
        "Observable": "Penetration test reports, testing schedules, logs of testing activities, list of applications tested, findings including business logic vulnerabilities, and evidence of authenticated and unauthenticated testing.",
        "Class": "Measurable",
        "Class.explanation": "Penetration testing produces quantifiable results such as the number of tests conducted, coverage of applications, and vulnerabilities found, which can be measured to assess enforcement quality.",
        "Evaluation_Method": [
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven: Evaluation involves analyzing statistics from penetration test reports, vulnerability databases, and logs to measure outcomes like coverage and effectiveness. Active testing: Evaluation may require probing the system through audits or sample tests to verify that penetration testing is conducted as specified, especially for critical applications.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "Application Penetration Testing Process for the enterprise"
            ]
        ],
        "Operations": [
            [
                "Determine whether Input 2 exists for the enterprise",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            "Use GV5 to identify and enumerate all applications within the enterprise (M2)",
            [
                "For each application identified in Operation 2, determine whether an unauthenticated penetration test has been conducted per the process outlined in Input 2",
                [
                    "Identify and enumerate applications that have been tested (M3)",
                    "Identify and enumerate applications that have not been tested (M4)"
                ]
            ],
            "Use the output of Operation 2 to identify and enumerate critical applications within the list of applications (M5)",
            [
                "For each application identified in Operation 4, determine whether an authenticated penetration test has been conducted per the process outlined in Input 2",
                [
                    "Identify and enumerate applications that have been tested (M6)",
                    "Identify and enumerate applications that have not been tested (M7)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of applications that underwent unauthenticated penetration testing per enterprise's process",
                "measure.description": [
                    "M3 = Count of applications that have undergone unauthenticated    penetration testing per enterprise's process",
                    "M2 = Count of applications within the enterprise"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Threat modeling reports, documentation of evaluation sessions, records of trained individuals performing threat modeling, updated design documents reflecting security fixes.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Threat modeling is verifiable because the existence and quality of threat models can be checked through documentation review. It is measurable because aspects like coverage and effectiveness can be quantified using data from the process.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Threat modeling involves examining application design models to identify security flaws, so evaluation is based on analyzing these models and their configurations rather than live testing or pure data analysis.",
        "Inputs": [
            [
                "GV5: Authorized Software Inventory",
                "Threat Modeling Process for the Enterprise"
            ]
        ],
        "Operations": [
            [
                "Determine whether Input 2 exists for the enterprise",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            "Use GV5 to identify and enumerate all in-house developed applications (M2)",
            [
                "For each application identified in Operation 2, determine whether the threat modeling process was followed",
                [
                    "Identify and enumerate applications for which threat modeling was conducted (M3)",
                    "Identify and enumerate applications for which threat modeling was not conducted (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of in-house developed applications that underwent threat modeling",
                "measure.description": [
                    "M3 = Count of in-house developed applications that underwent threat    modeling",
                    "M2 = Count of in-house developed applications"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Documentation listing the designated key and backup incident handlers, records of incident response coordination and documentation, evidence of oversight for third-party providers if used, and logs of annual reviews or reviews triggered by significant changes.",
        "Class": [
            "Verifiable",
            "Checklist"
        ],
        "Class.explanation": "This safeguard can be verified by examining organizational documents, such as incident response plans and role assignments, to confirm the presence of required designations. It can also be assessed using a checklist to ensure that all elements (key person, backup, oversight, and reviews) are in place and documented.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Model-based evaluation involves checking the configuration of roles in identity management systems or organizational documentation. Data-driven evaluation involves analyzing the timeliness and frequency of reviews based on date logs and records, such as review dates and triggers from significant changes.",
        "Inputs": [
            [
                "GV51: Enterprise Incident Response Documentation",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents designated personnel to manage incident handling by reviewing GV51. Input 1 can be an incident response plan or other documentation.",
                [
                    "If documentation designating personnel exists, M1 = 1",
                    "If documentation designating personnel does not exist, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation, at a minimum, outlines the following components: primary personnel, backup personnel, roles and responsibilities of each",
                [
                    "For each component included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for designated incident handling personnel",
                "measure.description": [
                    "M2 = Count of components included for designated personnel    documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "A documented list of contact information for security incidents, including verification dates and details of parties such as internal staff, service providers, law enforcement, etc.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be assessed by verifying the existence, completeness, and accuracy of the contact list through documentation review, which involves checking static records and configurations without the need for dynamic data analysis or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is based on examining the documentation and verification records, which are part of the system's configuration or governance artifacts, allowing for assessment through inspection of setup and records rather than data analytics or active testing.",
        "Inputs": [
            [
                "GV51: Enterprise Incident Response Documentation",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents establish and maintain contact information for reporting security incidents by reviewing GV51. Input 1 can be an incident response plan or other documentation.",
                [
                    "If documentation outlining contact information exists, M1 = 1",
                    "If documentation outlining contact information does not exist, M1 = 0"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M2)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M2 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "The documented incident reporting process, its accessibility to the workforce (e.g., on intranet or in handbooks), records of annual reviews or reviews triggered by changes, and logs of security incidents reported following the process.",
        "Class": [
            "Checklist",
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Checklist: Automated scripts can check for the existence and accessibility of the document. Verifiable: Manual inspection can verify the content includes required elements like timeframe, personnel, mechanism, and minimum information. Measurable: Data analysis can assess reporting compliance rates and review frequency using incident logs and review records.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Evaluate the configuration and content of the documented process. Data-driven: Analyze statistics from incident reports, access logs, and review records. Active testing: Conduct surveys or simulations to test workforce awareness and usage of the reporting process.",
        "Inputs": [
            [
                "GV51: Enterprise Incident Response Documentation",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents process for reporting incidents by reviewing GV51. GV51 can be an incident response plan or other documentation.",
                [
                    "If documentation for reporting incidents exists, M1 = 1",
                    "If documentation for reporting incidents does not exist, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation, at a minimum, outlines the following components: reporting timeframe, personnel to report to, mechanism for reporting, and the minimum information to be reported",
                [
                    "For each component included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)",
            [
                "Determine whether the process documentation is available to the whole workforce",
                [
                    "If it is available to all, M4 = 1",
                    "If it is not available to all, M4 = 0"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply.",
                "If M4 is 0, this Safeguard receives a failing score for this metric. Other metrics still apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for designated incident handling personnel",
                "measure.description": [
                    "M2 = Count of components included for reporting incidents process    documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 4"
            }
        ]
    },
    {
        "Observable": "Documented incident response process file, review logs or records, timestamps of reviews, and records of significant enterprise changes.",
        "Class": [
            {
                "name": "Checklist",
                "explanation": "The safeguard can be assessed by scripting to check for the existence of the documented process and its key elements, such as roles and responsibilities, compliance requirements, and communication plan."
            },
            {
                "name": "Verifiable",
                "explanation": "The content of the document can be verified by inspecting it to ensure it addresses all required components, and review activities can be confirmed through logs or records."
            }
        ],
        "Class.explanation": "The safeguard can be assessed by scripting to check for the existence of the documented process and its key elements, such as roles and responsibilities, compliance requirements, and communication plan.",
        "Evaluation_Method": [
            {
                "name": "Model-based",
                "explanation": "Evaluation relies on the state and configuration of the documentation, such as metadata, content completeness, and review timestamps, to assess enforcement."
            },
            {
                "name": "Active testing",
                "explanation": "Probing is required to access the document, check review logs, or simulate scenarios to verify that reviews are conducted as specified, especially after significant changes."
            }
        ],
        "Evaluation_Method.explanation": "Evaluation relies on the state and configuration of the documentation, such as metadata, content completeness, and review timestamps, to assess enforcement.",
        "Inputs": [
            [
                "GV51: Enterprise Incident Response Documentation",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents an incident response process, GV52, by reviewing GV51. GV51 can be an incident response plan or other documentation.",
                [
                    "If the documentation for an incident response process exists, M1 = 1",
                    "If the documentation for an incident response process does not exist, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation, at a minimum, outlines the following components: roles and responsibilities, compliance requirements, and a communication plan",
                [
                    "For each component included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for designated incident handling personnel",
                "measure.description": [
                    "M2 = Count of components included in the incident response process    documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "Incident response plan document, role assignment records, review meeting minutes, audit logs of review activities, evidence of updates after significant enterprise changes",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the existence and details of role assignments and reviews can be confirmed through inspection of documents and records. Measurable because the percentage of roles assigned and the adherence to review schedules can be quantified numerically.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation relies on the documented model of the incident response framework, including role assignments and review policies, without requiring data-driven analysis from event logs or active testing.",
        "Inputs": [
            [
                "GV52: Incident Response Process",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents key roles and responsibilities by reviewing GV52",
                [
                    "If documentation exists, M1 = 1",
                    "If documentation does not exist, M1 = 0"
                ]
            ],
            "Using the documentation in GV52, identify and enumerate the roles and responsibilities (M2)",
            [
                "For each role and responsibility identified in Operation 2, determine whether an individual is mapped to that role and responsibility",
                [
                    "Identify and enumerate those that are mapped (M3)",
                    "Identify and enumerate those that are not mapped (M4)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M5)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M5 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of roles and responsibilities that are mapped to an individual",
                "measure.description": [
                    "M3 = Count of roles and responsibilities that are mapped to an    individual",
                    "M2 = Count of roles and responsibilities outlined in the process"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "The documented incident response communication plan specifying primary and secondary mechanisms, records of annual reviews or reviews after significant enterprise changes, and evidence of communication mechanisms such as logs or configurations for phone calls, emails, secure chat, or notification letters.",
        "Class": "Verifiable",
        "Class.explanation": "This safeguard is verifiable because it can be assessed by checking the existence, content, and completeness of documentation, such as the communication plan and review records, through manual inspection or automated verification of files and logs, without requiring data-driven analytics or active probing.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "The evaluation method is model-based because it involves using the configuration and documentation of the incident response plan (e.g., the specified mechanisms and review schedules) to assess enforcement, by comparing against required standards without generating statistics or actively testing the system.",
        "Inputs": [
            [
                "GV52: Incident Response Process",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise document mechanisms for communication by reviewing GV52",
                [
                    "If the documentation for an incident response process exists, M1 = 1",
                    "If the documentation for an incident response process does not exist, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation, at a minimum, outlines primary and secondary mechanisms for communication",
                [
                    "For each mechanism included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for designated incident handling personnel",
                "measure.description": [
                    "M2 = Count of mechanisms for communication included in the documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 2"
            }
        ]
    },
    {
        "Observable": "Records of incident response exercises, including exercise plans, participation logs, after-action reports, documentation of tested aspects (communication channels, decision making, workflows), and dates of exercises.",
        "Class": "Measurable, Verifiable",
        "Class.explanation": "Measurable because quantitative data such as exercise frequency, aspect coverage, and participation rates can be analyzed; Verifiable because exercise documentation and logs can be inspected to confirm that exercises were planned and conducted as required.",
        "Evaluation_Method": "Data-driven, Active testing",
        "Evaluation_Method.explanation": "Data-driven evaluation involves generating statistics from exercise records, logs, and reports to assess frequency and coverage; Active testing is used because conducting the exercises themselves probes and tests the incident response capabilities, simulating real-world scenarios.",
        "Inputs": [
            [
                "GV52: Incident Response Process",
                "Date of last exercise or test"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise's incident response process includes routine incident response exercises by reviewing GV52",
                [
                    "If the documentation includes exercises, M1 = 1",
                    "If the documentation does not include exercises, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation for exercises, at a minimum, outlines test communication channels, decision-making, and workflows",
                [
                    "For each mechanism included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for incident response exercises",
                "measure.description": [
                    "M2 = Count of components included in the documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 3"
            }
        ]
    },
    {
        "Observable": "Post-incident review reports, documentation of lessons learned, records of follow-up actions, and audit logs indicating the conduct of review meetings.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the existence and content of post-incident reviews can be confirmed by examining documentation, records, and logs. Measurable because quantitative metrics such as review completion rates, implementation of lessons, and recurrence rates can be calculated from data collected over time.",
        "Evaluation_Method": [
            "Data-driven"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation is appropriate because it involves analyzing historical data from incident management systems, review logs, and action trackers to compute statistics on the frequency, timeliness, and effectiveness of post-incident reviews in preventing recurrence.",
        "Inputs": [
            [
                "GV52: Incident Response Process",
                "Last post-incident review"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise's incident response process includes post-incident reviews by reviewing GV52",
                [
                    "If the documentation includes post-indecent reviews, M1 = 1",
                    "If the documentation does not include post-incident reviews, M1 = 0"
                ]
            ],
            [
                "Use Input 2 to determine if post-incident reviews include, at a minimum, the following components: lessons learned and follow-up actions",
                [
                    "For each component included, assign a value of 1. Sum the values. (M2)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in post-incident reviews during Incident response exercises",
                "measure.description": [
                    "M2 = Count of components included in the documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 2"
            }
        ]
    },
    {
        "Observable": "Documents such as incident response policy, threshold definitions (including differentiation between incidents and events), review records, and change management logs indicating significant enterprise changes.",
        "Class": "Verifiable",
        "Class.explanation": "The safeguard can be verified by inspecting the documentation to ensure that security incident thresholds are defined, differentiate between incidents and events, and are reviewed annually or after significant changes, as it involves checking the existence and content of records without extensive data analysis.",
        "Evaluation_Method": "Model-based",
        "Evaluation_Method.explanation": "Evaluation is performed by examining the configuration and records, such as policy documents and review logs, to assess compliance with the safeguard requirements, using the documented model of thresholds and reviews without active testing or data-driven analysis.",
        "Inputs": [
            [
                "GV52: Incident Response Process",
                "Date of last update or review of the documentation"
            ]
        ],
        "Operations": [
            [
                "Determine whether the enterprise documents security incident threshold by reviewing GV52",
                [
                    "If the documentation for a security incident threshold exists, M1 = 1",
                    "If the documentation for a security incident threshold does not exist, M1 = 0"
                ]
            ],
            [
                "Determine whether the documentation, at a minimum, outlines the following components: differentiates between incident and event, prioritization schema based on known or potential impact, procedure relying on this schema is used to determine status update frequency during incident handling, and procedure relying on this schema is used to determine escalation paths during incident handling",
                [
                    "For each mechanism included, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date and capture the timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of components included in the documentation for security incident thresholds",
                "measure.description": [
                    "M2 = Count of components included in the documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 4"
            }
        ]
    },
    {
        "Observable": "Penetration testing program documentation, test reports, schedules, contact lists, remediation records, audit logs, and program characteristics definitions such as scope, frequency, limitations, and retrospective requirements.",
        "Class": "Verifiable, Measurable",
        "Class.explanation": "Verifiable because the program's documentation and characteristics can be inspected for compliance with defined standards; Measurable because quantitative aspects like test frequency, coverage, and remediation rates can be assessed and quantified.",
        "Evaluation_Method": "Data-driven, Model-based",
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing data from penetration tests, such as frequency logs and findings reports, to generate statistics; Model-based evaluation uses the program's defined model, such as scope and frequency settings, to verify adherence through configuration checks.",
        "Inputs": [
            [
                "GV53 Penetration Testing Program Documentation",
                "Date of last update to the penetration testing program documentation"
            ]
        ],
        "Operations": [
            [
                "Determine if GV53 exists within the enterprise",
                [
                    "If Input 1 exists, M1 = 1",
                    "If Input 1 does not exist, M1 = 0"
                ]
            ],
            [
                "Check GV53 for completeness. At a minimum, it should include the scope of the program, frequency, point of contact information, remediation, and retrospective requirements.",
                [
                    "For each component included in the documentation, assign a value of 1. Sum the values. (M2)"
                ]
            ],
            "Compare Input 2 to the current date. Capture timeframe in months (M3)"
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply.",
                "If M3 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of minimum components included in the program documentation",
                "measure.description": [
                    "M2 = Sum of components included in the documentation"
                ],
                "measure.id": [
                    "M2"
                ],
                "equation": "M2 / 5"
            }
        ]
    },
    {
        "Observable": "Penetration test reports, test schedules, logs of test activities, evidence of qualified testers, and inclusion of enterprise and environmental reconnaissance in tests.",
        "Class": "Measurable",
        "Class.explanation": "The safeguard requires measuring the frequency, coverage, and quality of penetration tests through data analysis of test results, logs, and reports, which involves quantitative assessment rather than simple checklist or configuration verification.",
        "Evaluation_Method": "Active testing",
        "Evaluation_Method.explanation": "Penetration testing involves actively probing the network to detect vulnerabilities and exploitable information, which requires direct interaction and testing of the system, aligning with the active testing evaluation method.",
        "Inputs": [
            [
                "GV54: Most Recent External Penetration Report"
            ]
        ],
        "Operations": [
            "Check GV54 for the date of the most recent external penetration\n    test. Compare the date to the current date and capture the timeframe in months (M1)"
        ],
        "Metric_as_text": [
            [
                "If M1 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": []
    },
    {
        "Observable": "Penetration test reports, remediation logs, documentation of remediation timelines and efforts based on impact, system configuration changes, records of prioritization and effort estimation",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable because the remediation of penetration test findings can be confirmed by inspecting system configurations, logs, and documentation to ensure fixes are applied. Measurable because quantitative metrics such as remediation rates, timeliness, and process adherence can be calculated from data on findings and remediations.",
        "Evaluation_Method": [
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Data-driven evaluation involves analyzing historical data from penetration tests, remediation logs, and documentation to assess compliance and effectiveness. Active testing may be used to verify that vulnerabilities are indeed fixed by conducting follow-up penetration tests or probes.",
        "Inputs": [
            [
                "GV53: Penetration Testing Program Documentation",
                "GV54: Most Recent External Penetration Report",
                "External penetration report prior to most recent report"
            ]
        ],
        "Operations": [
            "Use the findings in Input 3 to identify and enumerate the\n    vulnerabilities outlined (M1)",
            "Use the findings in GV54 to identify the vulnerabilities\n    outlined",
            [
                "Compare the output of Operation 1 and Operation 1",
                [
                    "Identify and enumerate vulnerabilities found in Input 3 that continue to be in Input 2 (M2)",
                    "Identify and enumerate vulnerabilities found in Input 3 that no longer appear in Input 2 (M3)"
                ]
            ],
            [
                "Using the program documentation from GV53, determine whether the output of Operation 3.2 is still within scope based on enterprise's policy",
                [
                    "Identify and enumerate vulnerabilities within scope (M4)",
                    "Identify and enumerate vulnerabilities out of scope (M5)"
                ]
            ]
        ],
        "Metric_as_text": [],
        "Metric": [
            {
                "definition": "The percent of successfully remediated or still within scope vulnerabilities identified in the initial penetration test findings.",
                "measure.description": [
                    "M3 = Count of vulnerabilities that have not been remediated",
                    "M4 = Count of unremediated vulnerabilities still in scope",
                    "M1 = Count of initial vulnerabilities identified by a penetration test"
                ],
                "measure.id": [
                    "M3",
                    "M4",
                    "M1"
                ],
                "equation": "(M3 + M4) / M1"
            }
        ]
    },
    {
        "Observable": "Penetration test reports, logs of validation actions, configuration changes in security systems (e.g., updated rulesets in firewalls or IDS), detection event logs showing if techniques are detected.",
        "Class": [
            "Verifiable",
            "Measurable"
        ],
        "Class.explanation": "Verifiable: The safeguard can be verified by inspecting system configurations, logs, and documentation to confirm that validation and modifications occurred after penetration tests. Measurable: The effectiveness can be quantified using metrics such as validation rates, modification compliance, and detection improvements, which require data analysis.",
        "Evaluation_Method": [
            "Model-based",
            "Data-driven",
            "Active testing"
        ],
        "Evaluation_Method.explanation": "Model-based: Configuration files and logs can be examined to verify if rulesets and capabilities were modified as needed. Data-driven: Statistical analysis of event logs and detection rates over time can assess improvements. Active testing: Probing the system with techniques from penetration tests can verify if they are now detected.",
        "Inputs": [
            [
                "GV53: Penetration Testing Program Documentation",
                "GV54: Most Recent External Penetration Report",
                "GV55: Most Recent Internal Penetration Report"
            ]
        ],
        "Operations": [
            [
                "Check GV53 to determine if it includes an enterprise process for validating security measures after a penetration test",
                [
                    "If the process exists, M1 = 1",
                    "If the process does not exist, M1 = 0"
                ]
            ],
            "Using the findings from both GV54 and GV55, as\n    applicable, identify and enumerate security measures that are required modification (M2)",
            [
                "For each security measure identified in Operation 2, check if modifications have been made",
                [
                    "Identify and enumerate security measures that have been modified per the enterprise's defined process (M3)",
                    "Identify and enumerate security measures not yet modified per the enterprise's defined process (M4)"
                ]
            ]
        ],
        "Metric_as_text": [
            [
                "If M1 is 0, this Safeguard receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": [
            {
                "definition": "The percentage of security measures requiring modification that have been properly addressed.",
                "measure.description": [
                    "M3 = Count of security measures requiring modification that are    properly addressed",
                    "M2 = Count of security measures requiring modification"
                ],
                "measure.id": [
                    "M3",
                    "M2"
                ],
                "equation": "M3 / M2"
            }
        ]
    },
    {
        "Observable": "Penetration test reports, schedules, logs of test execution, and records of network segments tested, including dates and coverage details.",
        "Class": "Measurable",
        "Class.explanation": "This safeguard involves measuring the frequency and coverage of penetration tests based on data from test reports and schedules, which requires data-driven analytics to assess compliance with program requirements.",
        "Evaluation_Method": "Active testing, Data-driven",
        "Evaluation_Method.explanation": "Active testing is used to conduct the penetration tests by actively probing the network to simulate attacks, and data-driven evaluation is applied to analyze the test data, such as frequency and coverage, to assess enforcement quality.",
        "Inputs": [
            [
                "GV55: Most Recent Internal Penetration Report"
            ]
        ],
        "Operations": [
            "Check GV55 for the date of the most recent internal penetration\n    test. Compare the date to the current date and capture the timeframe in months\n    (M1)"
        ],
        "Metric_as_text": [
            [
                "If M1 is greater than twelve months, then this Safeguard is measured at a 0 and receives a failing score. The other metrics don't apply."
            ]
        ],
        "Metric": []
    }
]